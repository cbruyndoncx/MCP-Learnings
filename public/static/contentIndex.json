{"1-Official-py-and-ts-sdk-tutes/001_model":{"slug":"1-Official-py-and-ts-sdk-tutes/001_model","filePath":"1 Official py and ts sdk tutes/001_model.md","title":"001_model","links":[],"tags":[],"content":"Okay, let’s break down the modelcontextprotocol-typescript-sdk project based on the provided file structure and content.\nProject Overview:\nThis repository contains the official TypeScript SDK for the Model Context Protocol (MCP). It provides the necessary tools and abstractions for developers to build both MCP clients and MCP servers in a TypeScript environment. The SDK aims to simplify the implementation of the MCP specification by handling protocol details, transport mechanisms, and core concepts like resources, tools, and prompts. It’s authored by Anthropic and licensed under MIT.\nCore Concepts &amp; Purpose:\n\nMCP Implementation: The primary goal is to provide a robust and easy-to-use implementation of the MCP specification.\nClient/Server Separation: The SDK clearly separates client-side (src/client) and server-side (src/server) concerns.\nTransport Abstraction: It defines a Transport interface (src/shared/transport.ts) and provides concrete implementations for common communication methods like stdio and Streamable HTTP. An older SSE transport is included for backwards compatibility, and a WebSocket transport exists for the client. InMemoryTransport is provided for testing.\nProtocol Handling: A core Protocol class (src/shared/protocol.ts) handles the JSON-RPC framing, request/response mapping, notifications, timeouts, and cancellation logic, serving as the base for both Client and Server.\nHigh-Level Abstractions: The McpServer class (src/server/mcp.ts) offers a simplified API on top of the base Server class (src/server/index.ts) for defining resources, tools, and prompts declaratively.\nSchema Definition: Uses zod extensively (src/types.ts) to define and validate the MCP message structures, ensuring type safety and protocol compliance.\nOAuth Integration: Provides significant support for OAuth 2.1, including client-side helper functions (src/client/auth.ts) and a comprehensive server-side implementation (src/server/auth/) with handlers, middleware, and even a proxy provider.\nResumability &amp; State Management: The StreamableHTTPServerTransport supports session management and resumability through an EventStore interface (example in src/examples/shared/inMemoryEventStore.ts).\nDynamic Capabilities: Supports adding, removing, enabling, disabling, and updating resources, tools, and prompts after the server has connected, automatically notifying clients of changes.\n\nKey Features &amp; Implementation Details:\n\n\nClient (src/client):\n\nClient class provides high-level methods (listTools, callTool, readResource, etc.).\nTransport implementations: StdioClientTransport, SSEClientTransport (deprecated), StreamableHTTPClientTransport, WebSocketClientTransport.\nOAuth client utilities for handling authorization flows.\nCapability negotiation during initialization.\n\n\n\nServer (src/server):\n\nServer class (low-level) allows direct request/notification handler registration.\nMcpServer class (high-level) simplifies defining tools, resources, and prompts using .tool(), .resource(), .prompt().\nTransport implementations: StdioServerTransport, SSEServerTransport (deprecated), StreamableHTTPServerTransport.\nComprehensive OAuth server implementation (src/server/auth):\n\nRouter (mcpAuthRouter) for standard OAuth endpoints (.well-known, authorize, token, register, revoke).\nHandlers for each endpoint.\nMiddleware for client authentication (authenticateClient) and bearer token validation (requireBearerAuth).\nProxyOAuthServerProvider to delegate authentication to an external provider.\n\n\nCompletable (src/server/completable.ts): A Zod wrapper to add autocompletion logic to schemas, used for prompt/resource arguments.\n\n\n\nShared (src/shared):\n\nprotocol.ts: Core logic for message handling, request timeouts, cancellation, progress.\ntypes.ts: Central Zod schemas defining the entire MCP message set and types. Includes protocol version constants.\ntransport.ts: The abstract Transport interface.\nauth.ts: Shared OAuth schemas (metadata, tokens, client info).\nuriTemplate.ts: RFC 6570 URI Template implementation, crucial for dynamic resources.\nstdio.ts: Shared logic for stdio message framing.\n\n\n\nTransports:\n\nStreamable HTTP: The modern, recommended transport. Supports stateful (session ID) and stateless modes, as well as resumability via an EventStore. Handles GET (SSE stream), POST (messages), and DELETE (session termination).\nStdio: For command-line integration. Uses cross-spawn.\nSSE (Deprecated): HTTP+SSE transport from older protocol versions, maintained for backwards compatibility. Uses separate GET (/sse) and POST (/messages) endpoints.\nWebSocket (Client-only): A client transport using WebSockets.\nInMemory: For testing client/server interaction within the same process.\n\n\n\nDocumentation &amp; Examples:\n\nREADME.md: Comprehensive overview, quick start, core concepts, transport setup, examples, and advanced usage patterns (dynamic servers, OAuth proxy, backwards compatibility).\nsrc/examples: Contains more detailed client and server examples, including different transport configurations (stateless, JSON response mode, backwards compatible) and parallel client scenarios. The examples README provides valuable context on multi-node deployment patterns.\n\n\n\nTesting &amp; Tooling:\n\nUses Jest and ts-jest for testing.\nUnit tests are co-located with source files (*.test.ts).\nIntegration tests (src/integration-tests) cover aspects like process cleanup and state management.\nESLint for linting.\nTypeScript for static typing.\nGitHub Actions (.github/workflows/main.yml) for CI (build, lint, test) and CD (publishing to npm on release).\n\n\n\nStrengths:\n\nComprehensive: Covers both client and server implementations thoroughly.\nWell-Structured: Clear separation of concerns (client/server/shared/transport).\nModern TypeScript: Uses ES Modules, Zod for schemas, standard tooling.\nFeature-Rich: Includes advanced features like dynamic capabilities, OAuth proxying, resumability, autocompletion, and backwards compatibility.\nGood Documentation: The main README is detailed and covers many use cases. The examples README adds context on deployment.\nExtensible: The Protocol base class and Transport interface allow for customization.\nTesting: Includes unit and integration tests.\n\nPotential Areas for Minor Clarification:\n\nThe existence of both Server and McpServer might initially confuse users, but the README explains McpServer as the higher-level abstraction.\nWebSocket server support is not present, only client-side. This seems intentional based on the file structure.\nThe CLAUDE.md file appears to be internal developer notes rather than public documentation.\n\nConclusion:\nThis is a well-designed and comprehensive SDK for the Model Context Protocol. It provides robust implementations for both clients and servers, supports multiple transport mechanisms (with a clear preference for Streamable HTTP), and includes advanced features necessary for real-world applications, such as authentication, dynamic capabilities, and resumability. The use of Zod ensures type safety and protocol adherence. The documentation and examples are strong, making it a solid foundation for developers looking to integrate with or build MCP-based systems."},"1-Official-py-and-ts-sdk-tutes/003_model":{"slug":"1-Official-py-and-ts-sdk-tutes/003_model","filePath":"1 Official py and ts sdk tutes/003_model.md","title":"003_model","links":[],"tags":[],"content":"Okay, let’s analyze the modelcontextprotocol-python-sdk project.\nProject Overview:\nThis repository contains the official Python SDK for the Model Context Protocol (MCP). Similar to its TypeScript counterpart, it provides developers with the tools to build both MCP clients and servers using Python. It leverages Python’s asynchronous capabilities (anyio) and modern tooling (uv, ruff, pyright, pydantic).\nCore Concepts &amp; Purpose:\n\nMCP Implementation: Provides a Pythonic way to implement the MCP specification.\nClient/Server: Maintains a clear distinction between client (src/mcp/client) and server (src/mcp/server) components.\nTransport Abstraction: Implements transports for stdio, SSE (Server-Sent Events), and WebSocket. Notably, it does not seem to have a direct implementation of the newer Streamable HTTP transport found in the TypeScript SDK, favoring SSE for HTTP-based server communication.\nProtocol Handling: A BaseSession class (src/mcp/shared/session.py) likely handles the core JSON-RPC logic, request/response mapping, and lifecycle, analogous to Protocol in the TS SDK.\nHigh-Level Server API (FastMCP): Offers a user-friendly, decorator-based interface (@mcp.tool, @mcp.resource, @mcp.prompt) for building servers, located in src/mcp/server/fastmcp/. This is the primary recommended way to build servers according to the README.\nLow-Level Server API: Provides a more granular Server class (src/mcp/server/lowlevel/server.py) for finer control over protocol handling.\nSchema Validation: Uses Pydantic (src/mcp/types.py) for defining and validating MCP message structures, ensuring data integrity and providing type hints.\nAsynchronous: Built heavily on anyio for robust asynchronous operations across different event loops (like asyncio, trio).\nCLI Tooling: Includes an mcp command-line tool (src/mcp/cli) built with typer. This tool offers development (mcp dev) and installation (mcp install) features, specifically integrating with the Claude Desktop application.\nLifespan Management: Supports server startup and shutdown logic using async context managers (lifespan).\n\nKey Features &amp; Implementation Details:\n\n\nClient (src/mcp/client):\n\nClientSession class provides the main interface (initialize, call_tool, read_resource, etc.).\nTransport implementations: stdio_client (using anyio.open_process, with Windows-specific handling), sse_client (using httpx-sse), websocket_client (using websockets).\n\n\n\nServer (src/mcp/server):\n\nFastMCP (src/mcp/server/fastmcp):\n\nHigh-level, decorator-based API.\nUses modular managers (ToolManager, ResourceManager, PromptManager) internally.\nProvides a Context object for injection into handlers, offering access to logging, progress reporting, etc.\nBuilt on ASGI principles, integrating with Starlette/Uvicorn for SSE and WebSocket transports via sse_app() and websocket_server.\nSupports lifespan context managers for resource initialization/cleanup.\n\n\nServer (src/mcp/server/lowlevel):\n\nLower-level API allowing direct handler registration via decorators (@server.call_tool(), @server.read_resource(), etc.).\n\n\nTransport implementations: stdio_server (using anyio streams wrapping sys.stdin/stdout), SseServerTransport (using sse-starlette), websocket_server (using starlette.websockets).\nAbsence of Streamable HTTP: Unlike the TS SDK, there’s no direct StreamableHTTPServerTransport. Server-side HTTP communication seems primarily handled via the SSE transport (SseServerTransport), which implies adherence to the older HTTP+SSE spec version or a custom interpretation.\n\n\n\nShared (src/mcp/shared):\n\nsession.py: Contains BaseSession for core protocol logic.\ntypes.py: Central Pydantic models for MCP messages.\ncontext.py: Defines RequestContext.\nexceptions.py: Custom exception classes.\n\n\n\nTooling &amp; Ecosystem:\n\nPackage Management: Uses uv as the primary tool (explicitly mandated in CLAUDE.md).\nLinting/Formatting: ruff.\nType Checking: pyright.\nTesting: pytest with anyio. Tests are well-structured, mirroring the source layout and including specific issue regression tests (tests/issues).\nDocumentation: mkdocs with mkdocstrings for API reference generation.\nCLI: typer for the mcp command.\n\n\n\nClaude Desktop Integration:\n\nThe mcp install command (src/mcp/cli/claude.py) directly modifies the Claude Desktop configuration file (claude_desktop_config.json) to register servers. This is a key feature for seamless integration with that specific client.\nThe mcp dev command likely starts the server and potentially the MCP Inspector tool (via npx).\n\n\n\nStrengths:\n\nPythonic API: FastMCP offers a very idiomatic Python experience using decorators.\nModern Tooling: Leverges uv, ruff, pyright, pydantic, anyio, typer, aligning with modern Python development practices.\nAsynchronous Focus: Built from the ground up with anyio, allowing flexibility in async backends.\nStrong Typing: Pydantic models and pyright ensure type safety.\nASGI Integration: Easily mountable into existing Starlette/FastAPI applications.\nClaude Desktop Integration: The CLI provides first-class support for integrating servers with the Claude Desktop app.\nGood Examples: Clear examples provided, especially for the FastMCP interface.\n\nDifferences from TypeScript SDK:\n\nPrimary HTTP Transport: Relies on SSE (SseServerTransport) for server-side HTTP, rather than the newer Streamable HTTP transport found in the TS SDK. This might imply targeting an older version of the MCP spec for HTTP or a different approach. It lacks the combined GET/POST/DELETE endpoint and built-in resumability features of Streamable HTTP.\nWeb Framework: Uses ASGI (Starlette/Uvicorn) instead of Node.js/Express.\nHigh-Level API: FastMCP is the Python equivalent of McpServer, but the implementation details differ due to Python’s decorator capabilities.\nTooling: Uses Python-specific tools (uv, ruff, pyright, pytest, mkdocs).\nCLI Integration: Has a more developed CLI (mcp) with specific commands for Claude Desktop.\nOAuth: No dedicated mcp/server/auth module is present, suggesting OAuth support might be less built-in compared to the TS SDK, potentially requiring manual integration with other Python libraries or relying on client-side handling.\n\nPotential Areas for Clarification:\n\nThe specific version of the MCP HTTP transport specification targeted by the SSE implementation isn’t immediately obvious. It seems closer to the deprecated HTTP+SSE than the newer Streamable HTTP.\nThe lack of a dedicated server-side OAuth module (compared to the TS SDK) might mean users need to implement more of the OAuth flow themselves if building a secure server.\nCLAUDE.md contains internal development guidelines, not user documentation.\n\nConclusion:\nThe modelcontextprotocol-python-sdk is a well-structured and Pythonic implementation of the MCP standard. It excels in its use of modern Python tooling, strong typing with Pydantic, native async support via anyio, and a user-friendly high-level API (FastMCP). The integration with ASGI frameworks is a significant advantage for Python web developers. Its standout feature is the CLI tooling for seamless integration with the Claude Desktop application. The main divergence from the TypeScript SDK is its apparent focus on SSE rather than the newer Streamable HTTP transport for server-side HTTP communication and the lack of a built-in server-side OAuth module."},"1-Official-py-and-ts-sdk-tutes/005_model":{"slug":"1-Official-py-and-ts-sdk-tutes/005_model","filePath":"1 Official py and ts sdk tutes/005_model.md","title":"005_model","links":[],"tags":[],"content":"Okay, here is a plan for a 10-part blog series diving deep into the MCP TypeScript and Python SDKs, covering inner workings, comparisons, and end-user implications.\nTarget Audience: Developers building or integrating with MCP servers/clients, technical architects evaluating the protocol, developers interested in cross-language SDK design.\nOverall Goal: To provide a comprehensive understanding of how the MCP SDKs function internally, highlight the design choices and trade-offs between the TypeScript and Python versions, and illustrate how these technical details enable specific end-user experiences and application types.\n\nBlog Series: Deep Dive into the Model Context Protocol SDKs (TypeScript &amp; Python)\nBlog 1: Introduction - Unpacking the MCP SDKs\n\nCore Focus: Introduce MCP, the role of the SDKs, and the series structure.\nKey Topics:\n\nWhat problem does MCP solve? (Brief recap)\nWhy SDKs? The value proposition over raw protocol implementation.\nHigh-level overview of the TS and Python SDK Repositories (purpose, core components based on README.md and structure).\nIntroducing the core primitives: Resources, Tools, Prompts (briefly, more detail later).\nSetting the stage for the deep dive and comparison.\n\n\nSDK Comparison: Mention the existence of both and the goal of comparing them.\nEnd-User Nuance: How do these SDKs ultimately enable richer, more contextual interactions between users, LLMs, and external systems/data?\n\nBlog 2: The Heart of the Protocol - Defining MCP Types\n\nCore Focus: How the MCP message structure is defined and validated in each SDK.\nKey Topics:\n\nDeep dive into src/types.ts (TS) and src/mcp/types.py (Python).\nRole of Zod (TS) vs. Pydantic (Python) for schema definition and validation.\nHow core JSON-RPC concepts (Request, Response, Notification, Error) are represented.\nExamining key MCP message types (Initialize, CallTool, ReadResource, GetPrompt, etc.) in both schemas.\nHandling of protocol versions (LATEST_PROTOCOL_VERSION, SUPPORTED_PROTOCOL_VERSIONS).\n\n\nSDK Comparison: Direct comparison of Zod vs. Pydantic for this specific use case (pros/cons), how unions/literals/optionals are handled, strictness.\nEnd-User Nuance: Type safety ensures reliable communication, preventing unexpected errors for the user due to malformed data between client/server. Robust schemas enable consistent tool/resource behavior.\n\nBlog 3: Server Architecture - High-Level APIs (McpServer / FastMCP)\n\nCore Focus: The primary, user-friendly way to build MCP servers in each language.\nKey Topics:\n\nTypeScript: McpServer (src/server/mcp.ts) - .tool(), .resource(), .prompt() methods. How it wraps the lower-level Server. Capability registration.\nPython: FastMCP (src/mcp/server/fastmcp/server.py) - Decorator-based approach (@mcp.tool, @mcp.resource, @mcp.prompt). Internal use of Managers (ToolManager, etc.).\nHow Resources, Tools, and Prompts are registered and managed internally in each high-level API.\nLifespan management (lifespan in Python, potentially manual in TS examples).\nContext injection (Context object in Python).\n\n\nSDK Comparison: Decorators (Python) vs. Method Chaining/Registration (TS). Ease of use, flexibility, Pythonic vs. TypeScript idiomatic approaches. Dependency specification in FastMCP.\nEnd-User Nuance: These APIs drastically lower the barrier for developers to expose existing tools or data sources to LLMs, leading to faster development of contextual AI applications for users.\n\nBlog 4: Server Architecture - Under the Hood (Low-Level Server APIs)\n\nCore Focus: The foundational server classes and protocol handling.\nKey Topics:\n\nTypeScript: Server class (src/server/index.ts) and the base Protocol class (src/shared/protocol.ts). setRequestHandler, setNotificationHandler.\nPython: Server class (src/mcp/server/lowlevel/server.py) and the base BaseSession class (src/mcp/shared/session.py). Decorators like @server.call_tool().\nCore request/response lifecycle management, message validation, ID tracking.\nCapability assertion logic (assertCapabilityForMethod, etc.).\nError handling and reporting (McpError).\nHow the high-level APIs build upon these low-level components.\n\n\nSDK Comparison: Similarities in core protocol logic abstraction. Differences in handler registration (explicit methods vs. decorators). Session management concepts (BaseSession vs. implicit in Protocol).\nEnd-User Nuance: The robustness of this underlying layer ensures the stability and reliability users experience, even if the application-specific tool/resource logic has bugs.\n\nBlog 5: Client Architecture - Talking to Servers\n\nCore Focus: How clients connect to and interact with MCP servers.\nKey Topics:\n\nTypeScript: Client class (src/client/index.ts). High-level methods (callTool, readResource).\nPython: ClientSession class (src/mcp/client/session.py). Similar high-level methods.\nThe initialize handshake process from the client’s perspective.\nSending requests and handling responses/errors.\nReceiving and handling server notifications (setNotificationHandler / callbacks).\nClient-side capability declaration and handling.\n\n\nSDK Comparison: API design differences (Client class methods vs. ClientSession methods). Callback/handler patterns for async operations and notifications.\nEnd-User Nuance: A well-behaved client ensures that user requests involving tools or resources are processed efficiently and that users are kept informed via notifications (e.g., progress updates).\n\nBlog 6: Bridging Worlds - Transport Deep Dive (Stdio &amp; Foundational HTTP)\n\nCore Focus: Exploring the non-Streamable HTTP transports and their implementations.\nKey Topics:\n\nThe Transport interface (src/shared/transport.ts / Implied in Python handler functions).\nStdio: Implementation in TS (StdioClientTransport, StdioServerTransport) vs. Python (stdio_client, stdio_server). Use of cross-spawn (TS) vs. anyio.open_process (Python). Windows-specific handling in Python (src/mcp/client/stdio/win32.py). Use cases (CLI tools, local integration).\nSSE (Python Focus): Deep dive into Python’s SseServerTransport and sse_client. How it handles separate GET/POST endpoints. Contrast with the deprecated SSE in TS (used mainly for backwards compatibility examples).\nWebSocket (Client): Brief overview of the client-side WebSocket transport in both SDKs. Discuss why a server might not be included.\nInMemory: Usefulness for testing (InMemoryTransport in TS, create_client_server_memory_streams in Python).\n\n\nSDK Comparison: Handling of process spawning (stdio). Python’s reliance on SSE for HTTP vs. TS’s deprecation. Asynchronous stream handling (anyio vs. Node streams/async).\nEnd-User Nuance: Stdio enables powerful local integrations (like the Claude Desktop app installing local tools). SSE/WebSocket enable remote tools and resources, expanding application possibilities beyond the local machine.\n\nBlog 7: The Modern Web - Streamable HTTP &amp; Backwards Compatibility\n\nCore Focus: Deep dive into the Streamable HTTP transport (primarily TS) and backwards compatibility strategies.\nKey Topics:\n\nStreamable HTTP (TypeScript): StreamableHTTPClientTransport, StreamableHTTPServerTransport. Single endpoint for GET/POST/DELETE. Session management (stateful vs. stateless). JSON Response mode. Built-in resumability via EventStore. Handling concurrent streams. Reconnection logic.\nComparison with Python’s SSE: Why did TS adopt Streamable HTTP? What are the advantages (single endpoint, resumability)? Why does Python seem to stick with SSE for server-side HTTP? (Spec version differences? Simplicity? ASGI integration ease?).\nBackwards Compatibility: Analyzing the strategies outlined in the READMEs (streamableHttpWithSseFallbackClient.ts, sseAndStreamableHttpCompatibleServer.ts). How clients and servers can support multiple transport versions.\n\n\nSDK Comparison: Major difference in primary HTTP transport approach and features. Resumability is a key differentiator for Streamable HTTP.\nEnd-User Nuance: Streamable HTTP enables more robust and resilient web-based MCP applications, especially for long-running operations (resumability). Backwards compatibility ensures users aren’t immediately broken when client/server versions mismatch.\n\nBlog 8: Securing Interactions - Authentication (OAuth Focus)\n\nCore Focus: How authentication, particularly OAuth, is handled. Strong focus on the TS implementation.\nKey Topics:\n\nTypeScript OAuth: Deep dive into src/server/auth. The mcpAuthRouter, handlers (authorize, token, register, revoke), middleware (authenticateClient, requireBearerAuth), OAuthServerProvider interface, and the ProxyOAuthServerProvider. Client-side helpers (src/client/auth.ts).\nPython OAuth: Absence of a dedicated auth module. Discuss potential approaches: relying on ASGI middleware, external libraries (like Authlib), or client-managed tokens passed via headers. How might the FastMCP context be used?\nBearer token usage in requests.\n\n\nSDK Comparison: TS has a highly integrated, comprehensive server-side OAuth solution. Python seems to require more manual setup or reliance on the broader Python web ecosystem.\nEnd-User Nuance: Robust authentication is critical for securing user data and actions when MCP servers handle sensitive operations or access private resources. OAuth enables standardized, secure delegation.\n\nBlog 9: Advanced Capabilities - Dynamic Updates, Context, CLI &amp; More\n\nCore Focus: Exploring advanced SDK features beyond basic requests.\nKey Topics:\n\nDynamic Capabilities (TS): How resources/tools/prompts can be added/updated/removed after connection using the RegisteredTool/Resource/Prompt handles (enable, disable, update, remove) and how listChanged notifications are triggered. (How is this done in Python? Is it supported in FastMCP?)\nContext Injection (Python): The Context object in FastMCP and how it provides access to logging, progress, resources (ctx.read_resource), request info. Compare with RequestHandlerExtra in TS.\nAutocompletion (TS): The Completable Zod wrapper and how it integrates with McpServer for resource/prompt argument completion. (Python equivalent?)\nCLI Tooling (Python): The mcp CLI (src/mcp/cli) - dev, run, install commands. Deep dive into the Claude Desktop integration (claude.py). (TS equivalent is simpler cli.ts).\nResumability (TS): Revisit the EventStore concept for Streamable HTTP.\n\n\nSDK Comparison: Dynamic updates seem more explicit in TS. Context injection is more integrated in Python’s FastMCP. CLI tooling is far more developed in Python. Resumability tied to Streamable HTTP (TS). Autocompletion support in TS.\nEnd-User Nuance: Dynamic capabilities allow applications to adapt available tools/resources based on user state or context. Context injection simplifies development. CLI tooling streamlines developer workflow, especially for Claude Desktop users. Resumability improves UX for long tasks over unreliable connections.\n\nBlog 10: Synthesis - Developer Experience, Use Cases &amp; Future\n\nCore Focus: Summarize the key differences, discuss the developer experience, and connect SDK features to end-user applications.\nKey Topics:\n\nSummary of key architectural and feature differences (Transports, High-Level APIs, Auth, CLI).\nDeveloper Experience: Ease of getting started, type safety, debugging, ecosystem integration (ASGI vs. Node/Express).\nMapping SDK features to end-user application types (e.g., Local control apps via Stdio, Web-based agents via SSE/StreamableHTTP, Chatbots integrating external tools).\nHow specific design choices (e.g., decorators vs. methods, anyio vs. Node async) reflect language idioms.\nPotential future directions for the SDKs or MCP itself based on current implementations.\nConcluding thoughts on choosing between the SDKs.\n\n\nSDK Comparison: Holistic comparison of the developer ergonomics and suitability for different project types.\nEnd-User Nuance: Final thoughts on how the design and features of these SDKs empower developers to create novel, powerful, and reliable AI-driven applications for end-users.\n\n\nThis plan provides a solid structure for a deep-dive series. Each post builds on the previous ones, progressively revealing more complex aspects of the SDKs while consistently comparing the two implementations and linking technical details back to the end-user value proposition. Remember to include plenty of code snippets and potentially diagrams (especially for architecture and transports) in the actual blog posts."},"1-Official-py-and-ts-sdk-tutes/Blogs/blog-1":{"slug":"1-Official-py-and-ts-sdk-tutes/Blogs/blog-1","filePath":"1 Official py and ts sdk tutes/Blogs/blog-1.md","title":"Blog 1: Unpacking the Model Context Protocol SDKs: Bridging the AI Context Gap","links":[],"tags":[],"content":"Blog 1: Unpacking the Model Context Protocol SDKs: Bridging the AI Context Gap\nSeries: Deep Dive into the Model Context Protocol SDKs (TypeScript &amp; Python)\r\nPost: 1 of 10\nLarge Language Models (LLMs) are incredibly powerful, but they often operate with a kind of digital amnesia. Out of the box, they lack awareness of your current application state, open files, recent emails, or specific domain knowledge unless explicitly provided in the prompt. This “context gap” limits their ability to act as truly integrated, helpful assistants within our digital workflows.\nEnter the Model Context Protocol (MCP).\nWhat is MCP?\nThink of MCP as a standardized API layer specifically designed for LLMs. It allows applications (like your text editor, email client, or custom internal tools) to securely expose relevant data (Resources) and functionalities (Tools) to LLM-powered clients (like AI assistants or chatbots) in a structured way. It also allows defining reusable interaction patterns (Prompts).\nThis separation of concerns is key:\n\nApplications (Servers): Focus on securely providing their specific context or capabilities.\nLLM Clients: Can discover and interact with any MCP-compliant server without needing custom integrations for each one.\n\nMCP aims to create a standardized ecosystem where AI can seamlessly and securely leverage the context of the applications we use daily.\nWhy SDKs? Beyond the Specification\nWhile MCP is defined by a specification, implementing it directly involves handling JSON-RPC framing, message validation, transport negotiation, lifecycle management, and more. To simplify this, official Software Development Kits (SDKs) have been developed.\nThis blog series dives deep into the two official SDKs maintained by Anthropic:\n\nmodelcontextprotocol-typescript-sdk: For Node.js and TypeScript environments. (GitHub)\nmodelcontextprotocol-python-sdk: For the Python ecosystem. (GitHub)\n\nThese SDKs provide higher-level abstractions, handle the protocol intricacies, manage transport layers (like stdio, SSE, Streamable HTTP), and offer idiomatic ways to build both MCP clients and servers in their respective languages. They are the key to unlocking MCP’s potential for developers.\nA Quick Tour of the SDK Repositories\nBefore we dive deeper in subsequent posts, let’s familiarize ourselves with the general structure, which is remarkably similar between the two SDKs, reflecting a shared design philosophy:\n\nsrc/ (or src/mcp/ in Python): The core source code.\n\nclient/: Contains the code for building MCP clients – applications that consume context or capabilities from MCP servers. This includes the main Client (TS) or ClientSession (Python) classes and transport implementations.\nserver/: Contains the code for building MCP servers – applications that expose context or capabilities. This includes base Server classes, high-level APIs like McpServer (TS) and FastMCP (Python), and transport implementations.\nshared/: Holds code common to both clients and servers, such as the core protocol logic (protocol.ts/session.py), transport interfaces, and utility functions.\ntypes.ts / types.py: Crucial files defining the entire MCP message structure using Zod (TypeScript) or Pydantic (Python). This ensures type safety and protocol compliance.\n\n\nexamples/: Contains practical examples of clients and servers, demonstrating various features and transport mechanisms. These are invaluable learning resources.\ntests/: Unit and integration tests ensuring the SDKs function correctly and adhere to the specification.\nConfiguration (package.json/pyproject.toml): Defines dependencies, build processes, and scripts.\n\nWe’ll explore the specifics within these directories throughout the series.\nCore MCP Primitives (via the SDKs)\nThe SDKs make it easy to work with the fundamental building blocks of MCP:\n\nResources: Think of these like GET endpoints in a web API. They expose data or context to the LLM client. The SDKs provide ways to define static resources (fixed URIs) and dynamic resources (using URI Templates like users://{user_id}/profile) backed by functions.\n\nEnd-User Nuance: Allows an AI assistant to “read” the content of the user’s currently open file, a specific email, or data from a custom application database.\n\n\nTools: Analogous to POST endpoints. They allow the LLM client to trigger actions or computations on the server side. The SDKs handle defining tools, their input parameters (with validation), and executing the associated function.\n\nEnd-User Nuance: Enables an AI assistant to perform actions like sending an email draft, querying a database based on user request, creating a calendar event, or even interacting with desktop automation.\n\n\nPrompts: Reusable templates for interaction patterns. They define a structure (often a series of messages) that can be filled with arguments, guiding the LLM’s interaction with the server’s capabilities or data.\n\nEnd-User Nuance: Can manifest as predefined actions or slash commands in a chat interface (e.g., /summarize_document, /debug_error [error message]), making complex interactions predictable and user-friendly.\n\n\n\nThe End-User Connection: Why Does This Matter?\nWhy go through the trouble of a protocol and SDKs? Because it enables fundamentally richer, more helpful, and more integrated AI experiences.\nImagine an AI assistant that:\n\nKnows your context: When you ask it to “summarize this,” it knows which document or email you’re referring to because the application exposes it as an MCP Resource.\nCan act on your behalf: You ask it to “find all customers in California and draft an email,” and it uses an MCP Tool exposed by your CRM server to query the data and another tool to initiate the draft.\nLeverages specialized tools: Your company’s internal inventory management system exposes MCP tools, allowing the assistant to check stock levels directly when you ask.\n\nThe SDKs are the enablers, making it feasible for developers to build these contextual bridges between applications and AI. They handle the complex plumbing so developers can focus on what context or capability to expose.\nWhat’s Next in the Series?\nThis was just a high-level introduction. In the upcoming posts, we’ll peel back the layers and dive into the specifics:\n\nBlog 2: Defining the MCP Language: A deep dive into how types.ts (Zod) and types.py (Pydantic) define the protocol structure.\nBlog 3: Building Servers the Easy Way: Exploring the high-level McpServer (TS) and FastMCP (Python) APIs.\nBlog 4: Server Architecture - Under the Hood: Looking at the low-level server implementations and core protocol handling.\n…and much more, covering clients, transports (Stdio, SSE, Streamable HTTP, WebSockets), authentication, advanced features like dynamic capabilities and context injection, and culminating in a synthesis of the developer experience and use cases.\n\nWe’ll be comparing the TypeScript and Python implementations side-by-side, highlighting design choices and trade-offs inherent in each language ecosystem.\nJoin us on this deep dive! Check out the SDK repositories, experiment with the examples, and feel free to ask questions in the comments below or in the GitHub Discussions (links point to Python repo, but applicable to both).\n\nTypeScript SDK Repository\nPython SDK Repository\n\nStay tuned for the next post where we’ll dissect the type systems that form the bedrock of these SDKs!"},"1-Official-py-and-ts-sdk-tutes/Blogs/blog-10":{"slug":"1-Official-py-and-ts-sdk-tutes/Blogs/blog-10","filePath":"1 Official py and ts sdk tutes/Blogs/blog-10.md","title":"Blog 10: Synthesis - MCP SDKs, Developer Experience, Use Cases, and the Road Ahead","links":["1-Official-py-and-ts-sdk-tutes/Blogs/blog-2","1-Official-py-and-ts-sdk-tutes/Blogs/blog-3","1-Official-py-and-ts-sdk-tutes/Blogs/blog-4","1-Official-py-and-ts-sdk-tutes/Blogs/blog-5","1-Official-py-and-ts-sdk-tutes/Blogs/blog-6","1-Official-py-and-ts-sdk-tutes/Blogs/blog-7","1-Official-py-and-ts-sdk-tutes/Blogs/blog-8","1-Official-py-and-ts-sdk-tutes/Blogs/blog-9"],"tags":[],"content":"Blog 10: Synthesis - MCP SDKs, Developer Experience, Use Cases, and the Road Ahead\nSeries: Deep Dive into the Model Context Protocol SDKs (TypeScript, Python, C#)\r\nPost: 10 of 10\nWe’ve reached the conclusion of our deep dive into the Model Context Protocol (MCP) SDKs! Over the past nine posts, we’ve journeyed from the foundational types and server APIs/internals, through the client architecture, explored various transports including Streamable HTTP, examined authentication strategies, and uncovered advanced capabilities.\nThe goal of MCP is ambitious: to create a universal language for applications to share context and capabilities with AI models, enabling truly integrated and intelligent assistance. The SDKs we’ve examined – for TypeScript, Python, and C# – are the crucial tools that make realizing this vision practical for developers across different ecosystems.\nIn this final post, we’ll synthesize our findings, comparing the overall developer experience (DX) offered by the three SDKs, mapping their features to specific application use cases, and offering some thoughts on the future of MCP development.\nRecapping the Core Philosophy &amp; Shared Ground\nAll three SDKs successfully abstract the core complexities of the MCP specification, providing developers with:\n\nProtocol Compliance: Handling JSON-RPC framing, message types, and lifecycle events.\nTransport Abstraction: Offering implementations for Stdio, HTTP-based communication (SSE/Streamable HTTP), and client-side WebSockets.\nPrimitive Management: Providing APIs to define and serve MCP Resources, Tools, and Prompts.\nAsynchronous Foundations: Built using modern async patterns native to each language (Node.js async/await, Python’s anyio, .NET’s async/await/Task).\n\nThey significantly lower the barrier to entry, allowing developers to focus on what context or capability to share, rather than the low-level how of the protocol exchange.\nEcosystem Reflections: How Language Influences Design\nWhile serving the same protocol, the SDKs showcase distinct design philosophies heavily influenced by their respective language ecosystems:\n\n\nTypeScript:\n\nStrengths: Explicit type safety (Zod), clear API boundaries (McpServer, Client, low-level Server), comprehensive built-in OAuth server, modern Streamable HTTP transport with resumability, explicit dynamic capability management.\nStyle: Explicit registration via methods, separate schema definitions (Zod), requires manual integration with web frameworks (e.g., Express).\nBest For: Node.js environments, web services needing high reliability/resumability, applications requiring standard OAuth server functionality out-of-the-box, developers preferring explicit registration over convention/inference.\n\n\n\nPython:\n\nStrengths: Highly ergonomic high-level API (FastMCP decorators), schema inference from type hints (Pydantic), seamless ASGI integration (sse_app), excellent CLI tooling (mcp dev/install) especially for Claude Desktop, flexible async via anyio.\nStyle: Pythonic decorators, relies on type hint inference, leverages ASGI ecosystem for web/auth middleware.\nBest For: Rapid prototyping, local tool development (especially for Claude Desktop), integrating MCP into existing Python/ASGI web applications, developers preferring convention and conciseness.\n\n\n\nC#:\n\nStrengths: Idiomatic .NET design, deep integration with Dependency Injection (IServiceCollection, IMcpServerBuilder) and Hosting (IHostedService), attribute-based discovery, strong typing via C# classes, supports Streamable HTTP alongside SSE, excellent ASP.NET Core integration (MapMcp), good performance potential. Integrates smoothly with Microsoft.Extensions.AI.\nStyle: Leverages .NET attributes and DI patterns, configuration via builder extensions, standard System.Text.Json.\nBest For: Enterprise .NET applications, ASP.NET Core web services, developers heavily invested in the Microsoft ecosystem, scenarios needing tight integration with other .NET libraries via DI.\n\n\n\nSummary Table:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFeatureTypeScriptPythonC#Primary HTTP Transport (Server)Streamable HTTP (Modern)HTTP+SSE (Legacy Spec)Streamable HTTP / SSEHigh-Level APIMcpServer (Methods)FastMCP (Decorators)Attributes + DI BuilderSchema/ValidationZod (Explicit)Pydantic (Type Hints)C# Classes + System.Text.JsonContext InjectionRequestHandlerExtra (Param)Context (Type Hint)DI + RequestContext (Param)Web Framework Int.Manual (e.g., Express)ASGI (Built-in)ASP.NET Core (Built-in)Built-in OAuth ServerYes (mcpAuthRouter)NoNoCLI ToolingBasicExcellent (mcp command)Standard dotnet toolingResumabilityYes (Streamable HTTP)NoYes (Streamable HTTP)Dynamic UpdatesYes (Handles)Less ExplicitLess ExplicitAutocompletionYes (Completable)NoNo\nDeveloper Experience (DX) - A Subjective Take\n\nFastest Start (Local/Claude Desktop): Python (FastMCP + mcp install).\nMost “Batteries Included” (Web Server): TypeScript (Streamable HTTP, OAuth) or C# (ASP.NET Core integration).\nMost “Pythonic”: Python (FastMCP decorators, anyio).\nMost “TypeScript-y”: TypeScript (Zod schemas, explicit registration).\nMost “.NET-y”: C# (DI, Hosting, Attributes).\nBest Type Safety: Arguably a tie, achieved differently (Compile-time TS vs. Runtime/Static Analysis Python/C#).\nMost Boilerplate (High-Level): Potentially TypeScript due to explicit schema definitions alongside code.\nMost Flexible Integration: Python (ASGI) and C# (ASP.NET Core / Generic Host) offer strong integration patterns.\n\nThe “best” DX depends heavily on the developer’s background and project context.\nMapping SDK Features to Use Cases\n\nClaude Desktop Plugins: Python’s mcp install makes it the clear winner for quickly adding local tools/resources. Stdio is the key transport.\nInternal Company Tools (Web):\n\nNeed Resumability/Long Tasks? TypeScript (Streamable HTTP) or C# (Streamable HTTP).\nNeed Standard OAuth? TypeScript (built-in) or C#/Python + external libraries/middleware.\nExisting ASP.NET Core Backend? C#.\nExisting Python/FastAPI/Starlette Backend? Python.\nExisting Node.js Backend? TypeScript.\n\n\nPublic MCP Services: Security is paramount. TypeScript’s built-in OAuth is a strong advantage. C# or Python require careful integration with robust authentication middleware. Streamable HTTP (TS/C#) offers better resilience.\nCLI Tools providing MCP context: Any SDK using Stdio server transport works well.\nCross-Platform Desktop Apps (non-Claude): Stdio transport in any SDK is viable. Packaging/deployment becomes the main challenge.\nAI Agent Frameworks: These might act as MCP clients. Any SDK client implementation could be used to connect to tools/resources exposed by MCP servers. C#‘s McpClientTool inheriting from AIFunction shows tight integration potential with frameworks like Microsoft.Extensions.AI.\n\nThe Road Ahead: MCP &amp; The SDKs\nMCP is laying the groundwork for a more interconnected and contextually aware AI future. The SDKs are evolving to make this practical. We might expect:\n\nTransport Convergence: Will Python adopt Streamable HTTP for parity with TS/C#? Will WebSocket server support become more prominent?\nFeature Parity: Features like built-in OAuth, resumability, autocompletion, and dynamic updates might become more consistent across SDKs over time.\nEnhanced Tooling: More sophisticated CLI tools, debugging aids, or testing utilities could emerge.\nSpecification Growth: As the MCP specification evolves (e.g., new primitives, refined transport rules), the SDKs will need to adapt.\nCommunity Adoption: Wider adoption will drive more examples, third-party libraries, and potentially contributions back to the core SDKs.\nPerformance Optimizations: As usage scales, performance tuning for transports and message handling will become more important.\n\nFinal Thoughts\nThe Model Context Protocol SDKs for TypeScript, Python, and C# provide developers with powerful, idiomatic tools to build the next generation of context-aware AI applications. While built on the same core protocol specification, they offer distinct developer experiences shaped by their respective language ecosystems and feature sets.\n\nTypeScript shines with its modern Streamable HTTP transport, robust built-in OAuth server capabilities, and explicit dynamic updates.\nPython offers exceptional developer ergonomics through FastMCP’s decorators, seamless ASGI integration, and unparalleled CLI tooling for local development and Claude Desktop.\nC# provides a deeply integrated experience within the .NET ecosystem, leveraging dependency injection, hosting, attributes, and strong ASP.NET Core support for both SSE and Streamable HTTP.\n\nThe choice of SDK depends on your project’s language, target platform, and specific feature requirements. But regardless of the choice, these SDKs effectively abstract the protocol’s complexities, empowering developers to focus on creating valuable, contextual connections between applications and the burgeoning world of Large Language Models. The foundation is laid; the future of context-aware AI awaits.\nThank you for following this series! We hope this deep dive has provided valuable insights into the inner workings and design of the MCP SDKs.\n\nTypeScript SDK Repository\nPython SDK Repository\nC# SDK Repository\nMCP Specification\n\n"},"1-Official-py-and-ts-sdk-tutes/Blogs/blog-2":{"slug":"1-Official-py-and-ts-sdk-tutes/Blogs/blog-2","filePath":"1 Official py and ts sdk tutes/Blogs/blog-2.md","title":"Blog 2: The Lingua Franca - Defining MCP Types with Zod and Pydantic","links":["1-Official-py-and-ts-sdk-tutes/Blogs/blog-1"],"tags":[],"content":"Blog 2: The Lingua Franca - Defining MCP Types with Zod and Pydantic\nSeries: Deep Dive into the Model Context Protocol SDKs (TypeScript &amp; Python)\r\nPost: 2 of 10\nIn our previous post, we introduced the Model Context Protocol (MCP) and its official TypeScript and Python SDKs. We saw how MCP aims to bridge the context gap for LLMs by providing a standard way for applications (servers) and AI clients to communicate.\nAt the heart of any protocol lies its message structure – the precise format of requests, responses, and notifications exchanged between participants. Defining this structure rigorously is crucial for ensuring interoperability, reliability, and developer sanity. A mismatch in expected data fields or types can lead to silent failures or cryptic errors.\nThis is where schema definition and validation libraries shine. The MCP SDKs leverage two popular choices: Zod for TypeScript and Pydantic for Python. In this post, we’ll dive into src/types.ts and src/mcp/types.py to see how these libraries are used to meticulously define the MCP “language.”\nFoundation: JSON-RPC 2.0\nMCP builds upon the well-established JSON-RPC 2.0 specification. This provides the basic message framing:\n\nRequest: Contains jsonrpc: &quot;2.0&quot;, a method (string), optional params (object or array), and a unique id. Expects a Response.\nResponse: Contains jsonrpc: &quot;2.0&quot;, the id matching the Request, and either a result (on success) or an error object (on failure).\nNotification: Contains jsonrpc: &quot;2.0&quot;, a method, and optional params. Does not have an id and does not expect a Response.\nError Object: Contains a code (integer), a message (string), and optional data.\n\nThe SDKs define schemas for these fundamental JSON-RPC structures first, then build the specific MCP messages upon them.\nTypeScript &amp; Zod: Fluent Schema Building\nThe TypeScript SDK (src/types.ts) uses Zod, a TypeScript-first schema declaration and validation library known for its fluent, chainable API.\nCore JSON-RPC Schemas:\nZod’s API makes defining these straightforward:\n// src/types.ts (Simplified)\nimport { z } from &quot;zod&quot;;\n \nexport const JSONRPC_VERSION = &quot;2.0&quot;;\nexport const RequestIdSchema = z.union([z.string(), z.number().int()]);\n \n// Base for requests (method + optional params)\nexport const RequestSchema = z.object({\n  method: z.string(),\n  params: z.optional(z.object({}).passthrough()), // Allows extra params fields\n});\n \n// Full JSON-RPC Request object schema\nexport const JSONRPCRequestSchema = z\n  .object({\n    jsonrpc: z.literal(JSONRPC_VERSION), // Ensures the value is exactly &quot;2.0&quot;\n    id: RequestIdSchema,\n  })\n  .merge(RequestSchema) // Combines base fields\n  .strict(); // Disallows unrecognized keys at the top level\n \n// Similarly for NotificationSchema, ResponseSchema, ErrorSchema...\nKey Zod Features Used:\n\nz.object({...}): Defines object shapes.\nz.string(), z.number(), z.boolean(), z.array(...): Basic type definitions.\nz.literal(...): Ensures a field has an exact value (like &quot;2.0&quot; or a specific method name).\nz.union([...]): Allows a field to be one of several types (e.g., RequestId).\nz.enum([...]): Defines allowed string values (e.g., LoggingLevel).\n.optional() / z.optional(...): Marks fields as optional.\n.extend({...}): Creates a new schema by adding fields to an existing one (used heavily for specific MCP request/notification types).\n.merge(...): Combines schemas.\n.passthrough(): Allows objects within params or result to have extra, undefined keys (important for extensibility).\n.strict(): Ensures the top-level JSON-RPC message structure doesn’t have unexpected keys.\nz.infer&lt;typeof Schema&gt;: Zod’s killer feature – automatically derives static TypeScript types from the schema definition.\n\nBuilding MCP Types:\nSpecific MCP requests/notifications extend the base schemas:\n// src/types.ts (Example: InitializeRequest)\nexport const InitializeRequestSchema = RequestSchema.extend({ // Extends base Request\n  method: z.literal(&quot;initialize&quot;), // Specific method\n  params: BaseRequestParamsSchema.extend({ // Extends base params\n    protocolVersion: z.string(),\n    capabilities: ClientCapabilitiesSchema,\n    clientInfo: ImplementationSchema,\n  }),\n});\n \n// Example: TextContent within messages\nexport const TextContentSchema = z\n  .object({\n    type: z.literal(&quot;text&quot;),\n    text: z.string(),\n  })\n  .passthrough(); // Allow annotations etc.\n \n// Example: Union type for message content\nexport const PromptMessageSchema = z\n  .object({\n    role: z.enum([&quot;user&quot;, &quot;assistant&quot;]),\n    content: z.union([ // Can be text, image, audio, or resource\n      TextContentSchema,\n      ImageContentSchema,\n      AudioContentSchema,\n      EmbeddedResourceSchema,\n    ]),\n  })\n  .passthrough();\nZod’s fluent API allows complex types to be built compositionally. The use of .passthrough() on nested objects like params and content provides flexibility, while .strict() on the main JSONRPCRequestSchema ensures the core protocol framing is correct.\nPython &amp; Pydantic: Leveraging Type Hints\nThe Python SDK (src/mcp/types.py) uses Pydantic, which leverages Python’s native type hints to define data models and perform validation.\nCore JSON-RPC Models:\nPydantic models are defined using standard Python classes and type annotations:\n# src/mcp/types.py (Simplified)\nfrom typing import Any, Generic, Literal, TypeAlias, TypeVar\nfrom pydantic import BaseModel, ConfigDict, Field, RootModel\n \nJSONRPC_VERSION: Literal[&quot;2.0&quot;] = &quot;2.0&quot;\nRequestId = str | int # Union using standard Python syntax\n \nRequestParamsT = TypeVar(&quot;RequestParamsT&quot;, bound=dict[str, Any] | None)\nMethodT = TypeVar(&quot;MethodT&quot;, bound=str)\n \n# Base for requests\nclass Request(BaseModel, Generic[RequestParamsT, MethodT]):\n    method: MethodT\n    params: RequestParamsT\n    # Allows extra fields on the model instance itself\n    model_config = ConfigDict(extra=&quot;allow&quot;)\n \n# Full JSON-RPC Request object model\nclass JSONRPCRequest(Request[dict[str, Any] | None, str]):\n    jsonrpc: Literal[JSONRPC_VERSION]\n    id: RequestId\n    method: str\n    params: dict[str, Any] | None = None\n    # No .strict() equivalent needed at top level by default\n \n# Similarly for Notification, JSONRPCResponse, ErrorData, JSONRPCError...\nKey Pydantic Features Used:\n\nBaseModel: The base class for all Pydantic models.\nType Hinting: Standard Python type hints (str, int, list[str], dict[str, Any], Literal[...], | for Union, Annotated) define the schema.\nField(...): Used to add metadata like descriptions, defaults, constraints (though less common in types.py itself, more in FastMCP).\nConfigDict(extra=&quot;allow&quot;): Explicitly configured on every model to allow extra fields, crucial for MCP’s extensibility (especially within params, result, and content blocks).\nRootModel[...]: Used to represent top-level Union types, like JSONRPCMessage itself, which can be one of several distinct structures.\nAutomatic Type Inference: Pydantic models are the types; no separate inference step is needed.\n\nBuilding MCP Types:\nSpecific MCP types inherit from base Pydantic models or use standard Python typing:\n# src/mcp/types.py (Example: InitializeRequest)\n \nclass InitializeRequestParams(RequestParams): # Inherits RequestParams\n    protocolVersion: str | int\n    capabilities: ClientCapabilities\n    clientInfo: Implementation\n    model_config = ConfigDict(extra=&quot;allow&quot;)\n \nclass InitializeRequest(Request[InitializeRequestParams, Literal[&quot;initialize&quot;]]):\n    method: Literal[&quot;initialize&quot;]\n    params: InitializeRequestParams\n \n# Example: TextContent within messages\nclass TextContent(BaseModel):\n    type: Literal[&quot;text&quot;]\n    text: str\n    annotations: Annotations | None = None\n    model_config = ConfigDict(extra=&quot;allow&quot;)\n \n# Example: Union type for message content (defined via standard typing)\nclass PromptMessage(BaseModel):\n    role: Role # Role is Literal[&quot;user&quot;, &quot;assistant&quot;]\n    content: TextContent | ImageContent | EmbeddedResource # Standard union type\n    model_config = ConfigDict(extra=&quot;allow&quot;)\nPydantic’s approach feels very integrated with Python’s type system. The explicit ConfigDict(extra=&quot;allow&quot;) on every model ensures the necessary flexibility for MCP’s passthrough fields. RootModel is used effectively for top-level unions like JSONRPCMessage.\nComparison: Zod vs. Pydantic for MCP\nBoth libraries achieve the goal of defining and validating the MCP structure effectively, but their approaches differ:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFeatureZod (TypeScript)Pydantic (Python)Notes for MCPSyntaxFluent, chainable methodsClass definitions, type hintsZod feels more like building a schema object; Pydantic feels like defining data classes.Type SafetyExcellent, via z.inferExcellent, via type hints &amp; validationBoth provide strong compile-time (TS) or runtime (Python) safety.Unionsz.union([...])`TypeATypeBorRootModel[…]`Extensibility.extend({...}), .merge(...)Class InheritanceBoth offer clear ways to build specific types from bases.Strictness.strict() controls top-level keysConfigDict(extra=&#039;...&#039;) controls fieldsMCP needs extra=&#039;allow&#039; widely (for params, result, _meta, content blocks), making Pydantic’s explicit config necessary on almost every model. Zod’s .passthrough() serves a similar purpose for nested objects.EcosystemNative to TypeScriptStandard in modern Python data validationBoth are excellent choices within their respective ecosystems.\nFor MCP, both work well. Zod’s explicit chaining might make the construction process clearer in some complex cases, while Pydantic’s reliance on standard type hints makes the Python code feel very natural. The need for widespread extra=&#039;allow&#039; in the Python models is a direct consequence of MCP’s design allowing arbitrary extra data in many places.\nKey MCP Type Examples (Side-by-Side)\nLet’s look at a couple of key types:\nInitializeRequest:\n\nTypeScript (Zod):\nexport const InitializeRequestSchema = RequestSchema.extend({\n  method: z.literal(&quot;initialize&quot;),\n  params: BaseRequestParamsSchema.extend({\n    protocolVersion: z.string(),\n    capabilities: ClientCapabilitiesSchema,\n    clientInfo: ImplementationSchema,\n  }),\n});\n\nPython (Pydantic):\nclass InitializeRequestParams(RequestParams):\n    protocolVersion: str | int\n    capabilities: ClientCapabilities\n    clientInfo: Implementation\n    model_config = ConfigDict(extra=&quot;allow&quot;)\n \nclass InitializeRequest(Request[InitializeRequestParams, Literal[&quot;initialize&quot;]]):\n    method: Literal[&quot;initialize&quot;]\n    params: InitializeRequestParams\n\n\nTool:\n\nTypeScript (Zod):\nexport const ToolSchema = z\n  .object({\n    name: z.string(),\n    description: z.optional(z.string()),\n    inputSchema: z.object({ // Simplified representation here\n        type: z.literal(&quot;object&quot;),\n        properties: z.optional(z.object({}).passthrough()),\n      }).passthrough(),\n    annotations: z.optional(ToolAnnotationsSchema),\n  })\n  .passthrough();\n\nPython (Pydantic):\nclass Tool(BaseModel):\n    name: str\n    description: str | None = None\n    inputSchema: dict[str, Any] # JSON Schema object\n    # Note: Python SDK&#039;s FastMCP generates this dynamically\n    model_config = ConfigDict(extra=&quot;allow&quot;)\n(Note: The Python SDK’s higher-level FastMCP often generates the inputSchema dynamically from function signatures, whereas the base type just expects a dict conforming to JSON Schema).\n\nWhy Strong Typing Matters for the End User\nIt might seem like internal plumbing, but the rigorous type definitions provided by Zod and Pydantic directly impact the end-user experience:\n\nReliability: Validated messages mean fewer communication errors between the client and server, leading to more stable and predictable application behavior. Users encounter fewer unexpected crashes or hangs caused by malformed data.\nConsistency: Tools and Resources exposed by different servers behave predictably because they adhere to the same defined structures for inputs (params) and outputs (result). An ImageContent block always contains type, data, and mimeType.\nSecurity: While not a replacement for security measures, validating input prevents certain classes of injection or unexpected data processing bugs that could arise from malformed requests.\nDeveloper Velocity: For developers using the SDKs, strong typing provides better autocompletion and catches errors earlier, leading to faster development of robust MCP applications, which ultimately benefits users with more features and quicker bug fixes.\n\nConclusion\nThe heart of the MCP SDKs lies in their meticulously defined type schemas using Zod (TypeScript) and Pydantic (Python). These schemas ensure that communication adheres strictly to the MCP specification, providing a reliable foundation for building both clients and servers. While the syntax differs – Zod’s fluent chaining versus Pydantic’s type-hint-driven classes – both libraries effectively model the protocol’s structure, including its need for extensibility via extra fields.\nUnderstanding these type definitions is fundamental to grasping how the SDKs operate. In the next post, we’ll move up a layer and explore the high-level server APIs – McpServer (TS) and FastMCP (Python) – which make building MCP servers significantly easier.\n"},"1-Official-py-and-ts-sdk-tutes/Blogs/blog-3":{"slug":"1-Official-py-and-ts-sdk-tutes/Blogs/blog-3","filePath":"1 Official py and ts sdk tutes/Blogs/blog-3.md","title":"Blog 3: Building MCP Servers the Easy Way: McpServer (TS) vs. FastMCP (Python)","links":["1-Official-py-and-ts-sdk-tutes/Blogs/blog-2"],"tags":[],"content":"Blog 3: Building MCP Servers the Easy Way: McpServer (TS) vs. FastMCP (Python)\nSeries: Deep Dive into the Model Context Protocol SDKs (TypeScript &amp; Python)\r\nPost: 3 of 10\nIn the previous post, we explored the type systems (Zod and Pydantic) that define the precise language of the Model Context Protocol (MCP) within the TypeScript and Python SDKs. These types ensure reliable communication, but directly implementing the request/response handling logic for every MCP method can still be complex.\nThis is where the high-level server APIs come in. Both SDKs offer abstractions designed to drastically simplify the process of creating MCP servers. Developers can focus on what functionality (Tools) or data (Resources, Prompts) they want to expose, letting the SDK handle the underlying protocol boilerplate.\nToday, we’ll compare the primary high-level server abstractions:\n\nTypeScript: The McpServer class (src/server/mcp.ts)\nPython: The FastMCP class (src/mcp/server/fastmcp/server.py)\n\nTypeScript: Declarative Registration with McpServer\nThe TypeScript SDK provides the McpServer class, which wraps the lower-level Server (more on that in the next post). Its core philosophy is declarative registration using specific methods for each MCP primitive.\nInitialization:\n// TypeScript\nimport { McpServer } from &quot;@modelcontextprotocol/sdk/server/mcp.js&quot;;\nimport { StdioServerTransport } from &quot;@modelcontextprotocol/sdk/server/stdio.js&quot;;\n \n// Create the server instance\nconst mcpServer = new McpServer({\n  name: &quot;MyTypeScriptServer&quot;,\n  version: &quot;1.0.0&quot;\n}, {\n  // Optional: Define server capabilities upfront\n  capabilities: {\n    logging: {}, // Enable logging capability\n    // resources, tools, prompts capabilities are often added\n    // implicitly when you register items below.\n  }\n});\nRegistering Primitives:\nYou add functionality by calling methods on the mcpServer instance:\n\n\nTools (.tool()):\n\nExposes functions as callable actions for the LLM client.\nHandles input validation using Zod schemas.\nSupports overloads for descriptions and annotations (hints about the tool’s behavior).\n\nimport { z } from &quot;zod&quot;;\n \n// Tool with no arguments\nmcpServer.tool(&quot;get_time&quot;, async () =&gt; ({\n  content: [{ type: &quot;text&quot;, text: new Date().toISOString() }]\n}));\n \n// Tool with description and Zod schema for arguments\nconst bmiTool = mcpServer.tool(\n  &quot;calculate_bmi&quot;, // Name\n  &quot;Calculates Body Mass Index&quot;, // Description\n  { // Zod schema for arguments\n    weightKg: z.number().describe(&quot;Weight in kilograms&quot;),\n    heightM: z.number().describe(&quot;Height in meters&quot;)\n  },\n  { // Optional Annotations\n     title: &quot;BMI Calculator&quot;,\n     readOnlyHint: true // This tool doesn&#039;t change anything\n  },\n  // Async callback function receiving validated arguments\n  async ({ weightKg, heightM }) =&gt; {\n    const bmi = weightKg / (heightM * heightM);\n    return { content: [{ type: &quot;text&quot;, text: String(bmi) }] };\n  }\n);\n\n\nResources (.resource()):\n\nExposes data to the LLM client.\nCan be a static resource (fixed URI) or dynamic (using ResourceTemplate).\nCallbacks receive URI details and matched template variables.\n\nimport { ResourceTemplate } from &quot;@modelcontextprotocol/sdk/server/mcp.js&quot;;\n \n// Static resource\nmcpServer.resource(\n  &quot;app_config&quot;, // Internal name\n  &quot;config://myapp&quot;, // Fixed URI\n  { mimeType: &quot;application/json&quot; }, // Metadata\n  async (uri) =&gt; ({ // Callback\n    contents: [{ uri: uri.href, text: JSON.stringify({ theme: &quot;dark&quot; }) }]\n  })\n);\n \n// Dynamic resource using a template\nconst userProfileResource = mcpServer.resource(\n  &quot;user_profile&quot;, // Internal name\n  new ResourceTemplate(&quot;users://{userId}/profile&quot;), // URI Template\n  { description: &quot;Fetches user profile data&quot; }, // Metadata\n  // Callback receives URI and matched &#039;userId&#039; variable\n  async (uri, { userId }) =&gt; {\n    // const profileData = await fetchUserProfileFromDB(userId);\n    const profileData = `Profile for ${userId}`;\n    return { contents: [{ uri: uri.href, text: profileData }] };\n  }\n);\n\n\nPrompts (.prompt()):\n\nDefines reusable interaction templates.\nCan accept arguments defined by a Zod schema.\nCallback returns a list of PromptMessage objects.\n\n// Prompt without arguments\nmcpServer.prompt(&quot;help_overview&quot;, async () =&gt; ({\n  messages: [{ role: &quot;user&quot;, content: { type: &quot;text&quot;, text: &quot;Provide a general overview of help topics.&quot; } }]\n}));\n \n// Prompt with arguments\nconst codeReviewPrompt = mcpServer.prompt(\n  &quot;review_code&quot;, // Name\n  &quot;Generates a code review request&quot;, // Description\n  { code: z.string().describe(&quot;The code snippet to review&quot;) }, // Zod Schema\n  // Callback receives validated &#039;code&#039; argument\n  ({ code }) =&gt; ({\n    messages: [{\n      role: &quot;user&quot;,\n      content: { type: &quot;text&quot;, text: `Please review this code:\\n\\n${code}` }\n    }]\n  })\n);\n\n\nDynamic Updates:\nA key feature highlighted in the TS SDK documentation is the ability to modify the server after it has connected to a transport. The .tool(), .resource(), and .prompt() methods return handles (RegisteredTool, etc.) that have methods like .enable(), .disable(), .update(...), and .remove(). Calling these automatically triggers listChanged notifications to connected clients.\n// Example: Disable the BMI tool initially\nbmiTool.disable();\n \n// Later... enable it based on some condition\nif (userHasPremiumAccess) {\n  bmiTool.enable(); // Client gets notified\n}\n \n// Update the prompt&#039;s callback or schema\ncodeReviewPrompt.update({ /* new options */ });\n \n// Remove a resource entirely\nuserProfileResource.remove();\nConnecting:\nFinally, the server needs to be connected to a transport (details in later posts):\n// Example using Stdio\nconst transport = new StdioServerTransport();\nawait mcpServer.connect(transport); // Starts listening\nPython: Ergonomic Decorators with FastMCP\nThe Python SDK introduces FastMCP (src/mcp/server/fastmcp/server.py), designed for a more Pythonic, developer-friendly experience using decorators. It wraps the lower-level Server internally.\nInitialization:\n# Python\nfrom mcp.server.fastmcp import FastMCP, Context\n \n# Create the server instance\n# Settings can be passed here or via env vars (FASTMCP_*)\nmcp = FastMCP(\n    name=&quot;MyPythonServer&quot;,\n    instructions=&quot;Server usage instructions...&quot;,\n    dependencies=[&quot;pandas&quot;] # Optional: Declare runtime dependencies\n)\nRegistering Primitives:\nFastMCP uses decorators applied directly to your Python functions:\n\n\nTools (@mcp.tool()):\n\nDecorated functions become MCP tools.\nPython type hints are automatically parsed (using Pydantic via func_metadata) to generate the inputSchema. Pydantic Field can be used for descriptions/defaults.\nOptional Context object can be injected via type hint for access to logging, progress, etc.\n\nfrom typing import Annotated\nfrom pydantic import Field\n \n# Basic tool\n@mcp.tool()\ndef add(a: int, b: int) -&gt; int:\n    &quot;&quot;&quot;Adds two numbers together.&quot;&quot;&quot; # Docstring becomes description\n    return a + b\n \n# Tool with Field descriptions and context injection\n@mcp.tool()\ndef complex_tool(\n    query: Annotated[str, Field(description=&quot;The search query&quot;)],\n    limit: int = 10,\n    ctx: Context | None = None # Context injection via type hint\n) -&gt; list[str]:\n    &quot;&quot;&quot;Performs a complex search.&quot;&quot;&quot;\n    if ctx:\n        ctx.info(f&quot;Running search for &#039;{query}&#039; with limit {limit}&quot;)\n    # ... perform search ...\n    return [&quot;result1&quot;, &quot;result2&quot;]\n\n\nResources (@mcp.resource()):\n\nDecorated functions provide resource content.\nThe decorator takes the URI (static or template).\nFunction parameters must match URI template parameters if it’s dynamic.\nReturn type determines content (str → text, bytes → binary, others → JSON).\n\n# Static resource\n@mcp.resource(&quot;config://myapp&quot;, mime_type=&quot;application/json&quot;)\ndef get_config() -&gt; dict:\n    &quot;&quot;&quot;Returns application configuration.&quot;&quot;&quot;\n    return {&quot;theme&quot;: &quot;dark&quot;}\n \n# Dynamic resource (template)\n@mcp.resource(&quot;users://{user_id}/profile&quot;)\ndef get_user_profile(user_id: str) -&gt; str: # &#039;user_id&#039; matches URI\n    &quot;&quot;&quot;Fetches profile data for a specific user.&quot;&quot;&quot;\n    # profile_data = db.fetch_user(user_id)\n    return f&quot;Profile data for user {user_id}&quot;\n\n\nPrompts (@mcp.prompt()):\n\nDecorated functions generate prompt messages.\nFunction parameters define prompt arguments.\nCan return strings, Message objects, or lists thereof.\n\nfrom mcp.server.fastmcp.prompts import UserMessage, AssistantMessage\n \n# Basic prompt returning a string\n@mcp.prompt()\ndef basic_greeting(name: str) -&gt; str:\n    &quot;&quot;&quot;Generates a simple greeting prompt.&quot;&quot;&quot;\n    return f&quot;Please greet {name} warmly.&quot;\n \n# Prompt returning structured messages\n@mcp.prompt()\ndef multi_turn_debug(error_log: str) -&gt; list[Message]:\n    &quot;&quot;&quot;Starts a debugging session.&quot;&quot;&quot;\n    return [\n        UserMessage(f&quot;I encountered this error:\\n{error_log}&quot;),\n        AssistantMessage(&quot;Okay, I can help. What steps did you take before this error occurred?&quot;)\n    ]\n\n\nLifespan Management:\nFastMCP supports ASGI-style lifespan context managers for setup/teardown logic:\nfrom contextlib import asynccontextmanager\nfrom collections.abc import AsyncIterator\n \n@dataclass\nclass AppState:\n    db_connection: Any # Your DB connection type\n \n@asynccontextmanager\nasync def app_lifespan(server: FastMCP) -&gt; AsyncIterator[AppState]:\n    print(&quot;Server startup: Connecting to DB...&quot;)\n    # connection = await connect_db()\n    connection = &quot;fake_db_connection&quot;\n    state = AppState(db_connection=connection)\n    try:\n        yield state # State is accessible via ctx.request_context.lifespan_context\n    finally:\n        print(&quot;Server shutdown: Disconnecting DB...&quot;)\n        # await connection.close()\n \nmcp = FastMCP(&quot;MyAppWithLifespan&quot;, lifespan=app_lifespan)\n \n# Tool accessing lifespan state\n@mcp.tool()\ndef query_data(query: str, ctx: Context) -&gt; list:\n    db_conn = ctx.request_context.lifespan_context.db_connection\n    # results = await db_conn.fetch(query)\n    print(f&quot;Querying with {db_conn}: {query}&quot;)\n    return [{&quot;result&quot;: &quot;dummy&quot;}]\nRunning:\nFastMCP provides a simple run() method:\nif __name__ == &quot;__main__&quot;:\n    mcp.run() # Defaults to stdio transport\n    # Or: mcp.run(transport=&quot;sse&quot;)\nComparison: McpServer vs. FastMCP\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFeatureMcpServer (TypeScript)FastMCP (Python)NotesRegistration StyleMethod calls (.tool(), .resource())Decorators (@mcp.tool(), @mcp.resource())TS uses explicit registration; Python leverages decorators for a more concise, idiomatic feel.Parameter HandlingExplicit Zod SchemasType Hint Inference + Pydantic FieldTS requires defining schemas separately; Python infers schemas from function signatures, potentially faster for simple cases but might hide complexity.Context AccessPassed via RequestHandlerExtra (low-level)Optional Context injection via type hintPython’s FastMCP provides a dedicated, user-friendly Context object directly in the high-level API.Dynamic UpdatesExplicit via handles (.enable(), .update())Less emphasized in docs/examples for FastMCPTS API makes post-connection updates explicit. Python’s FastMCP might require interacting with the underlying low-level server or managers for this.ConfigurationConstructor optionsSettings model, env vars, constructor kwargsPython offers more flexible configuration via Pydantic settings and environment variables.Dependenciespackage.jsondependencies kwarg, pyproject.tomlPython’s FastMCP allows declaring runtime dependencies needed by tools/resources directly.Web IntegrationRequires manual Express/etc. setupBuilt-in ASGI app (sse_app()), Uvicorn integrationFastMCP provides easier integration with the Python web ecosystem (ASGI).\nEnd-User Impact: Streamlined Development = Richer AI\nWhy do these high-level APIs matter to someone using an MCP-powered application?\n\nFaster Integration: McpServer and FastMCP significantly reduce the effort needed for developers to expose application capabilities or data to LLMs. This means more applications can gain contextual AI features more quickly.\nConsistency: By providing structured ways to define tools and resources (schemas in TS, type hints/Pydantic in Python), the SDKs encourage consistent definitions, leading to more predictable behavior when an AI client interacts with different servers.\nFocus on Value: Developers spend less time on protocol plumbing and more time defining useful tools and relevant resources, resulting in AI assistants that are genuinely more helpful and context-aware.\nEnabling Complex Apps: Features like context injection and lifespan management (especially prominent in FastMCP) make it feasible to build sophisticated servers that manage state or external connections, unlocking more powerful use cases for the end-user’s AI.\n\nConclusion\nBoth McpServer (TypeScript) and FastMCP (Python) serve as powerful, developer-friendly gateways to building MCP servers. They abstract away much of the underlying protocol complexity, allowing developers to focus on exposing functionality and data. While TypeScript’s McpServer uses explicit method calls and Zod schemas, Python’s FastMCP leans into decorators and type-hint inference for a more concise, Pythonic feel. Both successfully lower the barrier to entry for creating context-aware AI applications.\nWhile these high-level APIs are sufficient for many use cases, sometimes finer control is needed. In the next post, we’ll lift the hood and examine the lower-level Server classes in both SDKs to understand the core protocol handling and explore more advanced customization options.\n"},"1-Official-py-and-ts-sdk-tutes/Blogs/blog-4":{"slug":"1-Official-py-and-ts-sdk-tutes/Blogs/blog-4","filePath":"1 Official py and ts sdk tutes/Blogs/blog-4.md","title":"Blog 4: Under the Hood - The MCP Server Core (TypeScript & Python)","links":["1-Official-py-and-ts-sdk-tutes/Blogs/blog-3"],"tags":[],"content":"Blog 4: Under the Hood - The MCP Server Core (TypeScript &amp; Python)\nSeries: Deep Dive into the Model Context Protocol SDKs (TypeScript &amp; Python)\r\nPost: 4 of 10\nIn Blog 3, we explored the convenient high-level server APIs, McpServer (TypeScript) and FastMCP (Python), which significantly simplify building Model Context Protocol (MCP) servers. These APIs are excellent for many use cases, providing easy ways to register Tools, Resources, and Prompts.\nHowever, sometimes you need more granular control, want to implement custom protocol extensions, or simply wish to understand the fundamental mechanics of the SDK. For this, we need to dive beneath the high-level wrappers and explore the foundational server components.\nThis post peels back the abstraction layer to examine:\n\nThe core Server classes in both SDKs.\nThe underlying Protocol (TS) and BaseSession (Python) classes that manage the actual MCP communication logic.\nHow these lower-level APIs provide maximum flexibility at the cost of some convenience.\n\nWhy Go Low-Level?\nBefore diving in, why would you bypass the user-friendly McpServer or FastMCP?\n\nMaximum Control: Directly handle specific MCP request methods or notifications with custom logic beyond the standard primitives.\nCustom Extensions: Implement experimental or non-standard MCP methods or capabilities.\nFine-Grained Management: Control exactly how requests are processed, perhaps integrating with complex application state or external systems in ways not easily accommodated by the high-level wrappers.\nIntegration: Embed MCP handling deeply within an existing application or framework where the high-level API structure might be restrictive.\nUnderstanding: Gain a deeper appreciation for how the SDK functions internally.\n\nTypeScript: The Server and Protocol Foundation\nIn the TypeScript SDK, the foundation consists of two key classes:\n\nProtocol (src/shared/protocol.ts): This is the base class responsible for the core MCP logic, independent of whether it’s a client or server. It handles:\n\nConnecting to a Transport.\nManaging JSON-RPC message framing (requests, responses, notifications).\nMatching request IDs to responses.\nHandling timeouts (with DEFAULT_REQUEST_TIMEOUT_MSEC) and cancellation (notifications/cancelled).\nProcessing progress notifications (notifications/progress).\nProviding request() and notification() methods for sending messages.\nAbstract methods for capability assertions (assertCapabilityForMethod, etc.).\n\n\nServer (src/server/index.ts): This class extends Protocol and specializes it for server-side operation. It implements the server-specific capability checks and primarily exposes methods for registering handlers.\n\nWorking with the Low-Level Server:\nInstead of methods like .tool() or .resource(), you interact with the low-level Server primarily through setRequestHandler and setNotificationHandler.\n// TypeScript Low-Level Server Example\nimport { Server } from &quot;@modelcontextprotocol/sdk/server/index.js&quot;;\nimport { StdioServerTransport } from &quot;@modelcontextprotocol/sdk/server/stdio.js&quot;;\nimport {\n  ListPromptsRequestSchema, // Import specific Zod schema\n  ListPromptsResult,\n  McpError,\n  ErrorCode,\n  JSONRPCRequest,\n  ServerCapabilities,\n  Prompt,\n  // ... other necessary types\n} from &quot;@modelcontextprotocol/sdk/types.js&quot;;\nimport { RequestHandlerExtra } from &quot;@modelcontextprotocol/sdk/shared/protocol.js&quot;;\n \n// 1. Instantiate the low-level Server\nconst lowLevelServer = new Server(\n  { name: &quot;LowLevelServer&quot;, version: &quot;1.0&quot; },\n  {\n    // Declare capabilities explicitly\n    capabilities: {\n      prompts: { listChanged: false } // We&#039;ll handle prompts\n    }\n  }\n);\n \n// 2. Register a request handler using a Zod schema\nlowLevelServer.setRequestHandler(\n  ListPromptsRequestSchema, // Schema for the request type\n  // Async handler function receiving the parsed request and extra context\n  async (request: z.infer&lt;typeof ListPromptsRequestSchema&gt;, extra: RequestHandlerExtra&lt;any, any&gt;): Promise&lt;ListPromptsResult&gt; =&gt; {\n    console.log(`Handling listPrompts request (ID: ${extra.requestId}, Session: ${extra.sessionId})`);\n \n    // Access cancellation signal\n    if (extra.signal.aborted) {\n      throw new McpError(ErrorCode.InternalError, &quot;Request was cancelled&quot;);\n    }\n \n    // Example: Implement logic to fetch prompts\n    const prompts: Prompt[] = [\n      { name: &quot;prompt1&quot;, description: &quot;First prompt&quot; }\n      // ... fetch or define prompts\n    ];\n \n    // Return the result conforming to ListPromptsResult schema\n    return { prompts };\n  }\n);\n \n// (Similarly, use setNotificationHandler for notifications)\n \n// 3. Connect to a transport\nconst transport = new StdioServerTransport();\nawait lowLevelServer.connect(transport); // Starts listening and handling\n \nconsole.log(&quot;Low-level server connected via stdio.&quot;);\nKey Takeaways (TS Low-Level):\n\nYou explicitly register handlers for specific MCP methods using their corresponding Zod schemas (ListPromptsRequestSchema, CallToolRequestSchema, etc.).\nHandler functions receive the validated request object (matching the schema) and an RequestHandlerExtra object containing metadata (signal, sessionId, requestId, authInfo) and methods to send related messages (sendNotification, sendRequest).\nYou are responsible for declaring the server’s capabilities correctly during instantiation.\nError handling involves throwing McpError or standard Errors, which the Protocol layer translates into JSON-RPC error responses.\n\nPython: The Server and BaseSession Core\nThe Python SDK follows a similar pattern, with BaseSession providing the core logic and the low-level Server specializing it.\n\nBaseSession (src/mcp/shared/session.py): Analogous to TS Protocol. Manages the connection state, message sending/receiving via memory streams provided by transports, request/response ID mapping, timeouts, and cancellation. It defines send_request and send_notification.\nServer (src/mcp/server/lowlevel/server.py): This class uses a ServerSession internally (created during the run method). It provides decorators (@server.call_tool(), @server.list_prompts(), etc.) to register handlers for specific MCP operations. Note: This low-level Server uses decorators, unlike the TS low-level Server which uses explicit handler registration methods.\n\nWorking with the Low-Level Server:\nEven the “low-level” Python Server uses decorators, making the registration process quite different from TypeScript’s low-level approach.\n# Python Low-Level Server Example\nimport anyio\nimport mcp.types as types\nfrom mcp.server.lowlevel import Server, NotificationOptions\nfrom mcp.server.models import InitializationOptions\nfrom mcp.server.stdio import stdio_server\nfrom mcp.shared.context import RequestContext # For type hinting context\n \n# 1. Instantiate the low-level Server\nlowLevelServer = Server(name=&quot;LowLevelPyServer&quot;, version=&quot;1.0&quot;)\n \n# 2. Register handlers using decorators\n@lowLevelServer.list_prompts()\nasync def handle_list_prompts() -&gt; list[types.Prompt]:\n    # Access context if needed (available during request handling)\n    try:\n        ctx: RequestContext[ServerSession, Any] = lowLevelServer.request_context\n        print(f&quot;Handling listPrompts request (ID: {ctx.request_id}, Session: {ctx.session})&quot;)\n    except LookupError:\n        print(&quot;Context not available outside request&quot;) # Should not happen here\n \n    prompts: list[types.Prompt] = [\n        types.Prompt(name=&quot;prompt1&quot;, description=&quot;First prompt&quot;)\n        # ... fetch or define prompts\n    ]\n    return prompts\n \n# Example Tool Handler\n@lowLevelServer.call_tool()\nasync def handle_call_tool(name: str, arguments: dict | None) -&gt; list[types.TextContent]:\n     ctx = lowLevelServer.request_context # Access context\n     print(f&quot;Calling tool &#039;{name}&#039; for request {ctx.request_id}&quot;)\n     if name == &quot;echo&quot;:\n         return [types.TextContent(type=&quot;text&quot;, text=f&quot;Echo: {arguments.get(&#039;msg&#039;, &#039;&#039;)}&quot;)]\n     raise ValueError(f&quot;Unknown tool: {name}&quot;)\n \n# (Similarly for @server.read_resource, @server.get_prompt, etc.)\n \n# 3. Run the server with a transport\nasync def main():\n    init_options = lowLevelServer.create_initialization_options(\n        notification_options=NotificationOptions(), # Define notification capabilities\n        experimental_capabilities={}\n    )\n    async with stdio_server() as (read_stream, write_stream):\n        await lowLevelServer.run(read_stream, write_stream, init_options)\n \nif __name__ == &quot;__main__&quot;:\n    anyio.run(main)\nKey Takeaways (Python Low-Level):\n\nHandler registration still uses decorators, even on the low-level Server, making it feel somewhat similar to FastMCP but requiring manual handling of result types (e.g., returning list[types.Tool] instead of just tool info).\nRequest context (RequestContext) is accessed via server.request_context during the execution of a handler.\nYou manually create InitializationOptions including ServerCapabilities.\nThe core session logic lives within ServerSession, which is managed internally by Server.run().\n\nCore Logic: Protocol (TS) &amp; BaseSession (Python)\nBeneath the Server classes lie the true engines: Protocol (TS) and BaseSession (Python). These abstract base classes implement the state machine and logic for reliable MCP communication over any transport.\nShared Responsibilities:\n\nTransport Abstraction: They take read/write streams (from a Transport in TS, or directly from transport functions like stdio_server in Python) and handle message framing.\nJSON-RPC Compliance: Parsing incoming messages, validating against expected JSON-RPC structure.\nRequest/Response Matching: Generating unique request IDs and correlating incoming responses/errors back to the original outgoing request using the id field.\nTimeout Management: Implementing the request timeout logic (using setTimeout in TS, likely anyio.fail_after or equivalent in Python). Handling resetTimeoutOnProgress and maxTotalTimeout.\nCancellation: Sending notifications/cancelled when a request’s AbortSignal (TS) or CancelScope (Python) is triggered, and handling incoming cancellation notifications to abort in-flight request handlers.\nProgress Notifications: Handling incoming notifications/progress and routing them to the correct request’s onprogress callback (TS). Python’s ServerSession has send_progress_notification, implying progress is handled within the request implementation itself.\nError Handling: Catching errors during request handling and formatting them into JSONRPCError responses. Handling incoming JSONRPCError responses and rejecting the corresponding request promise/future.\n\nBy encapsulating this core logic, Protocol/BaseSession allows the Server classes (and the transport implementations) to focus on their specific roles.\nComparison: Low-Level APIs\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFeatureServer/Protocol (TypeScript)Server/BaseSession (Python)NotesHandler RegistrationsetRequest/NotificationHandler (explicit)Decorators (@server.call_tool, etc.)TS is more explicit, requires Zod schemas. Python uses decorators, feels closer to FastMCP.Base ClassProtocol (shared client/server)BaseSession (shared client/server)Similar role, different naming.Context AccessRequestHandlerExtra (passed to handler)server.request_context (accessed in handler)TS passes context data explicitly. Python uses a context variable pattern typical in async frameworks.Core LogicProtocol classBaseSession classBoth handle JSON-RPC, timeouts, cancellation, progress (though progress handling seems more explicit in TS).Capability ConfigPassed to Server constructorPassed to Server.run via InitializationOptionsConfiguration point differs slightly.\nConclusion: Power and Responsibility\nThe low-level Server APIs in both the TypeScript and Python MCP SDKs provide the foundational layer upon which the higher-level abstractions are built. They offer maximum flexibility and control, allowing developers to interact directly with the core MCP message flow and implement custom behaviors.\n\nTypeScript’s Server demands explicit handler registration using Zod schemas, offering strong type safety at the cost of more boilerplate compared to its Python counterpart.\nPython’s low-level Server surprisingly retains a decorator-based approach for handler registration, making it quite ergonomic, while still requiring manual construction of MCP response types.\n\nYou’d typically reach for these low-level APIs when the McpServer or FastMCP abstractions don’t meet your specific needs – perhaps for implementing non-standard protocol extensions, integrating deeply with another framework, or when requiring precise control over every aspect of the request lifecycle. They grant power but also demand a deeper understanding of the MCP specification itself.\nWith the server foundations covered, our next post will shift focus to the other side of the conversation: Blog 5: Client Architecture - Talking to Servers. We’ll explore how Client (TS) and ClientSession (Python) initiate requests and handle responses and notifications.\n"},"1-Official-py-and-ts-sdk-tutes/Blogs/blog-5":{"slug":"1-Official-py-and-ts-sdk-tutes/Blogs/blog-5","filePath":"1 Official py and ts sdk tutes/Blogs/blog-5.md","title":"Blog 5: Client Architecture - Consuming MCP Services (TypeScript & Python)","links":["1-Official-py-and-ts-sdk-tutes/Blogs/blog-2","1-Official-py-and-ts-sdk-tutes/Blogs/blog-3","1-Official-py-and-ts-sdk-tutes/Blogs/blog-4"],"tags":[],"content":"Blog 5: Client Architecture - Consuming MCP Services (TypeScript &amp; Python)\nSeries: Deep Dive into the Model Context Protocol SDKs (TypeScript &amp; Python)\r\nPost: 5 of 10\nSo far in our series, we’ve focused on the server side of the Model Context Protocol (MCP) equation. We’ve explored type definitions and examined both the high-level (McpServer/FastMCP) and low-level server APIs in TypeScript and Python.\nBut MCP is a two-way street. Servers expose capabilities, but it’s the clients that consume them to provide context-aware experiences. Clients could be AI chatbots, integrated development environments (IDEs), browser extensions, or any application that needs to leverage external context or functionality via MCP.\nIn this post, we shift our focus to the client-side implementations within the MCP SDKs:\n\nTypeScript: The Client class (src/client/index.ts).\nPython: The ClientSession class (src/mcp/client/session.py).\n\nWe’ll explore how these classes enable applications to connect to MCP servers, discover available primitives (Tools, Resources, Prompts), make requests, and handle asynchronous notifications.\nThe Core Client Classes: Your Gateway to MCP Servers\nBoth SDKs provide a primary class that acts as the main interface for interacting with an MCP server:\n\nTypeScript (Client): This class extends the shared Protocol base class. It provides methods like connect, listTools, callTool, readResource, getPrompt, etc., offering a clear, method-driven API.\nPython (ClientSession): This class extends the shared BaseSession class. It’s designed as an asynchronous context manager (async with ClientSession(...)). Interaction typically happens through methods on the session object after the context is entered (e.g., session.call_tool(...), session.read_resource(...)).\n\nUnderneath, both Client and ClientSession rely on the Protocol/BaseSession logic (discussed in Blog 4) to handle JSON-RPC framing, request/response matching, timeouts, and cancellation over a chosen transport.\nEstablishing the Connection: The Handshake\nBefore any meaningful interaction can occur, the client must connect to the server and perform the MCP initialization handshake.\nTypeScript (Client.connect):\nThe Client instance is created first, and then its connect method is called, passing in an instance of a specific transport implementation. The connect method handles sending the initialize request and processing the server’s response.\nimport { Client } from &quot;@modelcontextprotocol/sdk/client/index.js&quot;;\nimport { StdioClientTransport } from &quot;@modelcontextprotocol/sdk/client/stdio.js&quot;;\n// Or StreamableHTTPClientTransport, WebSocketClientTransport, etc.\n \n// 1. Create Client instance\nconst client = new Client(\n  { name: &quot;MyTSClient&quot;, version: &quot;0.1.0&quot; },\n  {\n    // Optional: Declare client capabilities\n    capabilities: {\n      sampling: {}, // We can handle sampling requests\n      roots: { listChanged: true } // We can handle root list changes\n    }\n  }\n);\n \n// 2. Create Transport instance\nconst transport = new StdioClientTransport({\n  command: &quot;python&quot;, // Or provide URL for HTTP/WS\n  args: [&quot;my_mcp_server.py&quot;]\n});\n \nasync function run() {\n  try {\n    // 3. Connect (handles initialize handshake internally)\n    await client.connect(transport);\n    console.log(&quot;Connected!&quot;);\n    console.log(&quot;Server Info:&quot;, client.getServerVersion());\n    console.log(&quot;Server Capabilities:&quot;, client.getServerCapabilities());\n    console.log(&quot;Server Instructions:&quot;, client.getInstructions());\n \n    // ... proceed with interactions ...\n \n  } catch (error) {\n    console.error(&quot;Connection failed:&quot;, error);\n  } finally {\n    await client.close(); // Close connection when done\n  }\n}\nrun();\nPython (async with ClientSession(...)):\nThe Python approach uses an asynchronous context manager. You typically call a transport factory function (like stdio_client, sse_client) which itself yields the necessary read/write streams to the ClientSession constructor. The ClientSession’s __aenter__ method implicitly calls its initialize method.\nimport anyio\nfrom mcp import ClientSession, StdioServerParameters, types\nfrom mcp.client.stdio import stdio_client\n# Or sse_client, websocket_client\n \n# 1. Define server parameters (for stdio) or URL (for HTTP/WS)\nserver_params = StdioServerParameters(\n    command=&quot;python&quot;,\n    args=[&quot;my_mcp_server.py&quot;]\n)\n \nasync def run():\n    # 2. Use transport factory in async with block\n    async with stdio_client(server_params) as (read_stream, write_stream):\n        # 3. Create ClientSession within its own async with block\n        #    Initialization happens automatically upon entering\n        async with ClientSession(\n            read_stream,\n            write_stream,\n            # Optional: Provide client info &amp; callbacks\n            client_info=types.Implementation(name=&quot;MyPyClient&quot;, version=&quot;0.1.0&quot;)\n            # sampling_callback=..., list_roots_callback=... etc.\n        ) as session:\n            print(&quot;Connected!&quot;)\n            # Access server info (available after __aenter__ completes initialize)\n            # Note: Python SDK doesn&#039;t seem to expose server caps/info as directly\n            #       as the TS SDK post-initialization via properties.\n \n            # ... proceed with interactions using &#039;session&#039; ...\n \nasync def main():\n    try:\n        await run()\n    except Exception as e:\n        print(f&quot;An error occurred: {e}&quot;)\n \nif __name__ == &quot;__main__&quot;:\n    anyio.run(main)\n \nKey Handshake Steps (Internal):\n\nClient sends initialize request with its info and capabilities.\nServer responds with its info, capabilities, and chosen protocol version.\nClient validates the server’s response (especially the protocol version).\nClient sends notifications/initialized.\nConnection is ready for use.\n\nBoth SDKs store the negotiated server capabilities, which might be used internally (or exposed, more clearly in TS) to check if certain operations are supported before attempting them.\nMaking Requests: Interacting with Primitives\nOnce connected, clients use methods provided by Client (TS) or ClientSession (Python) to interact with the server’s Resources, Tools, and Prompts. The SDKs abstract away the need to manually construct JSON-RPC request objects.\nListing Primitives:\n// TypeScript\nasync function listItems(client: Client) {\n  try {\n    const toolsResult = await client.listTools();\n    console.log(&quot;Tools:&quot;, toolsResult.tools.map(t =&gt; t.name));\n \n    const resourcesResult = await client.listResources();\n    console.log(&quot;Resources:&quot;, resourcesResult.resources.map(r =&gt; r.uri));\n \n    const promptsResult = await client.listPrompts();\n    console.log(&quot;Prompts:&quot;, promptsResult.prompts.map(p =&gt; p.name));\n  } catch (error) {\n    console.error(&quot;Error listing items:&quot;, error);\n  }\n}\n# Python\nasync def list_items(session: ClientSession):\n    try:\n        tools_result = await session.list_tools()\n        print(&quot;Tools:&quot;, [t.name for t in tools_result.tools])\n \n        resources_result = await session.list_resources()\n        print(&quot;Resources:&quot;, [r.uri for r in resources_result.resources])\n \n        prompts_result = await session.list_prompts()\n        print(&quot;Prompts:&quot;, [p.name for p in prompts_result.prompts])\n    except McpError as e:\n        print(f&quot;Error listing items: {e.error.message}&quot;)\n    except Exception as e:\n        print(f&quot;Unexpected error listing items: {e}&quot;)\nCalling a Tool:\n// TypeScript\nasync function callMyTool(client: Client) {\n  try {\n    const result = await client.callTool({\n      name: &quot;calculate_bmi&quot;,\n      arguments: { weightKg: 70, heightM: 1.75 }\n    });\n    console.log(&quot;Tool Result:&quot;, result.content);\n  } catch (error) {\n    console.error(&quot;Error calling tool:&quot;, error);\n  }\n}\n# Python\nasync def call_my_tool(session: ClientSession):\n    try:\n        result = await session.call_tool(\n            &quot;calculate_bmi&quot;,\n            arguments={&quot;weightKg&quot;: 70, &quot;heightM&quot;: 1.75}\n        )\n        print(&quot;Tool Result:&quot;, result.content)\n    except McpError as e:\n        print(f&quot;Error calling tool: {e.error.message}&quot;)\n    except Exception as e:\n        print(f&quot;Unexpected error calling tool: {e}&quot;)\nReading a Resource:\n// TypeScript\nasync function readMyResource(client: Client) {\n  try {\n    const result = await client.readResource({ uri: &quot;config://myapp&quot; });\n    console.log(&quot;Resource Content:&quot;, result.contents);\n  } catch (error) {\n    console.error(&quot;Error reading resource:&quot;, error);\n  }\n}\n# Python\nfrom pydantic import AnyUrl\n \nasync def read_my_resource(session: ClientSession):\n    try:\n        result = await session.read_resource(AnyUrl(&quot;config://myapp&quot;))\n        print(&quot;Resource Content:&quot;, result.contents)\n    except McpError as e:\n        print(f&quot;Error reading resource: {e.error.message}&quot;)\n    except Exception as e:\n        print(f&quot;Unexpected error reading resource: {e}&quot;)\nGetting a Prompt:\n// TypeScript\nasync function getMyPrompt(client: Client) {\n  try {\n    const result = await client.getPrompt({\n       name: &quot;review_code&quot;,\n       arguments: { code: &quot;print(&#039;hello&#039;)&quot; }\n    });\n    console.log(&quot;Prompt Messages:&quot;, result.messages);\n  } catch (error) {\n    console.error(&quot;Error getting prompt:&quot;, error);\n  }\n}\n# Python\nasync def get_my_prompt(session: ClientSession):\n    try:\n        result = await session.get_prompt(\n            &quot;review_code&quot;,\n            arguments={&quot;code&quot;: &quot;print(&#039;hello&#039;)&quot;}\n        )\n        print(&quot;Prompt Messages:&quot;, result.messages)\n    except McpError as e:\n        print(f&quot;Error getting prompt: {e.error.message}&quot;)\n    except Exception as e:\n        print(f&quot;Unexpected error getting prompt: {e}&quot;)\nIn both SDKs, the methods return Promises (TS) or awaitables (Python) that resolve to objects parsed according to the expected result type schema (e.g., ListToolsResult, CallToolResult). If the server returns a JSON-RPC error, the promise/awaitable rejects with an McpError.\nHandling Responses and Errors\nAs seen above, successful responses are returned as parsed objects (Zod-validated in TS, Pydantic-validated in Python). Errors are raised as exceptions:\n\nTypeScript: Rejects Promises, typically with an McpError containing the code, message, and optional data from the server’s error response. Network or timeout errors might raise different error types.\nPython: Raises an McpError (from src/mcp/shared/exceptions.py), which wraps the ErrorData Pydantic model. Network or timeout errors might raise anyio or httpx exceptions depending on the transport.\n\nStandard try...catch (TS) or try...except (Python) blocks are used for error handling.\nReceiving Server Notifications\nMCP isn’t just request-response; servers can proactively send notifications to clients (e.g., logging messages, resource updates, progress updates). Clients need a way to listen for and react to these.\nTypeScript (setNotificationHandler):\nThe Client class uses setNotificationHandler. You provide the Zod schema for the notification you want to handle and a callback function.\nimport { LoggingMessageNotificationSchema } from &quot;@modelcontextprotocol/sdk/types.js&quot;;\n \n// Assuming &#039;client&#039; is an initialized Client instance\n \nclient.setNotificationHandler(\n  LoggingMessageNotificationSchema, // Schema to match\n  async (notification) =&gt; { // Callback receives validated notification\n    console.log(`[SERVER LOG - ${notification.params.level}]:`, notification.params.data);\n  }\n);\n \n// Fallback for unhandled notifications\nclient.fallbackNotificationHandler = async (notification) =&gt; {\n  console.warn(&quot;Received unhandled notification:&quot;, notification.method);\n};\nPython (Constructor Callbacks):\nThe ClientSession constructor accepts optional callback functions for specific server-initiated interactions.\nfrom mcp import types\nfrom mcp.client.session import ClientSession # ... other imports\n \nasync def handle_logging(params: types.LoggingMessageNotificationParams) -&gt; None:\n    print(f&quot;[SERVER LOG - {params.level}]:&quot;, params.data)\n \nasync def handle_unhandled(message: Any) -&gt; None: # Can inspect message type\n    if isinstance(message, types.ServerNotification):\n        print(f&quot;Received unhandled notification: {message.root.method}&quot;)\n    elif isinstance(message, Exception):\n        print(f&quot;Received error from transport: {message}&quot;)\n    # ... handle requests if needed for client-acting-as-server\n \nasync def run_client_with_logging():\n    # ... setup transport streams (read_stream, write_stream) ...\n    async with ClientSession(\n        read_stream,\n        write_stream,\n        logging_callback=handle_logging,      # Specific callback\n        message_handler=handle_unhandled     # Generic fallback\n    ) as session:\n        await session.initialize() # Already done by __aenter__ but explicit call is fine\n        # ... interact ...\n \n# Note: ClientSession also accepts sampling_callback and list_roots_callback\n# for handling *requests* FROM the server, acting briefly as a server itself.\nPython’s approach uses specific callbacks passed during initialization, plus a general message_handler for anything else. TypeScript uses a more dynamic registration model with setNotificationHandler.\nAdvanced Client Features\nBoth SDKs support more advanced client-side operations, which we’ll explore further in later posts:\n\nTimeouts: Specifying timeouts for requests.\nCancellation: Using AbortSignal (TS) or anyio.CancelScope (implied, Python) to cancel long-running requests.\nProgress: Receiving progress updates for requests (onprogress option in TS client.request).\nAuthentication: Handling OAuth flows (more built-in helpers in TS).\n\nComparison: Client APIs\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFeatureClient (TypeScript)ClientSession (Python)NotesInstantiationnew Client(...)ClientSession(...) (within async with)TS is standard class instantiation; Python uses async context management.Connectionclient.connect(transport)async with transport_factory(...) as (r,w): async with ClientSession(r,w)TS takes transport instance; Python uses transport factory functions yielding streams. Initialization is implicit in Python’s async with.API StyleMethods on Client instanceMethods on session object (from async with)Both provide clear methods for MCP operations.Notification HandlingsetNotificationHandler(schema, cb)Callbacks passed to ClientSession constructorTS allows dynamic registration per type; Python uses pre-defined callback slots.Server→Client ReqsetRequestHandler (for sampling/roots)Specific callbacks (sampling_callback, list_roots_callback) in constructorBoth support client acting briefly as a server for specific methods.\nConclusion: Enabling Intelligent Interactions\nThe client-side components of the MCP SDKs (Client in TS, ClientSession in Python) provide the essential tools for applications to consume MCP services. They manage the connection lifecycle, abstract the complexities of the JSON-RPC protocol, and offer straightforward methods for interacting with server-provided Tools, Resources, and Prompts. Furthermore, they provide mechanisms for handling asynchronous server-sent notifications, enabling responsive and dynamic user experiences.\nBy simplifying client implementation, the SDKs empower developers to build applications – from chatbots to IDE extensions – that can intelligently leverage the context and capabilities exposed by a growing ecosystem of MCP servers.\nNext, we’ll delve into the crucial layer connecting clients and servers: Blog 6: Bridging Worlds - Transport Deep Dive. We’ll compare how Stdio, SSE, and WebSocket transports are implemented in both SDKs.\n"},"1-Official-py-and-ts-sdk-tutes/Blogs/blog-6":{"slug":"1-Official-py-and-ts-sdk-tutes/Blogs/blog-6","filePath":"1 Official py and ts sdk tutes/Blogs/blog-6.md","title":"Blog 6: Bridging Worlds - Transport Deep Dive (Stdio & Foundational HTTP)","links":["1-Official-py-and-ts-sdk-tutes/Blogs/blog-2","1-Official-py-and-ts-sdk-tutes/Blogs/blog-3","1-Official-py-and-ts-sdk-tutes/Blogs/blog-4","1-Official-py-and-ts-sdk-tutes/Blogs/blog-5"],"tags":[],"content":"Blog 6: Bridging Worlds - Transport Deep Dive (Stdio &amp; Foundational HTTP)\nSeries: Deep Dive into the Model Context Protocol SDKs (TypeScript &amp; Python)\r\nPost: 6 of 10\nWelcome back to our deep dive into the Model Context Protocol (MCP) SDKs! In previous posts, we’ve dissected the type systems, the high-level server APIs, the low-level server internals, and the client architecture. Now, we turn our attention to the crucial layer that physically connects clients and servers: the Transports.\nTransports are the conduits through which MCP’s JSON-RPC messages flow. They handle the specifics of establishing a connection, sending raw data, receiving raw data, and signaling connection state changes (open, close, error). The core Protocol (TS) and BaseSession (Python) classes build upon these transport primitives to manage the structured MCP communication.\nBoth SDKs define a conceptual Transport interface (explicit in TS src/shared/transport.ts, implied via factory functions yielding streams in Python) with core responsibilities:\n\nstart(): Initialize the connection.\nsend(message): Send a JSON-RPC message.\nclose(): Terminate the connection.\nCallbacks (onmessage, onclose, onerror): To notify the protocol layer of incoming data or state changes.\n\nIn this post, we’ll explore the “foundational” transports provided by the SDKs: Stdio (for local process communication) and the HTTP+SSE model heavily utilized by the Python SDK for web communication. We’ll leave the newer Streamable HTTP (prominent in TS) and WebSocket transports for the next installment.\nStdio: Talking to Local Processes\nThe Standard Input/Output (Stdio) transport is fundamental for integrating MCP servers that run as local command-line applications. This is the mechanism powering integrations like the Claude Desktop app’s ability to run and communicate with locally installed tools.\n\nUse Case: Running an MCP server as a child process of the client application, enabling local file access, system automation, or running language-specific tools securely without network exposure.\nMechanism: The client spawns the server application as a subprocess. Communication happens by the client writing JSON-RPC messages (as line-delimited JSON strings) to the server process’s stdin and reading responses/notifications from the server’s stdout. Server stderr is typically forwarded for debugging.\n\nTypeScript Implementation (StdioClientTransport, StdioServerTransport):\n\n\nClient (src/client/stdio.ts):\n\nUses the cross-spawn library for cross-platform process spawning (spawn(...)).\nTakes command, args, env, cwd, stderr handling options.\nProvides a getDefaultEnvironment function to inherit only safe environment variables (DEFAULT_INHERITED_ENV_VARS).\nPipes stdin/stdout and uses ReadBuffer (src/shared/stdio.ts) to parse line-delimited JSON from stdout.\nUses serializeMessage (src/shared/stdio.ts) to format outgoing messages to stdin.\nManages the child process lifecycle via an AbortController.\n\n// Client-side spawning\nconst transport = new StdioClientTransport({\n  command: &quot;python&quot;,\n  args: [&quot;my_server.py&quot;],\n  env: { ...getDefaultEnvironment(), MY_VAR: &quot;value&quot; },\n  stderr: &quot;inherit&quot; // Show server errors in client console\n});\nawait client.connect(transport); // Spawns the process\n\n\nServer (src/server/stdio.ts):\n\nSimpler; assumes it is the spawned process.\nWraps process.stdin and process.stdout (or provided streams).\nUses ReadBuffer and serializeMessage similarly to the client.\nListens for data events on stdin and writes to stdout.\nHandles close/error events on the streams.\n\n\n\nPython Implementation (stdio_client, stdio_server):\n\n\nClient (src/mcp/client/stdio/__init__.py):\n\nUses anyio.open_process for asynchronous process management.\nIncludes Windows-specific handling (src/mcp/client/stdio/win32.py) using subprocess.CREATE_NO_WINDOW to avoid console flashes and platform-specific executable path resolution (get_windows_executable_command).\nThe stdio_client function is an async context manager that yields the read/write memory streams connected to the process’s stdio pipes.\nUses anyio’s text streams (TextReceiveStream) for async reading/writing with specified encoding.\nProvides getDefaultEnvironment similar to TS.\n\n# Client-side spawning\nfrom mcp.client.stdio import stdio_client, StdioServerParameters\n \nserver_params = StdioServerParameters(\n    command=&quot;python&quot;, args=[&quot;my_server.py&quot;]\n)\nasync with stdio_client(server_params) as (read_stream, write_stream):\n    async with ClientSession(read_stream, write_stream) as session:\n        await session.initialize() # Already done by __aenter__\n        # ...\n\n\nServer (src/mcp/server/stdio.py):\n\nThe stdio_server function is also an async context manager.\nWraps sys.stdin.buffer and sys.stdout.buffer using TextIOWrapper (to ensure UTF-8) and anyio.wrap_file for async operation.\nUses async iteration over the wrapped stdin to read lines and stdout.write/flush to send.\n\n\n\nComparison (Stdio):\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFeatureTypeScriptPythonNotesProcess Spawncross-spawn libraryanyio.open_processBoth handle cross-platform spawning.Async ModelNode.js Streams &amp; Event Emittersanyio Streams &amp; Tasksanyio provides a higher-level async abstraction.API StyleExplicit Classes (Stdio*Transport)Async Context Managers (stdio_client)Python’s context managers handle setup/teardown neatly.Windows HandlingRelies on cross-spawn behaviorExplicit helpers in client/stdio/win32.pyPython SDK has more visible Windows-specific code.Message FramingCustom ReadBuffer/serializeStandard line reading/writing via anyioBoth achieve line-delimited JSON.\nEnd-User Nuance: Stdio is invisible but powerful. It’s what allows tools like the Claude Desktop app to securely run a local Python script as an MCP server, granting Claude access to local files or scripts without needing network configuration or exposing ports.\nFoundational HTTP: Python’s SSE Approach\nWhile the TypeScript SDK has moved towards Streamable HTTP as its primary web transport, the Python SDK’s main approach for HTTP communication relies on the Server-Sent Events (SSE) model, similar to the older MCP specification versions.\n\nUse Case: Enabling remote MCP servers accessible over the web, allowing clients (like web apps or other servers) to connect and interact.\nMechanism: This model uses two distinct HTTP endpoints:\n\nSSE Endpoint (GET): The client initiates a GET request to establish a persistent SSE connection. The server keeps this connection open and pushes messages (responses, notifications) to the client as standard SSE events. The first event sent by the server is typically an endpoint event, telling the client where to send its own messages.\nMessage Endpoint (POST): The client sends its requests and notifications to the server by making standard HTTP POST requests to the URL provided in the endpoint event from the SSE stream. Each POST includes a session_id query parameter (also received via the SSE stream’s endpoint URL) to link it to the correct server-side session and SSE connection.\n\n\n\nPython Implementation (SseServerTransport, sse_client):\n\n\nServer (src/mcp/server/sse.py):\n\nThe SseServerTransport class is designed to integrate with ASGI frameworks (like Starlette).\nconnect_sse: An ASGI application handling the initial GET request. It uses sse-starlette’s EventSourceResponse to manage the SSE stream. It generates a unique session_id (UUID). It sends the initial endpoint event containing the message POST URL with the session_id appended. It uses anyio memory streams internally to bridge between the main server logic and the SSE response stream.\nhandle_post_message: A separate ASGI application handling incoming POST requests. It extracts the session_id from the query parameters, looks up the corresponding write stream for that session (stored in _read_stream_writers), parses the JSON body, and forwards the message to the correct ServerSession via the memory stream. Returns HTTP 202 Accepted.\n\n# Server-side (simplified Starlette setup)\nfrom mcp.server.sse import SseServerTransport\nfrom starlette.applications import Starlette\nfrom starlette.routing import Route, Mount\n \nsse_transport = SseServerTransport(&quot;/messages/&quot;) # Endpoint for POSTs\n \nasync def handle_sse_get(request): # Handles GET /sse\n    async with sse_transport.connect_sse(...) as (read_stream, write_stream):\n        # ... run server logic with streams ...\n \napp = Starlette(routes=[\n    Route(&quot;/sse&quot;, endpoint=handle_sse_get), # GET for SSE stream\n    Mount(&quot;/messages/&quot;, app=sse_transport.handle_post_message) # POST handler\n])\n\n\nClient (src/mcp/client/sse.py):\n\nThe sse_client function is an async context manager.\nIt uses httpx-sse (aconnect_sse) to establish the GET connection to the server’s SSE endpoint.\nIt listens for the endpoint event to get the POST URL and session_id.\nIt listens for message events, parses them as JSON-RPC, and sends them to the client’s read stream.\nIt runs a separate async task (post_writer) that reads messages from the client’s write stream and sends them via HTTP POST (using httpx) to the learned endpoint URL.\nHandles timeouts and potential origin mismatches.\n\n# Client-side\nfrom mcp.client.sse import sse_client\n \nserver_sse_url = &quot;http://localhost:8000/sse&quot;\n \nasync with sse_client(server_sse_url) as (read_stream, write_stream):\n    async with ClientSession(read_stream, write_stream) as session:\n        # ... interact ...\n\n\nTypeScript (Deprecated SSE):\nThe TS SDK does contain SSEClientTransport and SSEServerTransport, primarily for backwards compatibility testing. Their internal logic is conceptually similar (GET for stream, POST for messages, session ID linking), but they are explicitly not the recommended modern approach in the TS ecosystem, having been superseded by Streamable HTTP.\nComparison (SSE):\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFeaturePython (SseServerTransport/sse_client)TypeScript (SSE*Transport - Deprecated)NotesRole in SDKPrimary HTTP TransportBackwards Compatibility / TestingPython relies on this model; TS prefers Streamable HTTP.EndpointsSeparate GET (SSE) and POST (Messages)Separate GET and POSTCore mechanism is the same two-endpoint approach.Libraries Usedsse-starlette, httpx-sse, anyioeventsource (client), manual server impl.Python leverages dedicated SSE/HTTP libraries built on anyio.API StyleClass (Server), Async Context Mgr (Client)Classes (SSE*Transport)Python client uses the familiar context manager pattern.IntegrationDesigned for ASGIManual setup with Express/httpPython’s SSE transport is tightly coupled with the ASGI standard.\nEnd-User Nuance: This HTTP+SSE mechanism allows MCP servers to be hosted traditionally and accessed remotely by clients over the web. While functional, the need for two connections (one long-lived GET, multiple short-lived POSTs) and the reliance on a session ID can be less efficient and potentially harder to manage in some load-balanced scenarios compared to newer protocols like WebSockets or Streamable HTTP.\nTesting Transport: InMemory / Memory\nBoth SDKs provide an essential transport for testing:\n\nTypeScript: InMemoryTransport (src/inMemory.ts) - A class with a static createLinkedPair() method returning two connected transport instances.\nPython: create_client_server_memory_streams (src/mcp/shared/memory.py) - An async context manager yielding two pairs of connected anyio memory streams.\n\nThese allow testing client-server interactions entirely in memory without real network or process I/O, making unit and integration testing much faster and more reliable.\nConclusion\nThe Stdio and HTTP+SSE transports form the foundational, albeit somewhat contrasting, communication layers in the MCP Python and TypeScript SDKs. Stdio provides a robust mechanism for secure, local inter-process communication crucial for desktop integrations. Python’s SDK fully embraces the two-endpoint HTTP+SSE model as its primary web transport, leveraging the ASGI ecosystem, while the TypeScript SDK has largely moved beyond this model, keeping it mainly for compatibility.\nUnderstanding these transports is key to deploying MCP servers correctly and choosing the right communication method for your client’s needs.\nIn our next post, we’ll explore the modern web transports: TypeScript’s Streamable HTTP (and its resumability features) and the WebSocket transport available in both SDKs (though primarily client-side in TS). Stay tuned!\n"},"1-Official-py-and-ts-sdk-tutes/Blogs/blog-7":{"slug":"1-Official-py-and-ts-sdk-tutes/Blogs/blog-7","filePath":"1 Official py and ts sdk tutes/Blogs/blog-7.md","title":"Blog 7: The Modern Web - Streamable HTTP, Resumability, and Backwards Compatibility","links":["1-Official-py-and-ts-sdk-tutes/Blogs/blog-6"],"tags":[],"content":"Blog 7: The Modern Web - Streamable HTTP, Resumability, and Backwards Compatibility\nSeries: Deep Dive into the Model Context Protocol SDKs (TypeScript &amp; Python)\r\nPost: 7 of 10\nIn Blog 6, we examined the Stdio transport for local communication and the foundational HTTP+SSE transport prevalent in the Python MCP SDK. While functional, the dual-endpoint nature of HTTP+SSE presents certain complexities for web-based interactions.\nThe TypeScript SDK, aligning with newer iterations of the MCP specification (like 2025-03-26), champions a more streamlined approach for HTTP: Streamable HTTP. This transport aims to simplify communication, enhance efficiency, and introduce powerful features like resumability.\nThis post dives into:\n\nThe Streamable HTTP transport (primarily focusing on the TypeScript implementation).\nIts key features: single endpoint, session management (stateful/stateless), JSON response mode, and resumability.\nStrategies for Backwards Compatibility enabling modern clients/servers to interoperate with older ones using HTTP+SSE.\nComparing Streamable HTTP with Python’s SSE-based approach.\n\nStreamable HTTP: A Unified Approach (TypeScript Focus)\nDefined primarily in the TypeScript SDK (src/client/streamableHttp.ts, src/server/streamableHttp.ts), the Streamable HTTP transport consolidates MCP communication over a single HTTP endpoint, typically /mcp. It elegantly handles different interaction patterns using standard HTTP methods:\n\nPOST: Used by the client to send requests and notifications to the server.\n\nThe Accept header must include both application/json and text/event-stream.\nThe server can respond in two ways:\n\nSSE Stream (Content-Type: text/event-stream): The server streams back JSON-RPC responses and subsequent server-initiated notifications related to the original request(s) in the POST body. This is the preferred method for long-running operations or when notifications are expected.\nDirect JSON (Content-Type: application/json): The server sends back all JSON-RPC responses directly in the POST response body (either a single object or a batch array). Used for simpler request-response cycles or when the server explicitly disables SSE (enableJsonResponse: true).\n202 Accepted: If the client sends only notifications (no requests needing a response), the server replies with 202 and no body.\n\n\n\n\nGET: Used by the client optionally to establish a standalone, long-lived SSE stream for receiving unsolicited server-initiated notifications (e.g., resourceListChanged, logMessage).\n\nRequires Accept: text/event-stream.\nThe server may support this, responding with an SSE stream or 405 Method Not Allowed.\n\n\nDELETE: Used by the client to explicitly terminate its session with the server.\n\nRequires the Mcp-Session-Id header.\nServer responds 200 OK on success or 405 Method Not Allowed if termination isn’t supported/allowed.\n\n\n\nKey Implementation (StreamableHTTPServerTransport - TS):\n\nhandleRequest(req, res, parsedBody?): A single method routes incoming Express req/res objects based on the HTTP method (req.method) to the appropriate internal handler (handlePostRequest, handleGetRequest, handleDeleteRequest). It can optionally accept a pre-parsed body.\nSession Management:\n\nStateful (Default): If sessionIdGenerator is provided (e.g., () =&gt; randomUUID()), the transport manages sessions. The first initialize POST response includes a generated Mcp-Session-Id header. Subsequent requests must include this header, and the transport validates it. It maintains internal state mapping session IDs to connections (_streamMapping).\nStateless: If sessionIdGenerator is undefined, session management is disabled. No session IDs are generated or validated (though an ID might still be sent on the initial response if the client provided one, for compatibility). Each request is treated independently.\n\n\nResponse Handling: Tracks pending requests (_requestToStreamMapping, _requestResponseMap). Sends responses via the appropriate SSE stream (POST-bound or GET-bound) or collects them for a single JSON response if enableJsonResponse is true.\nResumability (EventStore): If an EventStore implementation is provided during construction, the transport automatically:\n\nStores outgoing server messages (responses/notifications) with unique, sequential EventIds associated with a StreamId (session/connection identifier).\nIncludes the id: &lt;EventId&gt; field in SSE events sent to the client.\nHandles incoming GET or POST requests containing a Last-Event-ID header by querying the EventStore (replayEventsAfter) to resend any messages the client missed since that ID.\n\n\n\n// Server-side Streamable HTTP (TypeScript Example)\nimport express from &quot;express&quot;;\nimport { StreamableHTTPServerTransport } from &quot;@modelcontextprotocol/sdk/server/streamableHttp.js&quot;;\nimport { InMemoryEventStore } from &quot;../examples/shared/inMemoryEventStore.js&quot;; // Example store\nimport { McpServer } from &quot;@modelcontextprotocol/sdk/server/mcp.js&quot;;\nimport { randomUUID } from &quot;node:crypto&quot;;\n \nconst app = express();\napp.use(express.json()); // Needed if not using pre-parsed body\n \nconst transports: { [sessionId: string]: StreamableHTTPServerTransport } = {}; // Store transports\n \nconst mcpServer = new McpServer(/* ... server info ... */);\n \n// Single endpoint handles all methods\napp.all(&#039;/mcp&#039;, async (req, res) =&gt; {\n  const sessionId = req.headers[&#039;mcp-session-id&#039;] as string | undefined;\n  let transport: StreamableHTTPServerTransport;\n \n  if (sessionId &amp;&amp; transports[sessionId]) {\n    transport = transports[sessionId];\n  } else if (req.method === &#039;POST&#039; &amp;&amp; isInitializeRequest(req.body)) {\n    // New connection, create transport (stateful with resumability)\n    const eventStore = new InMemoryEventStore();\n    transport = new StreamableHTTPServerTransport({\n      sessionIdGenerator: () =&gt; randomUUID(), // Stateful\n      eventStore: eventStore,                // Enable resumability\n      onsessioninitialized: (newSessionId) =&gt; {\n         transports[newSessionId] = transport; // Store *after* init\n         console.log(`Session ${newSessionId} initialized.`);\n      }\n    });\n    await mcpServer.connect(transport); // Connect McpServer logic\n    // onclose handler needed to remove from &#039;transports&#039; map\n    transport.onclose = () =&gt; {\n      if (transport.sessionId) delete transports[transport.sessionId];\n    }\n  } else {\n     // Handle error: Invalid session or non-init request without session\n     res.status(400).json({ /* ... error object ... */ });\n     return;\n  }\n \n  // Let the transport handle routing based on method (GET/POST/DELETE)\n  // Pass req.body if using express.json() middleware\n  await transport.handleRequest(req, res, req.body);\n});\n \napp.listen(3000);\nClient Implementation (StreamableHTTPClientTransport - TS):\n\nUses fetch for all interactions (GET, POST, DELETE).\nSends appropriate Accept and Content-Type headers.\nStores the Mcp-Session-Id received from the server after initialize and includes it in subsequent requests.\nParses Content-Type of POST responses to determine if it’s JSON or an SSE stream.\nHandles SSE streams using EventSourceParserStream.\nManages an optional standalone GET SSE stream for server notifications.\nImplements reconnection logic with exponential backoff for the GET stream.\nSupports resumability by optionally tracking the Last-Event-ID received and sending it on reconnect attempts or subsequent POSTs (resumptionToken option in send).\n\nKiller Feature: Resumability\nStreamable HTTP’s integration with an EventStore enables powerful resumability, particularly useful for:\n\nLong-running Tools: If a client calls a tool that takes minutes and sends many progress notifications, the connection might drop.\nNetwork Glitches: Temporary network issues can interrupt the SSE stream.\n\nHow it works:\n\nServer: Assigns a unique, ordered EventId to every message sent over SSE (responses and notifications). Stores (StreamId, EventId, Message) in the EventStore.\nClient: Receives messages with id: &lt;EventId&gt; lines in the SSE stream. It keeps track of the last seen EventId.\nDisconnection: The connection drops.\nClient Reconnection: The client reconnects (either via GET or the next POST) and includes the Last-Event-ID: &lt;last_seen_event_id&gt; header.\nServer: Receives the request with Last-Event-ID. It queries the EventStore’s replayEventsAfter(&lt;last_seen_event_id&gt;) method.\nEventStore: Finds all messages for that stream after the provided EventId.\nServer: Sends the missed messages (with their original EventIds) down the new connection before sending any new messages.\n\nThis ensures the client seamlessly catches up without missing intermediate notifications or responses from long-running tasks, providing a much smoother user experience. The InMemoryEventStore (src/examples/shared/inMemoryEventStore.ts) provides a basic implementation, but production systems would use a persistent database (Redis, PostgreSQL, etc.).\nBackwards Compatibility: Bridging the Transport Gap\nSince not all clients and servers will upgrade simultaneously, the MCP specification and the SDKs provide guidance for interoperability between Streamable HTTP and the older HTTP+SSE transport.\nClient Strategy (Modern Client, Old Server):\nAs detailed in the TypeScript SDK’s streamableHttpWithSseFallbackClient.ts example:\n\nTry Modern First: The client first attempts an initialize request via POST to the server’s base URL (e.g., /mcp).\nCheck Response:\n\nIf the server responds 200 OK (with Content-Type: text/event-stream or application/json) and potentially an Mcp-Session-Id, the client proceeds using the Streamable HTTP transport logic.\nIf the server responds with a 4xx error (like 405 Method Not Allowed or 404 Not Found), the client assumes it’s an older server.\n\n\nFallback to SSE: The client then initiates a GET request to the same base URL (or potentially a dedicated /sse path if known). If successful, it expects the endpoint event and proceeds using the classic HTTP+SSE logic (sending messages via POST to the endpoint URL with ?session_id=...).\n\nServer Strategy (Modern Server, Old Client):\nAs detailed in the TypeScript SDK’s sseAndStreamableHttpCompatibleServer.ts example:\n\nSupport Both Endpoint Styles: The server listens on both the single Streamable HTTP endpoint (e.g., /mcp for GET/POST/DELETE) and the older separate endpoints (e.g., /sse for GET, /messages for POST).\nTransport Detection: When a connection is initiated:\n\nIf it’s a POST to /mcp for initialize or any request with Mcp-Session-Id, use StreamableHTTPServerTransport.\nIf it’s a GET to /sse, use SSEServerTransport.\nIf it’s a POST to /messages with ?session_id=..., look up the existing SSEServerTransport for that session.\n\n\nSession State: Maintain separate session state or transport instances based on the protocol detected for a given session ID to avoid mixing behaviors.\n\nThis allows a modern server to gracefully handle connections from both new and legacy clients.\nComparison: Streamable HTTP (TS) vs. SSE (Python)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFeatureStreamable HTTP (TS)HTTP+SSE (Python)NotesEndpointsSingle (e.g., /mcp)Two (e.g., /sse, /messages)Streamable HTTP is simpler architecturally.Request MethodPOSTPOSTClient-to-server messages use POST in both.Response MethodPOST (SSE Stream or JSON), GET (SSE Stream)GET (SSE Stream only)Streamable HTTP offers more flexibility in response delivery (direct JSON vs. SSE on POST).Session MgmtBuilt-in (Stateful/Stateless)Implicit via session_id query paramStreamable HTTP has explicit stateful/stateless modes. SSE relies on the client passing the correct ID.ResumabilityYes (via EventStore, Last-Event-ID)No (Protocol inherent limitation)Major advantage for Streamable HTTP, crucial for long tasks/unreliable networks.ComplexitySlightly more complex server logicSimpler server logicHandling multiple response types/methods on one endpoint adds some complexity for Streamable HTTP.SDK SupportPrimary in TSPrimary in PythonClear divergence in the preferred HTTP transport between the SDKs.\nConclusion\nStreamable HTTP represents a significant evolution in MCP’s web transport capabilities, offering a unified endpoint, flexible response modes, and robust resumability. The TypeScript SDK provides a comprehensive implementation, showcasing its advantages, particularly for complex, long-running interactions over potentially unreliable networks.\nWhile the Python SDK currently favors the established HTTP+SSE model, the clear specifications and examples for backwards compatibility ensure that applications built with either SDK can still communicate effectively during transition periods. Understanding both transports is key for developers working in mixed-language MCP environments or migrating existing applications.\nIn our next post, we’ll tackle Blog 8: Securing Interactions - Authentication (OAuth Focus), investigating how the SDKs approach securing MCP communication.\n"},"1-Official-py-and-ts-sdk-tutes/Blogs/blog-8":{"slug":"1-Official-py-and-ts-sdk-tutes/Blogs/blog-8","filePath":"1 Official py and ts sdk tutes/Blogs/blog-8.md","title":"Blog 8: Securing Interactions - Authentication in MCP SDKs (OAuth Focus)","links":["1-Official-py-and-ts-sdk-tutes/Blogs/blog-2","1-Official-py-and-ts-sdk-tutes/Blogs/blog-3","1-Official-py-and-ts-sdk-tutes/Blogs/blog-4","1-Official-py-and-ts-sdk-tutes/Blogs/blog-5","1-Official-py-and-ts-sdk-tutes/Blogs/blog-6","1-Official-py-and-ts-sdk-tutes/Blogs/blog-7"],"tags":[],"content":"Blog 8: Securing Interactions - Authentication in MCP SDKs (OAuth Focus)\nSeries: Deep Dive into the Model Context Protocol SDKs (TypeScript &amp; Python)\r\nPost: 8 of 10\nIn our journey through the Model Context Protocol (MCP) SDKs, we’ve explored type definitions, server APIs, low-level internals, client architecture, and various transports like Streamable HTTP. Now, we address a critical aspect of any real-world application integration: Security and Authentication.\nMCP servers often expose sensitive data (Resources) or powerful capabilities (Tools). Allowing unrestricted access would be a significant security risk. Imagine an AI assistant being able to arbitrarily query your company’s internal database or send emails from your account without permission! Authentication ensures that only legitimate, authorized clients can interact with an MCP server, and potentially only with specific permissions.\nWhile various authentication schemes exist, OAuth 2.1 (the successor to OAuth 2.0) is a strong candidate for standardized authorization in distributed systems like those MCP enables. It allows users to grant specific permissions to client applications without sharing their primary credentials.\nThis post examines how the TypeScript and Python MCP SDKs approach authentication, with a particular focus on their support (or lack thereof) for built-in OAuth server functionality.\nThe Crucial Role of Authentication in MCP\nBefore diving into specifics, let’s establish why authentication is vital:\n\nAuthorization: It’s the foundation for determining what a connected client is allowed to do (e.g., call specific tools, read certain resources).\nIdentification: The server needs to know which client is making a request, often mapping it back to a specific user or application registration.\nData Protection: Prevents unauthorized access to potentially sensitive information exposed via Resources.\nAction Control: Ensures only permitted clients can trigger Tools that might have side effects or costs.\nRate Limiting &amp; Auditing: Identifying clients enables effective rate limiting and logging of actions.\n\nTypeScript SDK: A “Batteries-Included” OAuth Server\nThe TypeScript SDK stands out by providing a remarkably comprehensive, built-in solution for implementing an OAuth 2.1 Authorization Server directly within your MCP server application. This functionality resides primarily within the src/server/auth/ directory.\nKey Components:\n\n\nmcpAuthRouter (src/server/auth/router.ts):\n\nThis is the central piece – an Express router factory function.\nWhen added to your Express app (typically at the root), it automatically sets up standard OAuth 2.1 endpoints:\n\n/.well-known/oauth-authorization-server: Serves the OAuth Authorization Server Metadata.\n/authorize: Handles the user authorization request (often redirecting the user’s browser).\n/token: Handles exchanging authorization codes or refresh tokens for access tokens.\n/register: (Optional) Handles Dynamic Client Registration.\n/revoke: (Optional) Handles Token Revocation.\n\n\nIt takes configuration options, including the crucial provider.\n\n\n\nOAuthServerProvider (src/server/auth/provider.ts):\n\nAn interface defining the contract for the actual authorization logic. You need to provide an implementation of this interface to mcpAuthRouter.\nMethods include authorize, exchangeAuthorizationCode, exchangeRefreshToken, verifyAccessToken, revokeToken, etc.\nThis allows plugging in different backend logic (e.g., storing codes/tokens in a database, validating users against an identity provider).\n\n\n\nProxyOAuthServerProvider (src/server/auth/providers/proxyProvider.ts):\n\nA concrete implementation of OAuthServerProvider provided by the SDK.\nIt acts as a proxy, forwarding OAuth requests to an external, upstream OAuth server (like Auth0, Okta, or your company’s SSO).\nIt simplifies integrating MCP authentication with existing identity infrastructure. You provide the upstream endpoints and implement token verification/client lookup.\n\n\n\nOAuthRegisteredClientsStore (src/server/auth/clients.ts):\n\nAn interface for managing registered OAuth clients (fetching client details by ID, potentially registering new clients dynamically). You provide an implementation (e.g., backed by a database).\n\n\n\nHandlers (src/server/auth/handlers/):\n\nInternal Express request handlers for each OAuth endpoint (authorize.ts, token.ts, etc.), used by mcpAuthRouter. They parse requests, call the appropriate OAuthServerProvider methods, and format responses according to OAuth specs.\n\n\n\nMiddleware (src/server/auth/middleware/):\n\nauthenticateClient: Middleware used by the /token and /revoke endpoints to validate client_id and client_secret sent in the request body (using client_secret_post).\nrequireBearerAuth: Crucially, this middleware is intended to be used on your actual MCP data/tool endpoints (e.g., the /mcp endpoint for Streamable HTTP). It extracts the Authorization: Bearer &lt;token&gt; header, calls provider.verifyAccessToken to validate the token, checks expiration and scopes, and attaches the resulting AuthInfo to req.auth for use in your MCP request handlers.\nallowedMethods: Utility to enforce HTTP methods.\n\n\n\nClient-Side Helpers (src/client/auth.ts):\nThe SDK also provides utilities for clients to interact with OAuth servers (including those built with the SDK’s server components): discovery, starting authorization, exchanging codes, refreshing tokens.\nSummary (TS): The TypeScript SDK provides a near-complete framework for adding a compliant OAuth 2.1 Authorization Server to your MCP application, either self-contained or proxied. requireBearerAuth is the key piece for protecting your MCP Resource/Tool endpoints.\nPython SDK: Leveraging the Ecosystem\nIn stark contrast to the TypeScript SDK, the Python SDK does not currently include a dedicated, built-in OAuth server module comparable to src/server/auth. The src/mcp/shared/auth.py file defines Pydantic models for OAuth concepts (Metadata, Tokens, Client Info), but there’s no equivalent to mcpAuthRouter or OAuthServerProvider.\nHow Would Authentication Work?\nThis implies that developers using the Python SDK need to implement authentication largely themselves, likely by integrating with the broader Python web and authentication ecosystem. Common approaches would include:\n\n\nUsing ASGI Middleware:\n\nThe FastMCP server integrates with ASGI frameworks (Starlette, FastAPI). Authentication would typically be handled by middleware placed before the MCP routes/application.\nLibraries like Authlib, FastAPI&#039;s Security utilities, or custom middleware could be used.\nThis middleware would inspect the Authorization: Bearer &lt;token&gt; header on incoming requests to the MCP endpoint (e.g., /sse and /messages for the SSE transport).\nIt would need to validate the token (potentially by calling an external identity provider’s introspection endpoint or validating a JWT locally).\nValid authentication information (AuthInfo-like data) could potentially be added to the Starlette request’s scope dictionary or a custom request extension for access within MCP handlers.\n\n\n\nImplementing OAuth Endpoints Separately:\n\nIf the MCP server itself needs to act as the OAuth Authorization Server (issuing tokens), the developer would need to implement the /authorize, /token, etc., endpoints manually, likely using a library like Authlib alongside Starlette/FastAPI. These endpoints would live alongside the MCP endpoints (/sse, /messages).\n\n\n\nChecking Auth within Handlers:\n\nWhile less ideal for separation of concerns, authentication could potentially be checked within individual FastMCP tool/resource handlers using the injected Context object. The context might provide access to request headers (depending on the underlying transport and framework integration), allowing manual extraction and validation of the Bearer token. This couples auth logic tightly with business logic.\n\n\n\n# Conceptual Python Example (using hypothetical middleware)\nfrom starlette.applications import Starlette\nfrom starlette.middleware import Middleware\nfrom starlette.middleware.authentication import AuthenticationMiddleware # Example\nfrom starlette.authentication import AuthCredentials, SimpleUser # Example\n \n# --- Hypothetical Auth Backend (using Starlette&#039;s patterns) ---\nclass BearerTokenAuthBackend: # You&#039;d implement this\n    async def authenticate(self, conn):\n        if &quot;authorization&quot; not in conn.headers:\n            return None\n        auth = conn.headers[&quot;authorization&quot;]\n        try:\n            scheme, token = auth.split()\n            if scheme.lower() != &#039;bearer&#039;:\n                return None\n            # *** YOUR TOKEN VALIDATION LOGIC HERE ***\n            # E.g., call external provider, validate JWT\n            # user_info = await validate_my_token(token)\n            # if user_info:\n            #    return AuthCredentials([&quot;authenticated&quot;]), SimpleUser(user_info[&#039;id&#039;])\n            if token == &quot;valid-token-for-test&quot;: # Replace with real validation\n                return AuthCredentials([&quot;authenticated&quot;]), SimpleUser(&quot;user123&quot;)\n        except ValueError:\n            pass # Invalid header format\n        except Exception as e:\n            print(f&quot;Token validation error: {e}&quot;) # Log error\n        return None # Failed validation\n \n# --- MCP Setup ---\nfrom mcp.server.fastmcp import FastMCP, Context\nfrom mcp.server.sse import SseServerTransport\n \nmcp = FastMCP(&quot;MySecureServer&quot;)\nsse_transport = SseServerTransport(&quot;/messages/&quot;)\n \n@mcp.tool()\ndef protected_tool(ctx: Context) -&gt; str:\n    # Access authenticated user from middleware (if populated)\n    if not ctx.request_context.session.scope.get(&quot;user&quot;, None).is_authenticated:\n         raise PermissionError(&quot;Authentication required&quot;)\n    # user = ctx.request_context.session.scope[&quot;user&quot;]\n    # print(f&quot;Executing tool for authenticated user: {user.display_name}&quot;)\n    return &quot;Sensitive data returned&quot;\n \n# --- ASGI App Setup ---\nasync def handle_sse_get(request):\n    async with sse_transport.connect_sse(...) as (r, w):\n        await mcp._mcp_server.run(r, w, ...) # Run MCP logic\n \nmiddleware = [\n    Middleware(AuthenticationMiddleware, backend=BearerTokenAuthBackend())\n]\napp = Starlette(\n    routes=[...], # Your MCP routes using handle_sse_get and sse_transport.handle_post_message\n    middleware=middleware\n)\nSummary (Python): The Python SDK relies on the developer to integrate authentication using standard Python web framework practices (likely ASGI middleware) and external libraries. It provides the Pydantic models for OAuth concepts but not the server-side endpoint implementations or bearer auth middleware.\nComparison: TS vs. Python Authentication Approach\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFeatureTypeScript SDKPython SDKNotesOAuth Server Built-inYes (mcpAuthRouter, OAuthServerProvider)NoTS provides a comprehensive framework out-of-the-box.Bearer Auth MiddlewareYes (requireBearerAuth)No (Requires custom/external middleware)TS explicitly provides middleware for protecting MCP endpoints.Client Auth MiddlewareYes (authenticateClient)No (Requires custom/external middleware)TS provides middleware for validating client_id/secret at token/revoke endpoints.FlexibilityMore opinionated (follows OAuth standard)High (Integrate any auth system via ASGI)Python offers more freedom but requires more manual setup for standard OAuth.Setup Effort (OAuth)Lower (using mcpAuthRouter)Higher (Requires implementing endpoints/middleware)Getting a standard OAuth server running is significantly easier with TS SDK.Proxy SupportBuilt-in (ProxyOAuthServerProvider)Manual Implementation RequiredTS simplifies integration with existing external OAuth providers.\nEnd-User Impact: Security, Trust, and Permissions\nRegardless of the SDK implementation details, robust authentication is paramount for the end user:\n\nSecurity &amp; Privacy: Users can trust that their data exposed via MCP Resources is only accessible by applications they have explicitly authorized. Unauthorized actions via Tools are prevented.\nControl &amp; Consent: OAuth flows allow users to grant specific permissions (scopes) to applications (e.g., “allow Assistant to read calendar” vs. “allow Assistant to read and write calendar”).\nSeamless Experience: When implemented correctly, the complexities of token management (acquisition, refresh, secure storage) are handled by the client application, providing a seamless experience for the user after the initial authorization grant.\nAccountability: Authenticated requests allow for proper auditing and logging, tracing actions back to specific clients or users.\n\nConclusion\nAuthentication is a non-negotiable aspect of building secure and trustworthy MCP applications. The TypeScript and Python SDKs present contrasting philosophies: TypeScript offers a comprehensive, integrated OAuth 2.1 server framework, simplifying standard implementations, while Python relies on the developer to leverage the broader ASGI and authentication library ecosystem for greater flexibility but requiring more manual setup.\nThe TypeScript SDK’s requireBearerAuth middleware (or an equivalent custom implementation in Python) is the critical component for protecting the actual MCP Tool and Resource interactions once a client has obtained an access token. Properly securing these interactions is essential for building user trust and enabling powerful, context-aware AI integrations safely.\nIn our next post, we’ll explore some of the more Advanced Capabilities offered by the SDKs, such as dynamic server updates, context injection, CLI tooling, and resumability. Stay tuned!\n"},"1-Official-py-and-ts-sdk-tutes/Blogs/blog-9":{"slug":"1-Official-py-and-ts-sdk-tutes/Blogs/blog-9","filePath":"1 Official py and ts sdk tutes/Blogs/blog-9.md","title":"Blog 9: Beyond the Basics - Advanced MCP SDK Capabilities","links":["1-Official-py-and-ts-sdk-tutes/Blogs/blog-2","1-Official-py-and-ts-sdk-tutes/Blogs/blog-3","1-Official-py-and-ts-sdk-tutes/Blogs/blog-4","1-Official-py-and-ts-sdk-tutes/Blogs/blog-5","1-Official-py-and-ts-sdk-tutes/Blogs/blog-6","1-Official-py-and-ts-sdk-tutes/Blogs/blog-7","1-Official-py-and-ts-sdk-tutes/Blogs/blog-8"],"tags":[],"content":"Blog 9: Beyond the Basics - Advanced MCP SDK Capabilities\nSeries: Deep Dive into the Model Context Protocol SDKs (TypeScript &amp; Python)\r\nPost: 9 of 10\nWe’ve covered a lot of ground in this series, exploring the core types, server APIs, low-level foundations, client architecture, various transports, Streamable HTTP, and authentication. Now, it’s time to delve into some of the more advanced features and capabilities offered by the TypeScript and Python Model Context Protocol (MCP) SDKs that enable more sophisticated and dynamic applications.\nThese features often differentiate the SDKs and highlight design choices specific to each language ecosystem. We’ll explore:\n\nDynamic Server Updates (TS): Modifying server capabilities after connection.\nContext Injection (Python FastMCP): Accessing request/server state within handlers.\nAutocompletion (TS): Providing suggestions for resource/prompt arguments.\nCLI Tooling (Python): The mcp command for development and Claude Desktop integration.\nResumability (TS Streamable HTTP): Recovering from disconnections.\n\nDynamic Server Capabilities (TypeScript Focus)\nOne of the powerful, explicitly documented features in the TypeScript McpServer is the ability to modify the available Tools, Resources, and Prompts while the server is running and connected to clients.\nHow it Works:\nWhen you register a primitive using mcpServer.tool(), .resource(), or .prompt(), the method returns a handle object (RegisteredTool, RegisteredResource, RegisteredPrompt). These handles expose methods to manage the lifecycle and definition of that primitive after the initial registration and connection:\n\n.enable() / .disable(): Toggles the visibility of the primitive. Disabled items won’t appear in listTools, listResources, etc.\n.update({...}): Allows changing aspects of the primitive, such as:\n\nThe callback function (callback).\nThe input schema (paramsSchema for tools, argsSchema for prompts).\nMetadata like description or annotations.\nFor resources, the underlying URI or ResourceTemplate.\n\n\n.remove(): Completely unregisters the primitive from the server.\n\nThe Notification Link:\nCrucially, whenever you call .enable(), .disable(), .update(), or .remove() on a registered handle after the McpServer is connected to a transport, the server automatically sends the corresponding notifications/.../list_changed message (e.g., notifications/tools/list_changed) to all connected clients. This informs clients that they should refresh their list of available primitives.\n// TypeScript Dynamic Example\nimport { McpServer } from &quot;@modelcontextprotocol/sdk/server/mcp.js&quot;;\nimport { z } from &quot;zod&quot;;\n// ... other imports ...\n \nconst mcpServer = new McpServer(/* ... */);\n \n// Register a tool, get its handle\nconst sensitiveTool = mcpServer.tool(\n  &quot;admin_action&quot;,\n  { targetId: z.string() },\n  async ({ targetId }) =&gt; { /* ... perform action ... */ }\n);\n \n// Initially disabled\nsensitiveTool.disable();\n \n// Connect the server\nconst transport = /* ... create transport ... */;\nawait mcpServer.connect(transport);\n \n// Later, based on authentication or state change:\nasync function checkAuthAndEnableTool(authInfo: AuthInfo | undefined) {\n  if (authInfo?.scopes.includes(&quot;admin&quot;)) {\n    if (!sensitiveTool.enabled) {\n      console.log(&quot;Admin connected, enabling sensitive tool...&quot;);\n      sensitiveTool.enable(); // Client receives notifications/tools/list_changed\n    }\n  } else {\n    if (sensitiveTool.enabled) {\n      console.log(&quot;Non-admin connected, disabling sensitive tool...&quot;);\n      sensitiveTool.disable(); // Client receives notifications/tools/list_changed\n    }\n  }\n}\n \n// Example Update: Change the schema for a prompt\nconst myPrompt = mcpServer.prompt(&quot;my_prompt&quot;, { oldArg: z.string() }, /* ... */);\n// ... server connected ...\nmyPrompt.update({\n  description: &quot;Updated description&quot;,\n  argsSchema: { newArg: z.number() }, // Schema changed!\n  callback: ({ newArg }) =&gt; { /* ... new logic ... */ }\n}); // Client receives notifications/prompts/list_changed\nPython FastMCP:\nThe documentation and examples for Python’s FastMCP don’t explicitly showcase this dynamic update pattern with handles in the same way. While the underlying low-level Server can send list_changed notifications manually (server.send_tool_list_changed(), etc.), dynamically altering the registered decorators after startup isn’t the standard pattern. Achieving similar dynamic behavior in FastMCP might involve:\n\nUsing conditional logic within the tool/resource/prompt functions based on server state.\nPotentially interacting with the internal managers (_tool_manager, etc.), though this is less documented and likely less stable than the TS handle approach.\nManually sending list_changed notifications via the low-level server instance if internal state affecting lists changes.\n\nEnd-User Nuance: Dynamic capabilities allow AI applications to adapt intelligently. An assistant might gain new tools after a user logs in or installs a plugin, or resources might appear/disappear based on the currently active project – all communicated seamlessly via MCP notifications.\nContext Injection (Python FastMCP Focus)\nPython’s FastMCP offers a very convenient way to access request-specific information and server capabilities within your handler functions: the Context object.\nHow it Works:\nYou simply add a parameter to your decorated function and type-hint it as Context. FastMCP automatically injects the appropriate context instance during the request.\n# Python FastMCP Context Example\nfrom mcp.server.fastmcp import FastMCP, Context\nfrom mcp.server.lowlevel.server import LifespanResultT # For lifespan context typing\nfrom mcp.server.session import ServerSessionT # For session typing\n \nmcp = FastMCP(&quot;MyContextServer&quot;)\n \n@mcp.tool()\nasync def complex_operation(item_id: str, ctx: Context) -&gt; str:\n    # Access lifespan state (if lifespan manager is used)\n    # db_conn = ctx.request_context.lifespan_context.db_connection\n \n    # Log messages to the client\n    ctx.info(f&quot;Starting operation for item {item_id} (Request ID: {ctx.request_id})&quot;)\n \n    # Report progress\n    await ctx.report_progress(progress=1, total=3)\n \n    # Read related resource\n    try:\n        resource_iter = await ctx.read_resource(f&quot;items://{item_id}/details&quot;)\n        details = &quot;&quot;.join([r.content for r in resource_iter]) # Assuming text content\n        ctx.debug(f&quot;Read details: {details[:50]}...&quot;)\n    except Exception as e:\n        await ctx.error(f&quot;Failed to read resource: {e}&quot;)\n        return &quot;Error fetching details&quot;\n \n    await ctx.report_progress(progress=2, total=3)\n    # ... perform more work ...\n    await ctx.report_progress(progress=3, total=3)\n \n    return f&quot;Operation complete for {item_id}&quot;\n \n# Get the underlying session for advanced features\n@mcp.tool()\nasync def check_client_caps(ctx: Context) -&gt; bool:\n    session: ServerSessionT = ctx.session # Access the low-level session\n    if session.client_params:\n        print(&quot;Client connected:&quot;, session.client_params.clientInfo)\n        return session.check_client_capability(types.ClientCapabilities(sampling={}))\n    return False\nTypeScript Context:\nWhile McpServer doesn’t have a single unified Context object like FastMCP, the low-level request handlers (Server.setRequestHandler) receive the RequestHandlerExtra object, which contains much of the same information (signal, sessionId, requestId, authInfo, _meta) and helper methods (sendNotification, sendRequest). If using McpServer, the callbacks for .tool(), .resource(), and .prompt() also receive this extra object as their last argument.\nComparison: Python’s Context object injected via type hint is arguably more ergonomic and discoverable for the common high-level use case within FastMCP. TypeScript requires passing the extra object explicitly in the high-level API callbacks or accessing it directly in low-level handlers.\nEnd-User Nuance: Context allows servers to provide better feedback (logging, progress) and perform more complex, state-aware operations, leading to more responsive and capable AI interactions for the user.\nAutocompletion (TypeScript Focus)\nThe TypeScript SDK includes a mechanism for providing autocompletion suggestions for arguments within Resource Templates and Prompts.\nHow it Works:\n\nCompletable (src/server/completable.ts): A wrapper around a Zod schema (completable(z.string(), ...)) that attaches a complete callback function.\nRegistration: You use this Completable schema when defining arguments for a ResourceTemplate or a McpServer.prompt.\nHandling: McpServer automatically registers a handler for the completion/complete MCP request. When a client sends this request for a specific argument of a prompt or resource template, the server finds the registered Completable schema and invokes its complete callback (passing the current partial value entered by the user).\nResponse: The server formats the suggestions returned by the callback into a CompleteResult message.\n\n// TypeScript Autocompletion Example\nimport { completable } from &quot;@modelcontextprotocol/sdk/server/completable.js&quot;;\nimport { ResourceTemplate } from &quot;@modelcontextprotocol/sdk/server/mcp.js&quot;;\n \nconst allCategories = [&quot;books&quot;, &quot;movies&quot;, &quot;music&quot;, &quot;games&quot;];\n \n// Resource Template with completable argument\nmcpServer.resource(\n  &quot;items_by_category&quot;,\n  new ResourceTemplate(&quot;items://{category}&quot;, {\n    list: undefined,\n    // Define completion logic for the &#039;category&#039; variable\n    complete: {\n      category: (partialValue) =&gt;\n        allCategories.filter(cat =&gt; cat.startsWith(partialValue))\n    }\n  }),\n  async (uri, { category }) =&gt; { /* ... fetch items ... */ }\n);\n \n// Prompt with completable argument\nmcpServer.prompt(\n  &quot;search_items&quot;,\n  {\n    // Wrap the Zod schema with completable\n    category: completable(\n      z.enum([&quot;books&quot;, &quot;movies&quot;, &quot;music&quot;, &quot;games&quot;]), // Base schema\n      (partialValue) =&gt; // Completion callback\n        allCategories.filter(cat =&gt; cat.startsWith(partialValue))\n    ).describe(&quot;The category to search within&quot;),\n    query: z.string()\n  },\n  async ({ category, query }) =&gt; { /* ... create prompt messages ... */ }\n);\nPython Equivalent:\nThe Python SDK (FastMCP or low-level Server) doesn’t appear to have a direct, built-in equivalent to the Completable wrapper and automatic completion/complete handler registration. Implementing autocompletion would likely require:\n\nManually registering a handler for completion/complete using the low-level @server.completion() decorator (if available, or @server.request_handler otherwise).\nStoring metadata about which arguments are completable and their associated completion functions alongside the tool/prompt/resource definitions.\nImplementing the logic within the completion/complete handler to look up the correct completion function based on the request’s ref and argument parameters and call it.\n\nEnd-User Nuance: Autocompletion significantly improves the usability of complex tools or resources with predefined argument values (like categories, file paths, user names), guiding the user (or the LLM) towards valid inputs.\nCLI Tooling (Python Focus)\nThe Python SDK ships with a powerful command-line tool, mcp, built using typer. This tool streamlines common development and deployment workflows, especially for users of the Claude Desktop application.\nKey Commands:\n\nmcp run &lt;file_spec&gt;: Directly runs an MCP server defined in a Python file (e.g., python my_server.py equivalent, but integrated). It imports and calls the .run() method on the discovered server object (mcp, server, or app by default, or specified via file:object).\nmcp dev &lt;file_spec&gt; [--with &lt;dep&gt;] [--with-editable &lt;path&gt;]: Runs the server in development mode, typically launching it alongside the MCP Inspector tool (npx @modelcontextprotocol/inspector ...). It uses uv run --with ... internally to manage a temporary virtual environment, installing the base mcp package plus any declared server dependencies (--with) or editable installs (--with-editable).\nmcp install &lt;file_spec&gt; [--name &lt;name&gt;] [--with &lt;dep&gt;] [--with-editable &lt;path&gt;] [-v KEY=VAL] [-f .env]: This is the key integration point with Claude Desktop.\n\nIt locates the Claude Desktop configuration file (claude_desktop_config.json).\nIt adds or updates an entry for the specified MCP server.\nIt constructs the correct uv run [...] mcp run &lt;file_spec&gt; command, including necessary --with and --with-editable flags based on declared/provided dependencies.\nIt allows setting environment variables (-v or -f) specific to that server entry in the Claude config.\nThe server_name defaults intelligently (server’s .name attribute or file stem).\n\n\n\nImplementation (src/mcp/cli/):\n\ncli.py: Defines the typer application and commands.\nclaude.py: Contains logic for finding the Claude config path (get_claude_config_path) and updating the JSON configuration (update_claude_config).\n\nTypeScript Equivalent:\nThe TS SDK has a much simpler src/cli.ts, which primarily acts as a basic command-line runner for example client/server setups, mainly using the Stdio transport. It lacks the sophisticated environment management and Claude Desktop integration of the Python CLI.\nEnd-User/Developer Nuance: The Python mcp CLI significantly enhances the developer workflow, especially for FastMCP users and those targeting Claude Desktop. mcp dev provides an integrated testing environment, while mcp install makes deploying local or custom servers to the Claude Desktop app trivial, handling dependency installation automatically via uv.\nResumability (TypeScript Streamable HTTP Focus)\nAs detailed in Blog 7, resumability is a built-in feature of the TypeScript SDK’s StreamableHTTPServerTransport when configured with an EventStore. It ensures clients can recover from disconnections during long-running operations without missing messages. While not a separate API feature, it’s an advanced capability tied to the transport choice. The Python SDK’s SSE transport lacks this built-in mechanism.\nConclusion\nThe advanced capabilities of the MCP SDKs showcase their potential beyond simple request-response interactions. TypeScript’s McpServer provides explicit control over the dynamic lifecycle of server primitives and built-in support for argument autocompletion. Python’s FastMCP, coupled with its mcp CLI, offers a highly ergonomic development experience with seamless context injection and effortless integration into environments like Claude Desktop. Resumability, currently a key feature of TypeScript’s Streamable HTTP transport, enhances robustness for web-based applications.\nUnderstanding these advanced features allows developers to build more sophisticated, dynamic, user-friendly, and resilient MCP applications.\nIn our final post, we’ll synthesize everything we’ve learned, comparing the overall developer experience, discussing ideal use cases for each SDK, and looking towards the future of MCP.\n"},"1-Official-py-and-ts-sdk-tutes/README":{"slug":"1-Official-py-and-ts-sdk-tutes/README","filePath":"1 Official py and ts sdk tutes/README.md","title":"README","links":[],"tags":[],"content":"\nOfficial py and ts sdk tutes\n"},"1-Official-py-and-ts-sdk-tutes/index":{"slug":"1-Official-py-and-ts-sdk-tutes/index","filePath":"1 Official py and ts sdk tutes/index.md","title":"1 Official py and ts sdk tutes","links":[],"tags":[],"content":""},"2-Official-c-and-java-sdk-tutes/029_model":{"slug":"2-Official-c-and-java-sdk-tutes/029_model","filePath":"2 Official c# and java sdk tutes/029_model.md","title":"029_model","links":[],"tags":[],"content":"Okay, let’s analyze the modelcontextprotocol-java-sdk project.\nProject Overview:\nThis repository contains the official Java SDK for the Model Context Protocol (MCP). It aims to provide Java developers with the necessary libraries and abstractions to build MCP clients and servers within the Java Virtual Machine (JVM) ecosystem. It leverages standard Java practices, Maven for building, and offers integrations with the popular Spring Framework (both WebFlux and WebMvc).\nCore Concepts &amp; Purpose:\n\nMCP Implementation: Provide an idiomatic Java implementation of the MCP specification.\nClient/Server: Clear separation into client (mcp/src/.../client) and server (mcp/src/.../server) components.\nSync/Async Duality: A significant design choice is the provision of both synchronous (McpSyncClient, McpSyncServer) and asynchronous (McpAsyncClient, McpAsyncServer) APIs, catering to different Java programming styles. The asynchronous API is built using Project Reactor (Mono, Flux).\nTransport Abstraction: Defines core transport interfaces (McpTransport, McpClientTransport, McpServerTransport, McpServerTransportProvider) in the spec/ package.\nTransport Implementations: Provides implementations for Stdio and HTTP+SSE. Notably, specific integrations for Servlet API (HttpServletSseServerTransportProvider), Spring WebFlux (WebFluxSseClientTransport, WebFluxSseServerTransportProvider), and Spring WebMvc (WebMvcSseServerTransportProvider) are offered in dedicated modules. Similar to the Python SDK, it appears to focus on the HTTP+SSE transport model rather than the newer Streamable HTTP.\nProtocol Handling: The core session logic likely resides in McpSession, McpClientSession, and McpServerSession within the spec/ package, managing JSON-RPC, request/response mapping, and lifecycle.\nSchema Representation: Uses Plain Old Java Objects (POJOs) with Jackson annotations (@JsonProperty, @JsonSubTypes, etc.) in spec/McpSchema.java to define the MCP message structures.\nBuild System: Uses Apache Maven (pom.xml, mvnw).\nModularity: Structured as a Maven multi-module project (mcp core, mcp-bom, mcp-spring-*, mcp-test).\n\nKey Features &amp; Implementation Details:\n\n\nCore Module (mcp/):\n\nspec/: Contains the foundational interfaces (McpTransport, McpSession, etc.) and the crucial McpSchema.java file defining all MCP message types as nested records/classes using Jackson annotations. This is the Java equivalent of types.ts/types.py.\nclient/: Implements McpAsyncClient (Reactor-based) and McpSyncClient (blocking wrapper). Contains transport implementations for Stdio (StdioClientTransport) and a base HTTP SSE client (HttpClientSseClientTransport).\nserver/: Implements McpAsyncServer and McpSyncServer. Crucially, it uses a Transport Provider pattern (McpServerTransportProvider interface). Implementations like StdioServerTransportProvider and HttpServletSseServerTransportProvider are responsible for accepting connections and creating per-session McpServerTransport instances, which are then managed by an McpServerSession. This differs from the TS/Python approach where the server often directly manages a single transport instance (like Stdio) or integrates with web framework request handlers.\nutil/: Contains utility classes, including URI template handling.\n\n\n\nSpring Integration Modules (mcp-spring/):\n\nmcp-spring-webflux/: Provides WebFluxSseClientTransport (using Spring WebClient) and WebFluxSseServerTransportProvider (integrating with WebFlux functional routing for SSE). Tailored for reactive Spring applications.\nmcp-spring-webmvc/: Provides WebMvcSseServerTransportProvider, integrating the SSE server transport with traditional Spring MVC (Servlet API).\n\n\n\nBill of Materials (mcp-bom/):\n\nA Maven BOM (pom.xml) to manage dependency versions consistently across the different SDK modules.\n\n\n\nTesting Module (mcp-test/):\n\nProvides shared testing utilities like MockMcpTransport and abstract base classes for client/server tests (AbstractMcpAsyncClientTests, AbstractMcpSyncClientTests), promoting consistent testing patterns across different transport implementations.\n\n\n\nTransports:\n\nStdio: Client (StdioClientTransport) launches a process; Server Provider (StdioServerTransportProvider) reads/writes from System.in/System.out.\nHTTP+SSE: This seems to be the primary web transport model.\n\nClient: Core HttpClientSseClientTransport (using java.net.http.HttpClient) and a Spring-specific WebFluxSseClientTransport (using WebClient). Both implement the dual-endpoint SSE logic (GET for events, POST for messages).\nServer: Relies on McpServerTransportProvider implementations. HttpServletSseServerTransportProvider for generic Servlet containers (like Tomcat), WebFluxSseServerTransportProvider for reactive Spring, and WebMvcSseServerTransportProvider for traditional Spring MVC. All implement the dual-endpoint SSE logic.\n\n\nStreamable HTTP: No apparent direct implementation matching the single-endpoint, resumable transport found in the TypeScript SDK.\nWebSocket: No dedicated WebSocket transport implementation is visible in the core or Spring modules.\n\n\n\nTooling &amp; Ecosystem:\n\nBuild: Maven.\nTesting: JUnit 5, Mockito, AssertJ, Reactor-Test, Testcontainers (for running external servers like the Everything Server docker image).\nJSON: Jackson.\nAsync: Project Reactor (Mono/Flux).\nLogging: SLF4J facade, Logback for testing.\nDocumentation: Planned via docfx (config present, but /docs seems minimal currently).\n\n\n\nDeveloper Experience:\n\nOffers both familiar blocking (Sync) APIs and modern reactive (Async) APIs.\nStrong integration with the Spring ecosystem is a major focus.\nRelies on standard Java patterns (interfaces, factories, builders).\nLess emphasis on a high-level, declarative API like FastMCP (Python) or method-chaining registration like McpServer (TS). Server configuration seems more focused on passing handler maps/lists to the builder.\nNo dedicated CLI tool comparable to Python’s mcp command.\n\n\n\nStrengths:\n\nIdiomatic Java: Leverages standard Java practices, Maven, and common libraries (Jackson, SLF4J).\nSync/Async Choice: Caters to both traditional blocking and modern reactive Java developers.\nSpring Ecosystem Integration: Dedicated modules provide first-class support for both Spring WebFlux and WebMvc, simplifying adoption in Spring-based applications.\nRobust Testing: Comprehensive test suite using standard Java testing tools and Testcontainers.\nModularity: Clear separation of core logic, Spring integrations, and testing utilities via Maven modules.\n\nDifferences from TypeScript/Python SDKs:\n\nPrimary HTTP Transport: Like Python, focuses on HTTP+SSE, lacking the Streamable HTTP transport and its built-in resumability found in TypeScript.\nAPI Style: Offers distinct Sync/Async APIs. Server configuration relies more on configuring and passing handler collections/features objects rather than extensive use of decorators (Python) or direct registration methods (TS McpServer).\nFramework Integration: Strong focus on Spring. While adaptable, it doesn’t have the generic ASGI integration ease of Python or the framework-agnostic nature of the TS SDK (which requires manual integration).\nReactive Library: Uses Project Reactor, the standard in the Spring ecosystem (vs. RxJS/Node async in TS, anyio in Python).\nType Definition: Uses Java POJOs + Jackson (vs. Zod in TS, Pydantic in Python).\nCLI Tooling: No dedicated developer CLI provided.\nOAuth: Similar to Python, lacks a built-in OAuth server framework like TypeScript’s. Authentication would rely on standard Java/Spring Security mechanisms.\nDynamic Capabilities: No obvious high-level API for dynamically adding/removing/updating tools/resources after the server starts, unlike the TypeScript SDK.\n\nConclusion:\nThe modelcontextprotocol-java-sdk provides a solid and idiomatic foundation for Java developers to build MCP clients and servers. Its key strengths lie in its choice of synchronous or asynchronous APIs (catering to different development styles) and its deep integration with the Spring Framework (WebFlux and WebMvc). It uses standard Java tooling (Maven, Jackson, SLF4J) and includes a robust testing strategy.\nCompared to its counterparts, it currently prioritizes the established HTTP+SSE transport model over the newer Streamable HTTP standard found in the TypeScript SDK, meaning it lacks built-in resumability for web transports. It also doesn’t offer the same level of built-in OAuth server functionality as the TS SDK or the developer-focused CLI tooling found in the Python SDK. Developers will need to leverage the broader Java/Spring ecosystem for advanced authentication and potentially for dynamic capability management.\nIt’s a well-suited choice for Java shops, especially those already using Spring, who want to integrate MCP capabilities into their applications using familiar patterns."},"2-Official-c-and-java-sdk-tutes/031_model":{"slug":"2-Official-c-and-java-sdk-tutes/031_model","filePath":"2 Official c# and java sdk tutes/031_model.md","title":"031_model","links":[],"tags":[],"content":"Okay, here’s a plan for a 10-part blog series focusing on the C# and Java MCP SDKs, diving into their internals, comparing them, and discussing the implications for end-users.\nTarget Audience: Developers working in the .NET or JVM ecosystems, architects evaluating MCP, developers interested in cross-language SDK design within enterprise environments.\nOverall Goal: To provide a deep, comparative understanding of the C# and Java MCP SDKs, exploring their design patterns, integration points, internal mechanisms, and how they enable developers to build robust, context-aware AI applications for end-users within their respective platforms.\n\nBlog Series: Bridging AI Context - A Deep Dive into the MCP C# and Java SDKs\nBlog 1: Introduction - Setting the Stage for .NET and Java MCP\n\nCore Focus: Introduce MCP, the need for SDKs in enterprise environments (.NET/JVM), and outline the series comparing the C# and Java implementations.\nKey Topics:\n\nRecap: What is MCP and the problem it solves?\nWhy dedicated C# and Java SDKs? Targeting enterprise ecosystems.\nHigh-level tour: modelcontextprotocol-csharp-sdk vs. modelcontextprotocol-java-sdk structures (Maven vs. .NET Sln/Proj, core modules, testing, samples).\nIntroducing core concepts via the SDKs: Tools, Resources, Prompts.\nThe end-user goal: Seamless, secure, contextual AI integration.\n\n\nSDK Comparison: Initial impressions based on project structure and build systems (Maven vs. MSBuild/NuGet). Mentioning the explicit Sync/Async split in Java.\nEnd-User Nuance: How mature enterprise platforms (.NET, Java) integrating MCP can bring powerful AI context to existing business applications.\n\nBlog 2: Defining the Contract - MCP Schemas in C# and Java\n\nCore Focus: How MCP message types are defined and validated using platform-idiomatic approaches.\nKey Topics:\n\nC#: POCOs (Plain Old C# Objects) likely defined in src/ModelContextProtocol/Protocol/Types/. Use of System.Text.Json attributes ([JsonPropertyName]). Source Generators (JsonSerializable) for AOT/performance. Nullability (?). Records vs. Classes.\nJava: POJOs (Plain Old Java Objects) in mcp/src/.../spec/McpSchema.java. Use of Jackson annotations (@JsonProperty, @JsonSubTypes, @JsonTypeInfo). Inner classes/records for structure.\nRepresenting core JSON-RPC types (Request, Response, Notification, Error).\nModeling MCP primitives (Tool, Resource, Prompt, Content types) in each language.\nHandling unions (e.g., ResourceContents) using JsonConverter (C#) vs. Jackson’s @JsonSubTypes (Java).\n\n\nSDK Comparison: System.Text.Json (with source generators) vs. Jackson. Attribute usage. Handling of nullability and collections. POCOs vs. POJOs. Impact on performance (potential AOT benefits in C#).\nEnd-User Nuance: Type safety in both languages prevents runtime errors due to unexpected data, leading to more reliable interactions for users relying on MCP-powered features.\n\nBlog 3: Server APIs - Building Blocks (.NET DI vs. Java Builders)\n\nCore Focus: The primary ways developers configure and build MCP servers.\n\nKey Topics:\nC#: Integration with Microsoft.Extensions.DependencyInjection. The IMcpServerBuilder interface and extension methods (.AddMcpServer(), .WithTools&lt;T&gt;(), .WithPrompts&lt;T&gt;(), .WithHttpTransport(), .WithStdioServerTransport()). Attribute-based discovery ([McpServerToolType], [McpServerTool]).\nJava: Builder pattern (McpServer.sync(...), McpServer.async(...)). Methods like .tools(...), .resources(...), .prompts(...) taking lists/maps of handler “Specifications” (AsyncToolSpecification, etc.). Less reliance on attributes for discovery in the core API (though samples might use them).\nHow Tools, Resources, and Prompts are registered and associated with handler logic in each SDK.\nServer configuration (McpServerOptions in both).\n\n\nSDK Comparison: DI/Builder extensions (C#) vs. explicit Builder pattern (Java). Attribute-based discovery (C#) vs. manual registration via builder (Java core). Configuration approaches.\nEnd-User Nuance: These APIs allow developers to quickly expose application logic as MCP primitives, enabling faster development of AI features like “summarize this document” (Resource) or “schedule meeting” (Tool) within existing enterprise apps.\n\nBlog 4: Server Internals - Sessions, Handlers, and Lifecycles\n\nCore Focus: The internal architecture managing client connections and request dispatching.\nKey Topics:\n\nC#: The McpServer class, its use of McpSession, and integration with ITransport. Request handling via RequestHandlers dictionary internally. DI scope management (ScopeRequests option). RequestContext.\nJava: The McpAsync/SyncServer classes wrapping the core McpServerSession. The McpServerTransportProvider pattern (separating connection acceptance from session transport). The McpAsync/SyncServerExchange objects passed to handlers.\nRequest/Response correlation, notification dispatch.\nError handling within the session/server core.\nServer Lifecycles (less explicit in provided files, potentially tied to Host lifetime in C# or manual start/stop in core Java).\n\n\nSDK Comparison: C#‘s DI integration vs. Java’s Transport Provider pattern. Context object (RequestContext vs. Mcp*ServerExchange). Internal session management (McpSession vs. McpServerSession). Java’s explicit Sync/Async server classes.\nEnd-User Nuance: A well-architected server core ensures that multiple users (clients) can interact reliably and concurrently with MCP features without interfering with each other.\n\nBlog 5: Client APIs - Consuming MCP Services in .NET and Java\n\nCore Focus: How client applications connect and make requests using the SDKs.\nKey Topics:\n\nC#: IMcpClient interface. McpClientFactory.CreateAsync. High-level extension methods (.ListToolsAsync, .CallToolAsync, .ReadResourceAsync, etc.). McpClientTool wrapping AIFunction. McpClientOptions.\nJava: McpAsyncClient and McpSyncClient. McpClient.async/sync builders. Methods like .callTool(), .listResources(). McpClientFeatures for configuration.\nInitialization (initialize() in Java, automatic in C# factory).\nHandling responses and McpError/McpException.\nReceiving notifications (RegisterNotificationHandler in C#, handler maps in Java session).\n\n\nSDK Comparison: Factory pattern (C#) vs. Builder pattern (Java). Extension methods (C#) vs. direct methods (Java). Integration with Microsoft.Extensions.AI (AIFunction) in C#. Java’s explicit Sync/Async client classes.\nEnd-User Nuance: These client APIs enable developers to build applications (e.g., internal dashboards, custom agents) that can seamlessly pull context or trigger actions from any MCP server, standardizing integration efforts.\n\nBlog 6: Local Channels - The Stdio Transport\n\nCore Focus: Implementing local client-server communication via standard input/output.\nKey Topics:\n\nC#: StdioClientTransport (uses System.Diagnostics.Process). StdioServerTransport (wraps Console.OpenStandardInput/Output). StdioClientTransportOptions.\nJava: StdioClientTransport (uses java.lang.ProcessBuilder). StdioServerTransportProvider (uses System.in/System.out). ServerParameters class.\nProcess creation and management nuances in each platform.\nMessage framing (newline-delimited JSON).\nUse cases: Local development, desktop app integrations (like Claude Desktop concept, though no specific CLI tool in C#/Java SDKs).\n\n\nSDK Comparison: Core mechanism is similar. Differences lie in the specific process/stream handling APIs used (System.Diagnostics.Process vs. ProcessBuilder, .NET Streams vs. Java Streams). C# integrates via DI/Hosting; Java uses the Transport Provider pattern.\nEnd-User Nuance: Stdio enables secure execution of local tools or access to local files by an AI assistant without network exposure, powerful for developer tools or personalized agents.\n\nBlog 7: Web Transports - HTTP+SSE Focus (Java) vs. ASP.NET Core Integration (C#)\n\nCore Focus: How the SDKs handle HTTP-based communication, noting the apparent divergence in primary approach.\nKey Topics:\n\nJava (HTTP+SSE): Deep dive into HttpClientSseClientTransport (client) and the server-side providers (HttpServletSseServerTransportProvider, WebFluxSseServerTransportProvider, WebMvcSseServerTransportProvider). Dual endpoint logic (GET for SSE, POST for messages). Use of java.net.http.HttpClient, Reactor (WebFluxSseClient), or Servlets.\nC# (ASP.NET Core &amp; Streamable HTTP?): Focus on ModelContextProtocol.AspNetCore. The WithHttpTransport() builder extension and MapMcp() endpoint mapping. How it likely leverages Kestrel and ASP.NET Core routing/middleware. Assumption: This primarily implements Streamable HTTP given the single map call and modern ASP.NET Core patterns (Needs verification against internal StreamableHttpHandler/SseHandler if possible, or test behavior). Discuss potential support for older SSE style via separate handlers if present. Resumability features (if using Streamable HTTP).\n\n\nSDK Comparison: Java’s explicit focus on the older HTTP+SSE spec via multiple provider implementations (Servlet, WebFlux, WebMvc). C#‘s tighter integration with ASP.NET Core, likely favoring the newer Streamable HTTP spec (single endpoint, potential resumability).\nEnd-User Nuance: C#‘s likely Streamable HTTP approach offers potential for more resilient web interactions (resumability). Java’s SSE is well-established but less efficient. The choice impacts how web-based clients interact with servers built using these SDKs.\n\nBlog 8: Framework Integration - ASP.NET Core vs. Spring/Servlets\n\nCore Focus: How the SDKs integrate with their dominant web frameworks.\nKey Topics:\n\nC#: The ModelContextProtocol.AspNetCore project. AddMcpServer(), WithHttpTransport(), MapMcp(). How it leverages ASP.NET Core’s routing, DI, hosting (IHostedService), and potentially middleware pipeline. Configuration via HttpServerTransportOptions. Idle session tracking (IdleTrackingBackgroundService).\nJava: The mcp-spring-webflux and mcp-spring-webmvc modules. WebFluxSseServerTransportProvider using functional routes. WebMvcSseServerTransportProvider likely adapting SSE to the Servlet API (perhaps using async servlets). Integration with Spring’s DI and configuration.\nHow authentication would typically be layered in using standard framework features (ASP.NET Core Authentication/Authorization vs. Spring Security).\n\n\nSDK Comparison: C# offers a more unified ASP.NET Core integration package. Java provides distinct modules for reactive (WebFlux) and traditional (WebMvc) Spring approaches, plus a basic Servlet provider. DI integration patterns in both ecosystems.\nEnd-User Nuance: Deep framework integration simplifies deployment and management for developers using these platforms, leading to more robust and scalable MCP services within existing application architectures.\n\nBlog 9: Advanced Capabilities &amp; Ecosystem Fit\n\nCore Focus: Features beyond basic request/response, and how the SDKs fit their ecosystems.\nKey Topics:\n\nSync vs. Async (Java): Deeper dive into the pros and cons of Java’s dual API approach. When to choose which? Impact on application design.\nDependency Injection (C#): How tools/prompts can receive dependencies (HttpClient, custom services) via constructors or method parameters when registered with DI.\nExtensibility: How easy is it to add custom transports or handlers? (Likely via implementing core interfaces).\nTesting: The role of mcp-test (Java) and testing utilities in C# (TestServerTransport, KestrelInMemoryTransport). Promoting testable designs.\nMissing Features (Compared to TS): Reiterate the apparent lack of built-in OAuth server, explicit dynamic update handles, and autocompletion in C#/Java core SDKs. Discuss how these might be achieved using platform features.\nMicrosoft.Extensions.AI Integration (C#): The synergy between McpClientTool (as an AIFunction) and IChatClient.\n\n\nSDK Comparison: Java’s explicit Sync/Async split. C#‘s strong DI-first approach for handlers. Testing support patterns. Feature gaps compared to the TypeScript SDK.\nEnd-User Nuance: The choice of Sync/Async (Java) impacts server responsiveness under load. DI (C#) allows tools to leverage existing application services easily. Robust testing frameworks ensure higher quality end-user applications.\n\nBlog 10: Synthesis - .NET vs. JVM Developer Experience, Use Cases &amp; Future\n\nCore Focus: Summarize, compare DX, map to use cases, and look ahead.\nKey Topics:\n\nRecap of key architectural differences (Transports, API styles, Framework integration, Auth).\nDeveloper Experience (.NET vs. JVM): Build tools (MSBuild/NuGet vs. Maven), IDE support, standard libraries, community/ecosystem factors. Learning curve.\nUse Cases Revisited:\n\nEnterprise Integration: Both are strong contenders, choice depends on existing stack (Java/Spring vs. .NET/ASP.NET Core).\nHigh-Performance Services: Both offer async models; specific benchmarks would be needed. C#‘s AOT potential might be relevant.\nDesktop Tools (Non-Claude): Stdio in both works, packaging/deployment differ.\n\n\nCross-Platform Interoperability: Emphasize that clients/servers from different SDKs can communicate if using compatible transports (like Stdio or HTTP+SSE).\nPotential Future Directions: Will Java/C# adopt Streamable HTTP more fully? Will auth helpers emerge? Community growth?\n\n\nSDK Comparison: Final thoughts on idiomatic approaches, strengths (C# DI/ASP.NET, Java Spring/Sync+Async), and current feature sets.\nEnd-User Nuance: Ultimately, both SDKs empower developers on major enterprise platforms to build powerful, context-integrated AI solutions, bringing sophisticated capabilities previously locked within specific applications directly into the user’s AI-assisted workflow.\n\n\nThis plan provides a detailed roadmap, ensuring each post covers specific internal aspects, draws direct comparisons between the C# and Java SDKs, and connects the technical implementation to the value delivered to the end user. Remember to populate each post with relevant code examples from the SDKs and samples."},"2-Official-c-and-java-sdk-tutes/Blogs/blog-1":{"slug":"2-Official-c-and-java-sdk-tutes/Blogs/blog-1","filePath":"2 Official c# and java sdk tutes/Blogs/blog-1.md","title":"Blog 1: Setting the Stage for .NET and Java MCP - Bridging AI Context in Enterprise","links":[],"tags":[],"content":"Blog 1: Setting the Stage for .NET and Java MCP - Bridging AI Context in Enterprise\nSeries: Deep Dive into the Model Context Protocol SDKs (C# &amp; Java)\r\nPost: 1 of 10\nThe AI revolution, particularly the rise of powerful Large Language Models (LLMs), promises to transform how we interact with software. Yet, a fundamental challenge remains: these models often operate in a vacuum, isolated from the rich context of our specific tasks, projects, and application data. How can an AI assistant truly assist if it doesn’t know which document you’re editing, which customer record you’re viewing, or what your company’s internal APIs can do?\nThe Model Context Protocol (MCP) (Website, Specification) emerges as a vendor-neutral, open standard designed to solve this very problem. It defines a structured way for applications (acting as “servers”) to securely expose their contextual data and functional capabilities to LLM-powered applications (acting as “clients”).\nWhy MCP Matters for .NET and Java Developers\nWhile exciting AI developments often happen in Python or TypeScript ecosystems, the vast majority of enterprise applications, internal tools, and backend services run on robust, established platforms like .NET (C#) and the Java Virtual Machine (JVM). Bringing the power of contextual AI to these environments requires dedicated, idiomatic tools.\nThis is where the official MCP C# SDK and MCP Java SDK come in. They are the bridges allowing developers on these critical platforms to:\n\nExpose Context: Allow existing .NET and Java applications to securely share relevant data (files, database records, application state) as Resources.\nExpose Capabilities: Enable applications to offer specific functions (API calls, calculations, automations) as Tools that AI clients can invoke.\nDefine Interactions: Create reusable Prompts to guide AI interactions in a structured way.\nConsume Context: Build .NET or Java applications (clients) that can intelligently leverage the tools and resources offered by any MCP-compliant server.\n\nThis blog series will take a deep dive into these two SDKs, exploring their internal architecture, comparing their design choices, and understanding how they empower developers to build the next generation of context-aware AI applications on the .NET and JVM platforms.\nSDKs: The Developer’s Toolkit for MCP\nImplementing the MCP specification from scratch involves handling:\n\nJSON-RPC 2.0 message framing and validation.\nTransport layer negotiation and management (Stdio, HTTP/SSE, potentially others).\nRequest/Response correlation and ID management.\nAsynchronous communication patterns.\nCapability negotiation during initialization.\nError handling according to the spec.\n\nThe SDKs abstract away this complexity, providing:\n\nType-Safe Models: Representing MCP messages using C# classes/records or Java POJOs, often with validation.\nTransport Implementations: Ready-to-use components for Stdio and HTTP-based communication.\nSession Management: Handling the lifecycle of client-server connections.\nHigh-Level APIs: Simplifying the definition of Tools, Resources, and Prompts.\nFramework Integration: Hooks and helpers for common frameworks like ASP.NET Core (C#) and Spring (Java).\n\nA Glimpse Inside the Repositories\nLet’s take a quick tour of the project structures, which reveal common patterns and platform-specific choices:\nmodelcontextprotocol-csharp-sdk: (GitHub)\n\nSolution/Projects (.sln, .csproj): Standard .NET project structure.\nsrc/ModelContextProtocol/: The core SDK library.\n\nClient/: Client-side logic (IMcpClient, McpClientFactory).\nServer/: Server-side logic (IMcpServer, McpServerTool, McpServerPrompt, DI builders).\nProtocol/: Defines the message types (Types/), transport abstractions (Transport/), and core session logic (Shared/). Uses System.Text.Json.\nConfiguration/: Dependency Injection extensions (AddMcpServer, WithTools, etc.).\n\n\nsrc/ModelContextProtocol.AspNetCore/: Specific integration for ASP.NET Core web servers (MapMcp, Streamable HTTP/SSE handlers).\nsamples/: Example projects demonstrating client and server usage, including ASP.NET Core integration.\nBuild: Relies on dotnet build / MSBuild. NuGet for packaging.\n\nmodelcontextprotocol-java-sdk: (GitHub)\n\nMaven Structure (pom.xml): Standard Java multi-module Maven project.\nmcp/: The core SDK module.\n\nclient/: Client logic (McpAsyncClient, McpSyncClient), Stdio and HTTP+SSE transports.\nserver/: Server logic (McpAsyncServer, McpSyncServer), Transport Providers (StdioServerTransportProvider, HttpServletSseServerTransportProvider).\nspec/: Core interfaces (McpTransport, McpSession) and the crucial McpSchema.java defining message POJOs using Jackson annotations.\nutil/: Utility classes.\n\n\nmcp-spring/: Modules for specific Spring integrations.\n\nmcp-spring-webflux/: Reactive SSE transports using Spring WebFlux.\nmcp-spring-webmvc/: SSE transport provider for traditional Spring MVC (Servlet API).\n\n\nmcp-bom/: Maven Bill of Materials for dependency management.\nmcp-test/: Shared testing utilities.\nBuild: Apache Maven (mvnw).\n\nCommon Themes:\n\nClear client/server separation.\nCore protocol types defined centrally.\nTransport abstraction.\nFocus on both Stdio and HTTP-based communication.\nExtensive test suites.\n\nKey Differences at First Glance:\n\nBuild System: Maven (Java) vs. .NET SDK/MSBuild/NuGet (C#).\nWeb Integration: Dedicated Spring modules (Java) vs. a unified ASP.NET Core module (C#).\nAsync Model: Explicit Sync/Async APIs (Java) vs. standard async/await/Task (C#).\nConfiguration: Java uses a builder pattern more heavily; C# leans heavily on Dependency Injection extensions.\n\nCore MCP Primitives - The C#/Java Flavor\nThe SDKs provide idiomatic ways to work with the core MCP ideas:\n\nResources: Exposing data.\n\nC#: Likely involves registering handlers via the IMcpServerBuilder (e.g., .WithListResourcesHandler, .WithReadResourceHandler) or potentially attribute-based discovery on classes.\nJava: Configured via the McpServer builder, passing Async/SyncResourceSpecification objects containing the resource metadata and the handler function.\nEnd-User Nuance: An inventory management app (Java or C#) exposes product details via products://{sku}. An AI assistant can then fetch this data when a user asks “Tell me about product SKU 12345.”\n\n\nTools: Exposing actions.\n\nC#: Primarily via attribute-based discovery ([McpServerToolType], [McpServerTool]) and DI integration. Methods marked with attributes become tools. DI injects services (HttpClient, etc.) and context (IMcpServer, RequestContext). McpClientTool integrates with Microsoft.Extensions.AI’s AIFunction.\nJava: Configured via the McpServer builder, passing Async/SyncToolSpecification objects containing tool metadata (name, description, schema) and the handler function. The handler receives an Exchange object for context.\nEnd-User Nuance: A C# service exposing a schedule_meeting tool allows an AI meeting assistant to directly book appointments based on user conversation, leveraging the service’s connection to Office 365/Google Calendar via injected services.\n\n\nPrompts: Reusable interaction templates.\n\nC#: Similar attribute-based discovery ([McpServerPromptType], [McpServerPrompt]) and DI integration as tools. Handlers often return ChatMessage arrays.\nJava: Configured via the McpServer builder, passing Async/SyncPromptSpecification objects. Handlers return GetPromptResult containing PromptMessage lists.\nEnd-User Nuance: A Java-based customer support tool exposes a /troubleshoot {issue} prompt. When invoked by the user/AI, the server returns a structured set of initial diagnostic questions for the user or LLM to answer.\n\n\n\nThe End-User Connection: Enterprise Context for AI\nFor businesses running on .NET and Java, these SDKs are pivotal. They allow tightly integrating AI capabilities directly with the applications and data stores that power the enterprise, moving beyond generic chatbot interactions:\n\nInternal Assistants: An AI assistant using the C# SDK can interact with internal ASP.NET Core services via MCP Tools to look up employee information, file expense reports, or query internal knowledge bases.\nCustomer Support: A Java Spring Boot application can expose customer order history as MCP Resources and order modification actions as MCP Tools, enabling AI support agents (or self-service bots) to provide context-rich assistance.\nDeveloper Tools: An IDE plugin (potentially using the client SDK) could connect to a local MCP server (built with any SDK using Stdio) that provides project-specific context, linting tools, or code generation capabilities relevant to the specific codebase being worked on.\n\nThe SDKs provide the necessary plumbing to build these secure, contextual bridges within familiar enterprise development environments.\nWhat’s Next in the Series?\nThis introduction sets the stage for our comparative exploration of the C# and Java MCP SDKs. In the upcoming posts, we will:\n\nBlog 2: Defining the Contract: Dive into MCP schema representation using C# POCOs/System.Text.Json vs. Java POJOs/Jackson.\nBlog 3: Server APIs: Compare the C# DI/Builder approach with Java’s explicit Builder pattern for server configuration.\nBlog 4: Server Internals: Look at session management, request handling, and lifecycles.\nBlog 5: Client APIs: Explore how C# and Java clients connect and interact.\n…and more, covering transports (Stdio, SSE, Streamable HTTP in C#), framework integrations (ASP.NET Core, Spring), advanced features, and finally, a synthesis of the developer experience.\n\nExplore the SDKs:\n\nC# SDK Repository\nJava SDK Repository\n\nJoin us next time as we scrutinize how C# and Java tackle the crucial task of defining the MCP message schemas!\n"},"2-Official-c-and-java-sdk-tutes/Blogs/blog-10":{"slug":"2-Official-c-and-java-sdk-tutes/Blogs/blog-10","filePath":"2 Official c# and java sdk tutes/Blogs/blog-10.md","title":"Blog 10: Synthesis - MCP SDKs Across Ecosystems: DX, Use Cases, and the Road Ahead","links":["2-Official-c-and-java-sdk-tutes/Blogs/blog-2","2-Official-c-and-java-sdk-tutes/Blogs/blog-3","2-Official-c-and-java-sdk-tutes/Blogs/blog-4","2-Official-c-and-java-sdk-tutes/Blogs/blog-5","2-Official-c-and-java-sdk-tutes/Blogs/blog-6","2-Official-c-and-java-sdk-tutes/Blogs/blog-8","2-Official-c-and-java-sdk-tutes/Blogs/blog-9"],"tags":[],"content":"Blog 10: Synthesis - MCP SDKs Across Ecosystems: DX, Use Cases, and the Road Ahead\nSeries: Deep Dive into the Model Context Protocol SDKs\r\nPost: 10 of 10\nOver the course of this series, we’ve dissected the official Model Context Protocol (MCP) SDKs for TypeScript, Python, C#, and Java. We’ve moved from the fundamental protocol definitions defined via Zod, Pydantic, System.Text.Json, and Jackson, through the various layers of server/internal architecture and client APIs, compared transport mechanisms like Stdio, SSE, Streamable HTTP, and WebSockets, explored framework integrations, and highlighted advanced capabilities unique to certain SDKs.\nMCP’s goal is to provide a standard interface enabling AI to leverage application context and capabilities securely and effectively. The SDKs are the linchpin, translating this specification into idiomatic tools for developers across diverse ecosystems. In this concluding post, we synthesize our findings, comparing the developer experience (DX), mapping strengths to use cases, discussing interoperability, and looking towards the future for developers working with MCP at an advanced level.\nCore Abstractions: A Shared Foundation\nDespite linguistic and architectural differences, all four SDKs successfully provide the core abstractions needed to work with MCP:\n\nProtocol Framing: Handling the intricacies of JSON-RPC 2.0 (requests, responses, notifications, errors, IDs).\nTransport Layer: Abstracting communication channels (Stdio, HTTP variants) and managing their lifecycles.\nPrimitive Handling: Offering APIs to define, register, and serve/consume Tools, Resources, and Prompts.\nSession Management: Managing the state and flow of communication for individual client-server connections.\nType Safety: Leveraging platform-native type systems (TypeScript interfaces/Zod, Python type hints/Pydantic, C# types/System.Text.Json, Java types/Jackson) to ensure message integrity.\n\nKey Differentiators: An Advanced Perspective\nBeyond the basics, significant divergences emerge, influencing design and integration choices:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFeatureTypeScriptPythonC# (.NET)Java (JVM)Primary HTTP TransportStreamable HTTP (Resumable)HTTP+SSE (Legacy Spec)Streamable HTTP / SSE Compat (ASP.NET Core)HTTP+SSE (Servlet/Spring Adapters)High-Level Server APIMcpServer (Methods)FastMCP (Decorators)DI Builder Extensions / AttributesBuilder Pattern (McpServer.sync/async)Low-Level Server APIServer (Explicit Handlers)Server (Decorators)McpServer (Internal, uses DI/Options)McpServerSession (Internal)Parameter HandlingZod SchemasType Hint InferenceAttributes / DIManual Specs + HandlersAsync ModelNode.js async/awaitanyio (Flexible Backend).NET async/await/TaskExplicit Sync/Async APIs (Reactor)Web Framework Int.Manual (Express examples)ASGI (sse_app)ASP.NET Core (MapMcp)Spring/Servlet (Transport Providers)DI IntegrationManualManual (or via Framework)Deep (Hosting, Extensions, Param Inj.)Manual Wiring (Core); Spring Context (Modules)Built-in OAuth ServerYes (mcpAuthRouter)NoNoNoDynamic CapabilitiesYes (Handles: .enable/.update)Less ExplicitLess ExplicitLess ExplicitAutocompletionYes (Completable)NoNoNoResumability (HTTP)Yes (Streamable HTTP)NoYes (Implied via Streamable HTTP support)NoCLI ToolingBasicExcellent (mcp dev/install, uv)Standard dotnetStandard mvnAI Framework Synergy(N/A in core)(N/A in core)Yes (McpClientTool is AIFunction)(N/A in core)\nDeveloper Experience (DX): Choosing Your Flavor\nFor advanced developers, the “best” DX often depends on aligning with existing workflows and desired control levels:\n\nTypeScript: Offers the most complete feature set regarding the latest MCP specs (Streamable HTTP, Resumability, Autocompletion) and includes a unique built-in OAuth server framework. Requires more manual setup for web hosting but provides explicit control, especially over dynamic capabilities. Zod offers powerful, composable schema definition.\nPython: Provides the most ergonomic high-level API (FastMCP) and the best local development/integration story via its mcp CLI and uv integration. anyio offers async flexibility. Lacks some advanced web features and built-in auth compared to TS, requiring reliance on the ASGI ecosystem.\nC#: Delivers the most integrated experience within the .NET ecosystem. Leverages DI, Hosting, Attributes, and ASP.NET Core seamlessly. McpClientTool integrating with Microsoft.Extensions.AI is a strong plus for agent development. Likely supports Streamable HTTP/Resumability via its ASP.NET Core integration.\nJava: Provides explicit choice (Sync/Async) and targeted adapters for major Java web frameworks (Servlet, WebFlux, WebMvc). The Builder pattern and Specification objects offer clear but potentially verbose configuration. Relies on the well-established Jackson and SLF4J libraries.\n\nAdvanced Use Case Suitability\n\nMicroservices Exposing MCP Tools/Resources:\n\nASP.NET Core: C# SDK is a natural fit.\nSpring Boot (WebFlux/WebMvc): Java SDK with corresponding Spring module is ideal.\nNode.js: TypeScript SDK, likely using Streamable HTTP. Need to add auth middleware.\nPython (FastAPI/Starlette): Python SDK via ASGI (sse_app). Need to add auth middleware.\nResilience Needed?: TS or C# (if using Streamable HTTP) provide better options via resumability.\n\n\nBuilding Secure Public MCP APIs:\n\nTypeScript: Offers the quickest path to a standard OAuth 2.1 server via mcpAuthRouter.\nC#/Java/Python: Require integrating robust external authentication/authorization libraries and middleware (e.g., Spring Security, ASP.NET Core Identity/JWT, Authlib).\n\n\nDesktop Application Integration (Agent &lt;&gt; Local Tools):\n\nPython: The mcp install CLI makes it the easiest for integrating into environments like Claude Desktop.\nC#/Java/TS: All support Stdio effectively for building the server side of a local tool. Client-side launching and management differ based on platform process APIs.\n\n\nAI Agent Frameworks (as Clients):\n\nC# (Microsoft.Extensions.AI): Direct integration via McpClientTool as AIFunction.\nPython/Java/TS: Require mapping discovered MCP tools/schemas to the specific function-calling format expected by the chosen agent framework (e.g., LangChain, LlamaIndex, Semantic Kernel Java/Python bindings).\n\n\nServers with Highly Dynamic Capabilities:\n\nTypeScript: The explicit handles (.enable(), .update(), etc.) provide the clearest API for managing primitives after connection.\nC#/Java/Python: Possible but requires more manual state management and explicit triggering of listChanged notifications.\n\n\n\nCross-Ecosystem Interoperability\nMCP’s core value proposition includes interoperability. Based on the SDKs:\n\nStdio: Should work seamlessly between any client/server pair regardless of SDK language.\nHTTP+SSE: Clients and servers built using the Java SDK, Python SDK, or C# SDK (via its legacy SSE handlers in MapMcp) should interoperate, as they target the same dual-endpoint specification.\nStreamable HTTP: Clients and servers using the TypeScript SDK or C# SDK (via MapMcp’s primary StreamableHttpHandler) should interoperate. Java and Python currently lack server-side Streamable HTTP support. A TS/C# client trying to connect to a Java/Python server using Streamable HTTP would likely fail or need to use the backwards-compatibility fallback to SSE.\n\nThe Future: Convergence and Growth\nThe MCP ecosystem is still young but holds immense potential. Looking ahead for the SDKs:\n\nTransport Alignment: The most significant area for potential convergence is HTTP transport. Will Java and Python gain first-class Streamable HTTP support with resumability, aligning with TS and C#? This seems like a logical next step for enhanced web resilience.\nFeature Parity: Will features like built-in OAuth helpers, dynamic capability handles, or autocompletion make their way into the Python, C#, and Java SDKs to match TypeScript’s current offerings?\nEnhanced Tooling: Python’s mcp CLI sets a high bar. Could similar developer QoL tools emerge for TS, C#, or Java (perhaps via dotnet tool or Maven plugins)?\nDeepening Framework Integration: Continued refinement of ASP.NET Core, Spring, and potentially other framework integrations (e.g., Quarkus for Java, NestJS for TS).\nSpecification Updates: The SDKs will track and implement new features or refinements added to the official MCP specification.\nCommunity &amp; Use Cases: As adoption grows, real-world use cases will drive demand for specific features, integrations (e.g., more EventStore implementations), and potentially community-contributed extensions.\n\nFinal Synthesis\nThe Model Context Protocol provides a powerful standard for integrating AI with application context. The official SDKs for TypeScript, Python, C#, and Java translate this standard into practical, idiomatic tools for developers across major ecosystems.\n\nTypeScript leads with the most comprehensive feature set aligned with the latest MCP specifications (Streamable HTTP, Resumability, OAuth Server, Autocompletion, Dynamic Handles).\nPython offers unparalleled developer ergonomics for rapid development and local/desktop integration via FastMCP and its superior CLI tooling.\nC# delivers a seamless experience within the modern .NET ecosystem, leveraging DI, Hosting, ASP.NET Core, and Microsoft.Extensions.AI effectively.\nJava provides robustness and choice, catering to both Sync and Async paradigms with dedicated support for the vast Spring and Servlet ecosystems.\n\nWhile feature sets currently differ, particularly around web transports and built-in helpers, the core protocol implementation is solid across the board, ensuring fundamental interoperability. The choice of SDK hinges on the target platform, required features (especially for web resilience and auth), framework integration needs, and developer preference for API style. These SDKs are poised to empower developers to build the deeply integrated, contextually-aware AI applications of the future.\n\nThank you for reading this series! We hope it has provided a valuable technical overview and comparison of the MCP SDKs.\nExplore further:\n\nTypeScript SDK\nPython SDK\nC# SDK\nJava SDK\nMCP Specification\n\n"},"2-Official-c-and-java-sdk-tutes/Blogs/blog-11":{"slug":"2-Official-c-and-java-sdk-tutes/Blogs/blog-11","filePath":"2 Official c# and java sdk tutes/Blogs/blog-11.md","title":"Blog 11: Beyond Stateless - State Management & Resumability in MCP SDKs","links":["2-Official-c-and-java-sdk-tutes/Blogs/blog-10","2-Official-c-and-java-sdk-tutes/Blogs/blog-7"],"tags":[],"content":"Blog 11: Beyond Stateless - State Management &amp; Resumability in MCP SDKs\nSeries: Deep Dive into the Model Context Protocol SDKs\r\nPost: 11 of 10 (Advanced Topics)\nIn our extensive 10-part series dissecting the TypeScript, Python, C#, and Java Model Context Protocol (MCP) SDKs, we covered the core architecture, APIs, transports, and framework integrations. While many MCP interactions can be treated as stateless request-response cycles, real-world AI assistants often need to handle stateful operations and gracefully recover from interruptions.\nImagine an AI assistant guiding a user through a multi-step configuration process, executing a long-running data analysis tool, or maintaining user preferences within a session. These scenarios demand mechanisms beyond simple statelessness.\nThis advanced post delves into how the MCP SDKs address these needs, focusing on:\n\nThe Challenge: Why simple request-response isn’t always sufficient.\nStreamable HTTP Resumability: The powerful, built-in solution in the TS (and likely C#) SDKs via EventStore.\nSession Management: How stateful connections are identified and managed across different transports and SDKs.\nState Handling Strategies (Java/Python): Patterns for managing state when built-in transport resumability isn’t available.\nThe Role of Context Objects: Accessing session and lifespan state within handlers.\n\nThe Need for State and Resilience\nStateless MCP servers are simple: each request is independent. However, many valuable interactions require state or continuity:\n\nMulti-Step Tools: A tool that requires several interactions (e.g., “select file”, “choose options”, “confirm execution”).\nLong-Running Operations: A tool analyzing a large dataset might take minutes, sending progress updates. A network hiccup shouldn’t force restarting the entire process.\nSession-Specific Data: Storing user preferences, conversation history summaries, or temporary results within the scope of a single client connection.\nResource Subscriptions: Maintaining the state of which client is subscribed to which resource for update notifications (resources/subscribe).\n\nFurthermore, network connections, especially over the web or mobile networks, are inherently unreliable. Clients might disconnect and reconnect. A robust system needs to handle these interruptions gracefully, ideally resuming operations where they left off.\nBuilt-in Resilience: Streamable HTTP + EventStore (TS/C# Focus)\nAs discussed in Blog 7, the Streamable HTTP transport, prominently featured in the TypeScript SDK and likely the foundation of the C# ASP.NET Core integration, has built-in support for resumability when paired with an EventStore.\nRecap of the Mechanism:\n\nEventStore Interface: Defines storeEvent(streamId, message) returning an EventId, and replayEventsAfter(lastEventId, sendCallback) returning the original streamId.\nServer-Side (StreamableHTTPServerTransport / C#‘s StreamableHttpHandler):\n\nWhen configured with an EventStore, it intercepts outgoing server-to-client messages (responses/notifications sent over SSE streams).\nIt calls eventStore.storeEvent() for each message, associating it with a unique StreamId (representing the specific SSE connection, often tied to the Mcp-Session-Id or even a specific POST request’s response stream).\nIt retrieves the unique, ordered EventId from the store.\nIt includes id: &lt;EventId&gt;\\n in the SSE event sent to the client.\nWhen a client connects (via GET or POST) with a Last-Event-ID header, the server calls eventStore.replayEventsAfter().\nThe replayEventsAfter implementation queries the store for messages on the corresponding StreamId after the lastEventId and uses the provided send callback (which writes to the new connection) to resend the missed messages with their original event IDs.\n\n\nClient-Side (StreamableHTTPClientTransport - TS):\n\nTracks the highest EventId received from id: lines in SSE events.\nOn reconnection (either initiating a GET stream or making the next POST after a perceived disconnect), it includes the Last-Event-ID header.\n\n\n\nEventStore Implementations:\n\nIn-Memory (Examples/Testing): The TS SDK provides InMemoryEventStore. Suitable only for single-instance servers and development. State is lost on restart.\nPersistent (Production): Requires implementing the EventStore interface using a durable, shared backend:\n\nRedis: Using Redis Streams or Sorted Sets. Offers good performance. Needs careful handling of data size/eviction.\nDatabase (SQL/NoSQL): Storing events in a table/collection indexed by StreamId and EventId (or timestamp). Requires careful schema design and indexing for efficient querying.\nMessage Queues (Kafka, RabbitMQ): Can potentially be adapted, using topics per stream and managing offsets, though might be overkill unless already using a queue for other purposes.\n\n\n\nKey Benefit: Provides transparent resilience for long-running operations or flaky connections at the transport level, without requiring complex state management logic within the Tool/Resource handlers themselves.\nSession Management Across SDKs\nResumability relies on identifying the stream to resume. More broadly, stateful interactions rely on identifying the session.\n\nStreamable HTTP (TS/C#): Uses the Mcp-Session-Id HTTP header. The server generates it on the initial initialize response (if stateful) and validates it on subsequent requests. The client stores and sends it. Stateless mode (sessionIdGenerator: undefined in TS) bypasses this.\nHTTP+SSE (Java/Python/Legacy): Uses the sessionId query parameter. The server generates a UUID, embeds it in the endpoint URL sent in the initial SSE endpoint event (e.g., /message?sessionId=...). The client extracts this ID and appends it to all subsequent POST requests to the message endpoint.\nStdio: Implicitly single-session. The client owns the server process lifecycle. No explicit session ID is needed for routing, though one might be generated internally for logging/tracking.\n\nThe session ID allows the server framework or transport provider to route incoming messages (especially POST requests in SSE) to the correct McpSession (Java) or McpSession (C# internal) instance managing the state and communication channel for that specific client.\nState Handling without Built-in Resumability (Java/Python HTTP+SSE)\nSince the HTTP+SSE transport model used primarily by the Java and Python SDKs doesn’t have built-in EventStore-based resumability, developers needing stateful interactions or resilience for long operations must implement patterns manually:\n\n\nExternal State Store (Most Common):\n\nMechanism: Store all necessary session or task state in an external database (SQL, NoSQL) or cache (Redis) keyed by the sessionId.\nWorkflow:\n\nClient connects (GET /sse), server generates sessionId and stores initial session state externally. Client gets endpoint URL with sessionId.\nClient sends POST /message?sessionId=... containing a request.\nServer handler retrieves the sessionId from the query param.\nHandler fetches the current state for that session from the external store.\nHandler performs logic, updates the state, and saves it back to the external store.\nHandler sends the response back via the session’s SSE connection.\n\n\nPros: Works across stateless server instances (good for scaling), state is durable.\nCons: Adds latency (database/cache calls per request), requires careful state schema design, doesn’t automatically replay missed notifications if the client disconnects/reconnects during a long operation (though the final result can be retrieved based on the persisted state).\n\n\n\nIdempotent Operations + Client Retries:\n\nMechanism: Design Tools to be idempotent (safe to retry). The client is responsible for retrying requests if a response isn’t received within a timeout.\nPros: Simple server-side.\nCons: Only works for idempotent actions, doesn’t handle missed notifications or progress, pushes complexity to the client.\n\n\n\nStateful Server Instances + Sticky Sessions/Routing:\n\nMechanism: Maintain session state in memory on specific server instances. Use a load balancer with sticky sessions or a message queue/service bus to route all requests for a given sessionId to the same server instance. (See Python examples README discussion on multi-node deployment).\nPros: Lower latency for state access (in-memory).\nCons: More complex infrastructure (sticky sessions or message queue), single point of failure for session state unless replicated, doesn’t solve dropped SSE connection notification loss directly without extra logic.\n\n\n\nCustom Resumability Logic:\n\nMechanism: Implement a custom version of the EventStore pattern. Server handlers store events/progress updates externally. Clients track the last received update ID. On reconnect, the client sends the last ID, and the server replays missed events from the store.\nPros: Provides true resumability.\nCons: Significant custom implementation effort on both client and server.\n\n\n\nFor Java/Python using HTTP+SSE, the External State Store pattern is often the most practical approach for managing session state and ensuring long operations can eventually complete, even if intermediate notifications are missed during client disconnects.\nRole of Context/Exchange Objects\nThe RequestContext (C#) and McpAsync/SyncServerExchange (Java) objects passed into handlers provide access to crucial identifiers for state management:\n\nsessionId: Directly available on the Java Exchange (via its internal McpServerSession) and accessible via the IMcpServer instance within the C# RequestContext. Essential for keying external state stores.\nrequestId: Available in both. Useful for tracking specific operations within a session.\nlifespan_context (C#) / Lifespan State (Java): If using lifespan management, the context object provides access to resources initialized at server startup (like database connection pools), which might be needed to interact with state stores.\n\nConclusion: Choosing Your State Strategy\nHandling state and ensuring resilience are critical for moving beyond simple, stateless MCP interactions.\n\nThe TypeScript SDK, with its embrace of Streamable HTTP and the EventStore pattern, offers the most integrated and powerful solution for resumability, especially for web-based transports. C# likely benefits from this too via its ASP.NET Core integration. This significantly simplifies building reliable long-running tools.\nThe Java and Python SDKs, primarily using HTTP+SSE, require developers to adopt manual state management strategies when needed. Using an external state store keyed by the sessionId is a common and robust pattern, although it doesn’t automatically solve the issue of missed notifications during client disconnections as transparently as the EventStore model.\nStdio transports generally imply simpler, single-session state management often held within the server process itself.\n\nAdvanced developers must choose their state management strategy based on the SDK they are using, the chosen transport, the specific requirements of their tools/resources (stateless vs. stateful vs. long-running), and their deployment architecture (single instance vs. scaled). Understanding the built-in capabilities (like Streamable HTTP resumability) and the patterns needed when those aren’t available (like external state stores) is key to building sophisticated and reliable MCP applications.\nThis concludes our deep dive into the MCP SDKs! We’ve covered the spectrum from foundational types to advanced state management, comparing the approaches across TypeScript, Python, C#, and Java. We hope this series has equipped you with the knowledge to effectively leverage these powerful tools.\n"},"2-Official-c-and-java-sdk-tutes/Blogs/blog-12":{"slug":"2-Official-c-and-java-sdk-tutes/Blogs/blog-12","filePath":"2 Official c# and java sdk tutes/Blogs/blog-12.md","title":"Blog 12: Staying Synced & Handling Failures - Advanced Notifications, Subscriptions, and Resilience in MCP SDKs","links":["2-Official-c-and-java-sdk-tutes/Blogs/blog-1","2-Official-c-and-java-sdk-tutes/Blogs/blog-1.md1","2-Official-c-and-java-sdk-tutes/Blogs/blog-1.md2"],"tags":[],"content":"Blog 12: Staying Synced &amp; Handling Failures - Advanced Notifications, Subscriptions, and Resilience in MCP SDKs\nSeries: Deep Dive into the Model Context Protocol SDKs\r\nPost: 12 of 10 (Advanced Topics)\nOur journey through the Model Context Protocol (MCP) SDKs for TypeScript, Python, C#, and Java has taken us from core concepts to advanced tooling and resource management. While request-response interactions form the backbone of MCP, truly dynamic and robust applications rely heavily on asynchronous communication (server-to-client notifications) and graceful handling of errors and interruptions.\nFor advanced developers building complex MCP integrations, mastering these aspects is crucial. This post dives into the nuances of:\n\nServer-Sent Notifications: How servers proactively push information (logs, updates, progress) to clients across the SDKs.\nClient-Side Handling: Comparing the mechanisms for receiving and reacting to these notifications.\nResource Subscriptions: The lifecycle (subscribe/unsubscribe) and notification (updated) flow for keeping clients synced with resource changes.\nError Handling Strategies: Differentiating and managing transport, protocol, and application-level errors.\nCancellation &amp; Resilience: Propagating cancellation signals and revisiting transport-level resilience mechanisms.\n\nPushing Information: Server-Initiated Notifications\nBeyond responding to requests, MCP servers can send notifications to inform clients about events or progress.\nCommon Notification Types:\n\nnotifications/message (Logging): Servers send log entries based on the level set by the client (logging/setLevel request).\nnotifications/{tools|resources|prompts}/list_changed: Sent when the server’s available set of Tools, Resources, or Prompts changes (if the server supports this capability).\nnotifications/progress: Sent during long-running operations (initiated by a client request that included a progressToken) to provide status updates.\nnotifications/resources/updated: Sent to subscribed clients when a specific resource’s content changes.\n\nSending Notifications (Server-Side):\n\nTypeScript (McpServer/Server):\n\nUse methods on the Server instance (accessible via mcpServer.server): server.sendLoggingMessage(...), server.sendResourceUpdated(...), server.sendToolListChanged(...), etc.\nProgress notifications are sent via the sendNotification function within the RequestHandlerExtra passed to tool/resource/prompt handlers: extra.sendNotification({ method: &quot;notifications/progress&quot;, params: { progressToken: ..., progress: ..., total: ... }}).\nlist_changed notifications are often sent automatically by McpServer when using the .enable(), .disable(), .update(), .remove() methods on registered handles.\n\n\nPython (FastMCP/Server):\n\nUse methods on the injected Context object within FastMCP handlers: ctx.log(...), ctx.report_progress(...).\nFor list_changed or resource/updated, use the underlying low-level server session: ctx.session.send_resource_list_changed(), ctx.session.send_resource_updated(...). FastMCP itself doesn’t provide high-level wrappers for these specific notifications currently.\n\n\nC# (IMcpServer):\n\nUse extension methods on the IMcpServer instance (often injected into handlers): server.SendNotificationAsync(&quot;notifications/message&quot;, logParams).\nProgress reporting uses the injected IProgress&lt;ProgressNotificationValue&gt; parameter in tool methods, which is automatically wired to send notifications if the client provided a token.\nlist_changed requires manual sending via server.SendNotificationAsync(...) if not using a collection that raises events (like McpServerPrimitiveCollection).\n\n\nJava (McpAsync/SyncServer / McpAsync/SyncServerExchange):\n\nUse methods on the Exchange object passed to handlers: exchange.loggingNotification(...).\nProgress reporting is not automatically handled via an IProgress equivalent; requires manually calling exchange.session.sendNotification(&quot;notifications/progress&quot;, ...) with the correct token.\nlist_changed and resource/updated require manual sending via exchange.session.sendNotification(...).\nThe McpServerTransportProvider.notifyClients(...) method allows broadcasting to all connected sessions (use with caution).\n\n\n\nKey Difference: TypeScript’s high-level McpServer provides the most automation for list_changed notifications. C# has good integration for IProgress&lt;&gt;. Python’s Context offers convenient logging/progress methods. Java requires more manual notification construction/sending via the session object found within the Exchange.\nListening In: Client-Side Notification Handling\nClients need to register handlers to react to these server-sent events.\n\nTypeScript (Client.setNotificationHandler):\n\nDynamically register handlers using a Zod schema and a callback.\nAllows multiple handlers per method.\nfallbackNotificationHandler catches unhandled types.\n\nclient.setNotificationHandler(LoggingMessageNotificationSchema, async (log) =&gt; { /*...*/ });\n\nPython (ClientSession Callbacks):\n\nSpecific callbacks (logging_callback, toolsChangeConsumer, etc.) are passed to the ClientSession constructor via the McpClient.async/sync builder.\nA generic message_handler catches anything else (including requests from the server like sampling/roots).\n\nasync def my_logger(params: LoggingMessageNotificationParams): # ...\nasync def fallback(msg: Any): # ...\n \nclient = McpClient.async(transport)\n            .loggingConsumer(my_logger)\n            .message_handler(fallback)\n            .build()\n\nC# (IMcpEndpoint.RegisterNotificationHandler):\n\nRegisters handlers dynamically using the method name string and a Func&lt;JsonRpcNotification, CancellationToken, ValueTask&gt;.\nReturns an IAsyncDisposable to unregister the handler when disposed. Allows multiple handlers.\n\nawait using var reg = client.RegisterNotificationHandler(\n    NotificationMethods.ResourceUpdatedNotification,\n    async (notification, ct) =&gt; { /* Handle update */ }\n);\n\nJava (McpClientSession Configuration):\n\nHandlers (NotificationHandler) are provided in a map to the internal McpClientSession constructor, typically populated via the McpClient.async/sync builder’s consumer methods (e.g., .loggingConsumer(...)).\nHandlers are tied to the client instance lifetime.\n\n// In McpClient.sync/async builder chain\n.loggingConsumer(notification -&gt; { /* Handle log (Sync) */ })\n.toolsChangeConsumer(tools -&gt; Mono.fromRunnable(() -&gt; { /* Handle tools change (Async) */ }))\n\n\nComparison: C# and TypeScript offer more dynamic registration/unregistration of handlers using disposables. Python and Java configure handlers primarily at client creation time via the builder.\nStaying Updated: Resource Subscriptions\nA specific notification flow enables clients to track resource changes:\n\nClient Sends resources/subscribe Request: Specifies the URI to watch.\nServer: If supported (requires ResourcesCapability.Subscribe = true and a registered SubscribeToResourcesHandler), the server registers the client’s interest (often storing (sessionId, uri)).\nResource Change: When the resource at the subscribed URI changes, the server detects this (implementation-specific).\nServer Sends notifications/resources/updated: Sends a notification containing the URI of the changed resource to all subscribed sessions.\nClient: Receives the notification (via its registered handler) and typically re-fetches the resource using resources/read.\nClient Sends resources/unsubscribe Request: When updates are no longer needed.\nServer: Removes the subscription registration.\n\nSDK Support:\n\nHigh-Level: None of the SDKs seem to offer a high-level client API like client.subscribe(uri, callback) out-of-the-box. Subscription management is manual.\nServer-Side Handlers: C# and Java require explicitly registering handlers for subscribe and unsubscribe requests via the IMcpServerBuilder / McpServer builder if supporting this capability. TS and Python would likely require using the low-level setRequestHandler / @server.request_handler to handle these specific methods.\nState Management: The server is responsible for tracking (sessionId, uri) subscription state, typically in memory (for single instances) or an external store (for scaled deployments).\n\nHandling the Unexpected: Errors and Resilience\nFailures are inevitable in distributed systems. Robust MCP applications need to handle errors gracefully.\nTypes of Errors:\n\nTransport Errors: Network connection lost, process crashed (Stdio), HTTP errors (4xx/5xx), SSE stream disconnection.\n\nDetection: Usually manifest as exceptions from transport.send/read operations (e.g., IOException, HttpRequestException, OperationCanceledException on close).\nHandling: The core Protocol/BaseSession layers often catch these and trigger the onerror and/or onclose callbacks. Client applications typically need to implement reconnection logic (potentially using exponential backoff). Server transports might log the error and clean up the specific session.\n\n\nProtocol Errors (JSON-RPC): Malformed JSON (ParseError), invalid request structure (InvalidRequest), unknown method (MethodNotFound), invalid parameters (InvalidParams), internal server processing error (InternalError).\n\nDetection: SDKs perform validation. McpSession/BaseSession catches parsing/validation errors. Handlers might throw McpError/McpException with specific codes.\nHandling: SDKs generally convert these into JSONRPCError responses sent back to the original requester. Clients receive these as McpError/McpException.\n\n\nApplication Errors (Handler Exceptions): Uncaught exceptions within Tool/Resource/Prompt handler logic.\n\nDetection: Caught by the SDK’s request handling loop (McpSession/BaseSession or higher-level wrappers like AIFunctionMcpServerTool).\nHandling:\n\nTools: C#, Python, and TS typically convert these into a CallToolResult with isError: true and the error message as text content. Java requires the handler to manually return such a result or risk an unhandled exception.\nResources/Prompts: Usually result in a standard JSONRPCError response (often InternalError) being sent back to the client. The raise_exceptions flag in Python’s low-level server can alter this for testing.\n\n\n\n\n\nTimeout Handling:\n\nBoth client and server SDKs manage request timeouts (requestTimeout option).\nIf a response isn’t received within the timeout, the pending request promise/future/Mono rejects with a specific timeout error (McpError with RequestTimeout code in TS, standard timeout exceptions in C#/Java).\nTypeScript’s resetTimeoutOnProgress offers fine-grained control for long-running tasks sending progress updates.\n\nCancellation:\n\nClient → Server: Clients pass CancellationToken (C#) or AbortSignal (TS) to request methods. If cancelled, the SDK sends notifications/cancelled.\nServer Handling: The RequestContext (C#) / RequestHandlerExtra (TS) / Exchange (Java, via session) / Context (Python FastMCP) provides access to a cancellation signal/token tied to the request. Handlers must check this token periodically for long-running operations and abort gracefully.\nServer → Client: Less common, but a server could potentially cancel an operation it requested from a client (like sampling/createMessage) using a similar cancellation notification flow if needed.\n\nResilience Revisited:\n\nStreamable HTTP (TS/C#): Offers the highest built-in resilience via EventStore. Missed notifications and responses during disconnects can be replayed automatically on reconnect if the client provides Last-Event-ID.\nHTTP+SSE (Java/Python): No built-in transport-level replay. Resilience requires application-level strategies:\n\nClient retries for requests.\nServer storing task state externally and allowing clients to query status or retrieve final results after reconnection (missed intermediate progress/notifications are lost).\nDesigning idempotent tools where possible.\n\n\n\nConclusion: Building Robust Asynchronous Systems\nHandling notifications, managing subscriptions, and gracefully recovering from errors and cancellations are hallmarks of advanced, production-ready MCP applications.\n\nThe SDKs provide varying levels of abstraction for sending and receiving standard notifications. TypeScript and C# offer more dynamic client-side handler registration, while Java and Python favor configuration-time setup.\nResource subscriptions require significant server-side state management, which is largely left to the developer in all current SDKs.\nError handling follows standard JSON-RPC patterns, with SDKs mapping errors to exceptions (McpError/McpException) or specific result types (CallToolResult.isError). Robust applications need try/catch blocks and appropriate logging.\nCancellation is supported via standard platform mechanisms (CancellationToken, AbortSignal) and requires cooperative handlers.\nResilience against network drops during web communication is most seamlessly handled by the Streamable HTTP transport’s resumability feature (prominent in TS, likely available in C#), while HTTP+SSE (Java/Python) necessitates more application-level state management for recovery.\n\nMastering these asynchronous and resilience patterns is key to building MCP integrations that are not just functional but also reliable and user-friendly in the face of real-world complexities.\n"},"2-Official-c-and-java-sdk-tutes/Blogs/blog-2":{"slug":"2-Official-c-and-java-sdk-tutes/Blogs/blog-2","filePath":"2 Official c# and java sdk tutes/Blogs/blog-2.md","title":"Blog 2: Defining the Contract - MCP Schemas in C# (.NET) and Java (JVM)","links":["2-Official-c-and-java-sdk-tutes/Blogs/blog-1"],"tags":[],"content":"Blog 2: Defining the Contract - MCP Schemas in C# (.NET) and Java (JVM)\nSeries: Deep Dive into the Model Context Protocol SDKs (C# &amp; Java)\r\nPost: 2 of 10\nIn Blog 1, we introduced the Model Context Protocol (MCP) and its mission to standardize communication between AI models and applications. We also highlighted the official C# and Java SDKs, designed to bring MCP capabilities into the robust .NET and JVM enterprise ecosystems.\nEvery communication protocol needs a clearly defined language – a precise structure for messages exchanged between parties. This ensures that both client and server understand what data to expect, what fields are required, and what types those fields should have. Without this contractual clarity, integrations become brittle and prone to errors.\nThis post dives into the core of this contract within the C# and Java SDKs, exploring how they define the MCP message schemas. We’ll compare the approaches taken by:\n\nC# SDK: Leveraging System.Text.Json, C# records/classes (POCOs), attributes, and source generation. (Primarily in src/ModelContextProtocol/Protocol/Types/)\nJava SDK: Utilizing the Jackson library, Java records/classes (POJOs), and annotations. (Defined largely within mcp/src/.../spec/McpSchema.java)\n\nThe Foundation: JSON-RPC 2.0 Revisited\nAs mentioned previously, MCP uses JSON-RPC 2.0 as its base framing protocol. Both SDKs must represent these core structures:\n\nRequest: jsonrpc, method, params, id.\nResponse (Success): jsonrpc, id, result.\nResponse (Error): jsonrpc, id, error (with code, message, data).\nNotification: jsonrpc, method, params (no id).\n\nLet’s see how each SDK models this.\nC# &amp; System.Text.Json: Leveraging Modern .NET Features\nThe C# SDK embraces modern .NET idioms and the built-in System.Text.Json library, enhanced by source generation for performance and AOT compatibility.\nCore JSON-RPC Models:\nTypes are typically defined as C# record types (for immutability) or classes (POCOs). Attributes control JSON serialization behavior.\n// src/ModelContextProtocol/Protocol/Messages/JsonRpcMessage.cs (Simplified)\nusing System.Text.Json.Serialization;\nusing ModelContextProtocol.Utils.Json; // For custom converter\n \n[JsonConverter(typeof(JsonRpcMessageConverter))] // Handles polymorphism\npublic abstract class JsonRpcMessage\n{\n    [JsonPropertyName(&quot;jsonrpc&quot;)]\n    public string JsonRpc { get; init; } = &quot;2.0&quot;;\n    // Note: RelatedTransport is JsonIgnore&#039;d, not part of the schema\n}\n \n// src/ModelContextProtocol/Protocol/Messages/JsonRpcRequest.cs (Simplified)\nusing System.Text.Json.Nodes; // Often uses JsonNode for flexible params/result\n \npublic class JsonRpcRequest : JsonRpcMessageWithId // Inherits Id property\n{\n    [JsonPropertyName(&quot;method&quot;)]\n    public required string Method { get; init; } // &#039;required&#039; keyword\n \n    [JsonPropertyName(&quot;params&quot;)]\n    public JsonNode? Params { get; init; } // Nullable reference type &#039;?&#039;\n}\n \n// src/ModelContextProtocol/Protocol/Messages/JsonRpcErrorDetail.cs (Simplified)\npublic record JsonRpcErrorDetail\n{\n    [JsonPropertyName(&quot;code&quot;)]\n    public required int Code { get; init; }\n \n    [JsonPropertyName(&quot;message&quot;)]\n    public required string Message { get; init; }\n \n    [JsonPropertyName(&quot;data&quot;)]\n    public object? Data { get; init; } // Allows any extra data\n}\nKey System.Text.Json / C# Features Used:\n\nPOCOs (Records/Classes): Standard C# types define the structure. record types are often used for their value semantics and conciseness.\n[JsonPropertyName(&quot;...&quot;)]: Maps C# property names (typically PascalCase) to JSON field names (typically camelCase).\nrequired Modifier: Ensures essential properties are present during deserialization and initialization (C# 11+).\nNullability (?): Clearly indicates optional fields.\n[JsonConverter(typeof(...))]: Used on base types (JsonRpcMessage, ResourceContents) to handle polymorphic deserialization – determining the correct concrete type based on JSON properties (e.g., presence of id, method, result, error).\n[JsonIgnore]: Excludes properties (like RelatedTransport) from serialization.\nSource Generation (JsonSerializable, JsonSourceGenerationOptions in McpJsonUtilities.cs): Although not visible directly in the type definition, the SDK uses source generation (JsonSerializerContext) to create optimized (de)serialization logic at compile time. This improves performance and is crucial for Native AOT compatibility. The McpJsonUtilities.DefaultOptions likely configures the serializer to use this context.\nJsonNode / JsonElement: Used for flexible params and result fields where the exact structure varies by method.\n\nBuilding MCP Types:\nSpecific MCP types inherit or compose these base types:\n// src/ModelContextProtocol/Protocol/Types/InitializeRequestParams.cs\npublic class InitializeRequestParams : RequestParams // Base class not shown, likely empty\n{\n    [JsonPropertyName(&quot;protocolVersion&quot;)]\n    public required string ProtocolVersion { get; init; }\n \n    [JsonPropertyName(&quot;capabilities&quot;)]\n    public ClientCapabilities? Capabilities { get; init; }\n \n    [JsonPropertyName(&quot;clientInfo&quot;)]\n    public required Implementation ClientInfo { get; init; }\n}\n \n// src/ModelContextProtocol/Protocol/Types/Tool.cs\npublic class Tool\n{\n    [JsonPropertyName(&quot;name&quot;)]\n    public string Name { get; set; } = string.Empty;\n \n    [JsonPropertyName(&quot;description&quot;)]\n    public string? Description { get; set; }\n \n    [JsonPropertyName(&quot;inputSchema&quot;)]\n    public JsonElement InputSchema // Represents the JSON Schema object\n    {\n        get =&gt; _inputSchema;\n        set { /* validation logic */ _inputSchema = value; }\n    }\n    private JsonElement _inputSchema = McpJsonUtilities.DefaultMcpToolSchema;\n \n    // ... Annotations ...\n}\n \n// src/ModelContextProtocol/Protocol/Types/ResourceContents.cs (Polymorphism)\n[JsonConverter(typeof(Converter))] // Custom converter handles type deduction\npublic abstract class ResourceContents { /* ... common fields ... */ }\n \npublic class TextResourceContents : ResourceContents { /* ... text field ... */ }\npublic class BlobResourceContents : ResourceContents { /* ... blob field ... */ }\nThe C# approach feels very integrated with the language (nullability, required) and the modern .NET serialization library, prioritizing performance and AOT via source generation. Polymorphism is handled via custom JsonConverter implementations.\nJava &amp; Jackson: Annotation-Driven Configuration\nThe Java SDK relies heavily on the ubiquitous Jackson library for JSON processing, using annotations extensively to configure serialization and deserialization. Most MCP types are defined as nested static records or classes within a single large McpSchema.java file.\nCore JSON-RPC Models:\n// mcp/src/.../spec/McpSchema.java (Simplified)\nimport com.fasterxml.jackson.annotation.*;\n// ... other imports\n \npublic final class McpSchema {\n \n    // Base interface - used with @JsonSubTypes\n    public sealed interface JSONRPCMessage permits JSONRPCRequest, JSONRPCNotification, JSONRPCResponse {\n        String jsonrpc();\n    }\n \n    @JsonInclude(JsonInclude.Include.NON_ABSENT)\n    @JsonIgnoreProperties(ignoreUnknown = true)\n    public record JSONRPCRequest(\n            @JsonProperty(&quot;jsonrpc&quot;) String jsonrpc,\n            @JsonProperty(&quot;method&quot;) String method,\n            @JsonProperty(&quot;id&quot;) Object id, // Often Object or custom Id type needed\n            @JsonProperty(&quot;params&quot;) Object params // Flexible params\n    ) implements JSONRPCMessage {}\n \n    @JsonInclude(JsonInclude.Include.NON_ABSENT)\n    @JsonIgnoreProperties(ignoreUnknown = true)\n    public record JSONRPCResponse(\n            @JsonProperty(&quot;jsonrpc&quot;) String jsonrpc,\n            @JsonProperty(&quot;id&quot;) Object id,\n            @JsonProperty(&quot;result&quot;) Object result, // Flexible result\n            @JsonProperty(&quot;error&quot;) JSONRPCError error // Can be null\n    ) implements JSONRPCMessage {\n \n        @JsonInclude(JsonInclude.Include.NON_ABSENT)\n        @JsonIgnoreProperties(ignoreUnknown = true)\n        public record JSONRPCError(\n                @JsonProperty(&quot;code&quot;) int code,\n                @JsonProperty(&quot;message&quot;) String message,\n                @JsonProperty(&quot;data&quot;) Object data // Flexible extra data\n        ) {}\n    }\n    // ... JSONRPCNotification ...\n}\nKey Jackson / Java Features Used:\n\nPOJOs (Records/Classes): Standard Java types define the structure. Nested static records are frequently used for conciseness and immutability.\n@JsonProperty(&quot;...&quot;): Maps Java field names (camelCase) to JSON field names (often also camelCase, but ensures mapping). Essential as Java doesn’t have built-in field name mapping like C#‘s source gen or reflection attributes by default for all cases.\n@JsonInclude(JsonInclude.Include.NON_ABSENT): Prevents null or empty collection fields from being included in the serialized JSON, matching MCP spec conventions.\n@JsonIgnoreProperties(ignoreUnknown = true): Allows deserialization even if the JSON contains extra, unexpected fields (crucial for MCP’s extensibility).\n@JsonTypeInfo / @JsonSubTypes: Used on base types (Content, ResourceContents) to handle polymorphism. Jackson deduces the correct subclass based on a type identifier field (like &quot;type&quot;: &quot;text&quot;).\nStandard Java Types: Uses String, Integer, Boolean, Double, List&lt;&gt;, Map&lt;&gt;. Nullability is handled by standard Java reference types being nullable.\nObject Type: Often used for params and result where the structure is highly variable. Further processing/casting might be needed after initial deserialization.\n\nBuilding MCP Types:\n// mcp/src/.../spec/McpSchema.java (Simplified Examples)\n \n// InitializeRequest defined as a nested record\n@JsonInclude(JsonInclude.Include.NON_ABSENT)\n@JsonIgnoreProperties(ignoreUnknown = true)\npublic record InitializeRequest(\n    @JsonProperty(&quot;protocolVersion&quot;) String protocolVersion,\n    @JsonProperty(&quot;capabilities&quot;) ClientCapabilities capabilities,\n    @JsonProperty(&quot;clientInfo&quot;) Implementation clientInfo\n) implements Request {} // &#039;Request&#039; is a marker interface\n \n// Tool defined as a nested record\n@JsonInclude(JsonInclude.Include.NON_ABSENT)\n@JsonIgnoreProperties(ignoreUnknown = true)\npublic record Tool(\n    @JsonProperty(&quot;name&quot;) String name,\n    @JsonProperty(&quot;description&quot;) String description,\n    // Schema is often handled as Map&lt;String, Object&gt; or JsonNode in Jackson\n    @JsonProperty(&quot;inputSchema&quot;) JsonSchema inputSchema\n) {}\n \n// ResourceContents using polymorphism annotations\n@JsonTypeInfo(use = JsonTypeInfo.Id.DEDUCTION, include = JsonTypeInfo.As.PROPERTY)\n@JsonSubTypes({\n    @JsonSubTypes.Type(value = TextResourceContents.class, name = &quot;text&quot;),\n    @JsonSubTypes.Type(value = BlobResourceContents.class, name = &quot;blob&quot;)\n})\npublic sealed interface ResourceContents permits TextResourceContents, BlobResourceContents {\n    String uri();\n    String mimeType();\n}\n \n@JsonInclude(JsonInclude.Include.NON_ABSENT)\n@JsonIgnoreProperties(ignoreUnknown = true)\npublic record TextResourceContents(\n    @JsonProperty(&quot;uri&quot;) String uri,\n    @JsonProperty(&quot;mimeType&quot;) String mimeType,\n    @JsonProperty(&quot;text&quot;) String text\n) implements ResourceContents {}\n \n// ... BlobResourceContents ...\nThe Java SDK heavily relies on Jackson’s powerful annotation system within standard Java record/class definitions. The use of nested types keeps all protocol definitions within the McpSchema.java file, which is convenient but can make the file very large. Polymorphism is handled cleanly using Jackson’s built-in annotations.\nComparison: System.Text.Json (C#) vs. Jackson (Java) for MCP\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFeatureSystem.Text.Json (C#)Jackson (Java)Notes for MCPLibraryBuilt-in .NETDe facto standard Java JSON lib (external dep)Both are highly capable and widely used.ConfigurationAttributes, JsonSerializerOptionsAnnotations, ObjectMapper modulesBoth use attributes/annotations heavily. C# options often leverage source-gen context; Java uses ObjectMapper configuration.POCOs/POJOsRecords / ClassesRecords / Classes (often nested)Similar object mapping approaches. Java SDK heavily uses nested types within McpSchema.java.PolymorphismCustom JsonConverter neededBuilt-in (@JsonTypeInfo, @JsonSubTypes)Jackson has more built-in, annotation-driven support for polymorphic types like Content and ResourceContents.Null HandlingC# Nullable Reference Types (?)Standard Java nullable referencesC# provides more explicit compile-time null safety checks.Extensibility[JsonExtensionData] (less used here)@JsonIgnoreProperties(ignoreUnknown=true)Both handle unexpected fields well. Java’s @JsonIgnoreProperties is crucial for MCP. C# relies on default behavior or specific settings.PerformanceHigh (esp. with Source Generation)High (mature, optimized)C#‘s source generation offers potential advantages, especially for AOT. Jackson is highly optimized through maturity.\nBoth SDKs successfully map the MCP schema to their respective language’s object models using standard, powerful JSON libraries. C# leans on modern language features and source generation for type safety and performance, while Java leverages the extensive annotation-based configuration of Jackson.\nEnd-User Impact: The Unseen Foundation\nWhile users don’t directly interact with these schema definitions, they form the bedrock of a reliable MCP experience:\n\nInteroperability: Correctly defined schemas ensure that a C# client can talk to a Java server (or Python/TS servers) and vice-versa, as long as they agree on the protocol version. The data structures match.\nReduced Errors: Validation catches malformed messages early, preventing confusing application errors downstream that the user might otherwise encounter.\nFeature Consistency: When a client requests listTools, the structure of the Tool objects received will be consistent regardless of the server’s implementation language, thanks to the shared schema.\nEnabling Development: These precise definitions allow SDK developers to build higher-level APIs (like the server builders or client methods) that are intuitive and type-safe, accelerating the development of useful MCP features for end-users.\n\nConclusion\nDefining the data contract is a fundamental task for any protocol SDK. Both the C# and Java MCP SDKs accomplish this effectively using the standard JSON libraries and idiomatic patterns of their respective platforms – System.Text.Json with POCOs and source generation in .NET, and Jackson with POJOs and annotations in Java. These carefully crafted schemas ensure that clients and servers speak the same language, enabling the reliable, cross-platform communication that MCP promises.\nWith the contract defined, how do we actually build servers using these SDKs? In the next post, Blog 3: Server APIs - Building Blocks, we’ll compare the high-level APIs and patterns (IMcpServerBuilder in C# vs. the McpServer.sync/async builders in Java) used to configure and launch MCP servers.\n"},"2-Official-c-and-java-sdk-tutes/Blogs/blog-3":{"slug":"2-Official-c-and-java-sdk-tutes/Blogs/blog-3","filePath":"2 Official c# and java sdk tutes/Blogs/blog-3.md","title":"Blog 3: Server APIs - Building Blocks (.NET DI vs. Java Builders)","links":["2-Official-c-and-java-sdk-tutes/Blogs/blog-2","2-Official-c-and-java-sdk-tutes/Blogs/blog-4"],"tags":[],"content":"Blog 3: Server APIs - Building Blocks (.NET DI vs. Java Builders)\nSeries: Deep Dive into the Model Context Protocol SDKs (C# &amp; Java)\r\nPost: 3 of 10\nIn Blog 2, we examined the foundational data contracts – the MCP schemas defined using C# POCOs with System.Text.Json and Java POJOs with Jackson. These schemas ensure clients and servers speak the same language. But how do developers construct a server application using these SDKs?\nWhile the low-level server APIs (which we’ll cover next) offer fine-grained control, both the C# and Java SDKs provide higher-level mechanisms designed to simplify server setup and configuration. These APIs handle boilerplate like registering protocol handlers, integrating with transports, and managing server capabilities.\nThis post compares the primary approaches for building and configuring MCP servers in each SDK:\n\nC# SDK: Leveraging the ubiquitous Microsoft.Extensions.DependencyInjection pattern with IMcpServerBuilder extension methods.\nJava SDK: Employing a fluent Builder pattern via static methods on the McpServer class (McpServer.sync(...), McpServer.async(...)).\n\nC#: Fluent Configuration via Dependency Injection Extensions\nThe C# SDK deeply integrates with the standard .NET dependency injection (DI) and hosting abstractions (Microsoft.Extensions.DependencyInjection, Microsoft.Extensions.Hosting). Configuring an MCP server feels idiomatic for developers familiar with ASP.NET Core or generic host applications.\nThe Core Pattern:\n\nAddMcpServer(): An extension method on IServiceCollection that registers the essential MCP server services and returns an IMcpServerBuilder.\nIMcpServerBuilder Extensions: A series of extension methods (.WithTools&lt;T&gt;(), .WithPrompts&lt;T&gt;(), .WithStdioServerTransport(), .WithHttpTransport(), .WithListResourcesHandler(), etc.) are chained onto the builder to configure server features, handlers, and transports.\nAttribute-Based Discovery: Many extensions (like .WithToolsFromAssembly(), .WithPrompts&lt;T&gt;()) use reflection to find classes and methods marked with specific attributes ([McpServerToolType], [McpServerTool], [McpServerPromptType], [McpServerPrompt]) and register them automatically.\nHosting Integration: The configured services are often used with Microsoft.Extensions.Hosting to run the server, e.g., as a background service (SingleSessionMcpServerHostedService for Stdio) or integrated into an ASP.NET Core application (MapMcp).\n\nExample (Stdio Server with Hosting):\n// Program.cs (Simplified from samples/TestServerWithHosting)\nusing Microsoft.Extensions.DependencyInjection;\nusing Microsoft.Extensions.Hosting;\nusing ModelContextProtocol.Server;\nusing System.ComponentModel;\n \nvar builder = Host.CreateApplicationBuilder(args);\n \n// 1. Add MCP Server services and get the builder\nbuilder.Services.AddMcpServer(options =&gt; {\n        // Configure basic McpServerOptions directly\n        options.ServerInfo = new() { Name = &quot;MyDotNetServer&quot;, Version = &quot;1.1&quot; };\n        options.ServerInstructions = &quot;Use this server for echo and AI sampling.&quot;;\n    })\n    // 2. Configure Stdio Transport\n    .WithStdioServerTransport()\n    // 3. Discover and register tools/prompts via attributes\n    .WithToolsFromAssembly() // Scans current assembly\n    .WithPromptsFromAssembly(); // Scans current assembly\n \n// (Optional: Add other services needed by tools/prompts to DI)\n// builder.Services.AddHttpClient(...);\n \nvar app = builder.Build();\nawait app.RunAsync(); // Runs the IHostedService managing the MCP server\n \n// --- Tool Definition (in same or different file) ---\n[McpServerToolType] // Mark class for discovery\npublic static class MyTools\n{\n    [McpServerTool, Description(&quot;Echoes the message.&quot;)]\n    public static string Echo(string message) =&gt; $&quot;Echo: {message}&quot;;\n \n    // Method parameters like IMcpServer or services from DI\n    // are automatically injected if registered.\n    [McpServerTool]\n    public static async Task&lt;string&gt; UseAi(IMcpServer server, HttpClient http, string query)\n    {\n        // Use injected server context and HttpClient\n        var response = await server.RequestSamplingAsync(/* ... */);\n        return response.Content.Text ?? &quot;&quot;;\n    }\n}\nExample (ASP.NET Core Server):\n// Program.cs (Simplified from samples/AspNetCoreSseServer)\nvar builder = WebApplication.CreateBuilder(args);\n \n// 1. Add MCP Server &amp; Configure Features\nbuilder.Services.AddMcpServer()\n    .WithHttpTransport() // Configures necessary handlers for MapMcp\n    .WithTools&lt;EchoTool&gt;() // Register specific tool types\n    .WithTools&lt;SampleLlmTool&gt;();\n \nvar app = builder.Build();\n \n// 2. Map MCP endpoints (e.g., /mcp, /sse, /message)\napp.MapMcp();\n \napp.Run(); // Runs the ASP.NET Core host\nKey C# Aspects:\n\nDI-Centric: Configuration is tied to the IServiceCollection. Tools and prompts can easily receive dependencies via constructor or method injection.\nFluent Builder Extensions: Provides a discoverable and chainable configuration API.\nAttribute Discovery: Simplifies registration for tools and prompts defined within classes.\nHosting Integration: Seamlessly integrates with standard .NET application hosting models.\n\nJava: Explicit Builder Pattern\nThe Java SDK uses a more traditional Builder pattern, accessed via static factory methods on the McpServer class. It distinguishes explicitly between synchronous and asynchronous server configurations from the start.\nThe Core Pattern:\n\nMcpServer.sync(provider) / McpServer.async(provider): Static methods initiate the builder, requiring an McpServerTransportProvider instance upfront.\nBuilder Methods: Chain methods like .serverInfo(...), .capabilities(...), .tools(...), .resources(...), .prompts(...), .requestTimeout(...) on the returned SyncSpecification or AsyncSpecification object.\nHandler Registration: Methods like .tools(...) typically accept lists or maps of “Specification” objects (e.g., AsyncToolSpecification, SyncResourceSpecification). These specifications pair the metadata (like Tool or Resource objects) with the corresponding handler Function or BiFunction.\n.build(): Finalizes the configuration and returns the configured McpSyncServer or McpAsyncServer instance.\nRunning: The transport provider often needs separate integration (e.g., providing a router function for Spring WebFlux, using a Servlet for WebMvc, or manual stream handling for Stdio). The server logic itself doesn’t automatically “run” just from building; it depends on the transport provider’s lifecycle.\n\nExample (Async Stdio Server):\n// Java Example (Conceptual - requires transport setup)\nimport io.modelcontextprotocol.server.*;\nimport io.modelcontextprotocol.server.transport.*;\nimport io.modelcontextprotocol.spec.*;\nimport io.modelcontextprotocol.spec.McpSchema.*;\nimport reactor.core.publisher.Mono;\nimport java.util.List;\nimport java.util.Map;\n// ... other imports\n \n// 1. Create Transport Provider\nMcpServerTransportProvider transportProvider = new StdioServerTransportProvider();\n \n// Define a tool specification\nTool echoToolMeta = new Tool(&quot;echo&quot;, &quot;Echoes input&quot;, /* schema */ &quot;{\\&quot;type\\&quot;:\\&quot;object\\&quot;,...}&quot;);\nAsyncToolSpecification echoToolSpec = new AsyncToolSpecification(\n    echoToolMeta,\n    (exchange, args) -&gt; Mono.just(new CallToolResult(\n        List.of(new TextContent(&quot;Echo: &quot; + args.get(&quot;message&quot;))), false\n    ))\n);\n \n// Define a resource specification\nResource configResourceMeta = new Resource(&quot;config://app&quot;, &quot;App Config&quot;, &quot;application/json&quot;, null, null);\nAsyncResourceSpecification configResourceSpec = new AsyncResourceSpecification(\n    configResourceMeta,\n    (exchange, req) -&gt; Mono.just(new ReadResourceResult(\n        List.of(new TextResourceContents(req.uri(), &quot;application/json&quot;, &quot;{\\&quot;theme\\&quot;:\\&quot;dark\\&quot;}&quot;))\n    ))\n);\n \n// 2. Start builder chain\nMcpAsyncServer server = McpServer.async(transportProvider)\n    // 3. Configure via builder methods\n    .serverInfo(&quot;MyJavaServer&quot;, &quot;1.0&quot;)\n    .instructions(&quot;Instructions for Java server.&quot;)\n    .capabilities(ServerCapabilities.builder().tools(true).resources(true, false).build()) // Explicit capabilities\n    .tools(echoToolSpec) // Pass specification objects\n    .resources(Map.of(configResourceMeta.uri(), configResourceSpec)) // Can use maps\n    // ... other configurations (.prompts, .requestTimeout) ...\n    // 4. Build the server logic object\n    .build();\n \n// 5. Running depends on the transport provider\n// For Stdio, you might manually start the session handling loop if not using hosting\n// (The SDK&#039;s tests and samples often wrap this)\n// transportProvider.setSessionFactory(... server logic using session...);\n// --&gt; Start listening on System.in/out via the provider...\nKey Java Aspects:\n\nBuilder Pattern: Classic Java pattern for object construction and configuration.\nExplicit Sync/Async: Separate builder entry points (McpServer.sync/.async) lead to distinct server types.\nHandler Specifications: Requires wrapping handler functions along with metadata into *Specification objects before passing them to the builder.\nTransport Provider: Server creation is tied to a specific McpServerTransportProvider instance from the start.\nFramework Integration: Less built-in core integration; relies on specific modules (mcp-spring-webflux, mcp-spring-webmvc) or manual setup for web frameworks.\n\nComparison: Building Servers\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFeatureC# (.NET DI Extensions)Java (Builder Pattern)NotesConfiguration StyleFluent Extensions on IServiceCollectionFluent Methods on Sync/AsyncSpecificationC# ties into the standard DI configuration flow. Java uses a self-contained builder.Handler RegistrationAttribute Discovery / DI / Manual HandlersPassing *Specification objects to builderC# offers more automatic discovery via attributes. Java requires explicitly creating specification objects containing both metadata and the handler lambda/method reference.Transport ConfigBuilder Extensions (.With*Transport)Passed to initial Builder methodTransport choice is made earlier in Java’s builder flow. C# configures it via extensions.CapabilitiesOften inferred or set via OptionsSet via .capabilities() methodBoth allow explicit capability setting, but C# DI extensions might infer some based on registered handlers/tools.DependenciesStandard .NET DIHandlers receive Exchange objectC# leverages DI for injecting services into tools/prompts. Java provides context via the Exchange object passed to handlers.Framework FitIdiomatic for ASP.NET Core/Generic HostStandard Java Builder; specific Spring modulesC# feels very native to modern .NET development. Java provides good core flexibility and dedicated Spring modules for framework integration.\nEnd-User Impact: Stability, Features, and Integration\nThe way server APIs are designed impacts the end user indirectly but significantly:\n\nDeveloper Productivity: Easier configuration (subjective, but arguably Python &gt; C# &gt; Java core in terms of boilerplate for simple cases) means developers can ship MCP features faster.\nRobustness: Clear configuration patterns reduce the chance of misconfiguration. C#‘s DI helps manage dependencies for complex tools, while Java’s explicit specifications ensure handlers are correctly associated.\nIntegration Depth: Framework-specific integrations (ASP.NET Core, Spring) allow MCP servers to leverage existing authentication, logging, monitoring, and deployment infrastructure within enterprise applications, leading to more polished and maintainable features for users.\nFeature Availability: The ease (or difficulty) of implementing specific MCP capabilities (like dynamic updates, complex resources) in the SDK influences whether developers will expose those advanced features to end-users.\n\nConclusion\nBoth the C# and Java MCP SDKs provide capable high-level APIs for building servers, but they reflect the distinct idioms of their ecosystems. C# embraces the .NET dependency injection and hosting model, offering fluent configuration through extension methods and convenient attribute-based discovery. Java utilizes a classic Builder pattern, separating sync/async concerns early and requiring explicit handler “Specification” objects, while providing dedicated modules for seamless Spring integration.\nNeither approach is inherently superior; the best fit depends on the target platform and developer preference. C#‘s DI integration might appeal strongly to ASP.NET Core developers, while Java’s explicit Builder and dedicated Spring modules cater well to the JVM world. Both successfully abstract much of the underlying protocol complexity, enabling developers to focus on building valuable MCP integrations.\nHaving explored the high-level server APIs, our next post will delve into the low-level server internals, examining the core Server and session management classes to understand the foundational mechanics shared by both high-level approaches.\n"},"2-Official-c-and-java-sdk-tutes/Blogs/blog-4":{"slug":"2-Official-c-and-java-sdk-tutes/Blogs/blog-4","filePath":"2 Official c# and java sdk tutes/Blogs/blog-4.md","title":"Blog 4: Server Architecture - Under the Hood (MCP C# & Java Internals)","links":["2-Official-c-and-java-sdk-tutes/Blogs/blog-3"],"tags":[],"content":"Blog 4: Server Architecture - Under the Hood (MCP C# &amp; Java Internals)\nSeries: Deep Dive into the Model Context Protocol SDKs (C# &amp; Java)\r\nPost: 4 of 10\nIn Blog 3, we admired the convenience of the high-level server APIs offered by the C# and Java Model Context Protocol (MCP) SDKs. C#‘s IMcpServerBuilder extensions and Java’s McpServer.sync/async builders provide streamlined ways to configure servers using dependency injection or fluent patterns.\nBut what lies beneath these user-friendly facades? How does the SDK actually manage connections, route requests, handle notifications, and interact with the transport layer? Understanding these internals is key for advanced customization, debugging complex issues, or integrating MCP deeply into existing systems.\nThis post lifts the hood to explore the core server classes and session management logic:\n\nC# SDK: Examining the internal McpServer, the role of McpSession, and the ITransport interface.\nJava SDK: Unpacking the McpAsync/SyncServer, the central McpServerSession, and the McpServerTransportProvider pattern.\nComparing how each SDK handles request dispatch, context, and session lifecycles at this fundamental level.\n\nWhy Look Under the Hood?\nWhile the high-level APIs are often sufficient, exploring the internals offers:\n\nDeeper Understanding: See how the magic of the high-level APIs actually works.\nCustomization: Identify extension points or base classes for building custom transports or specialized server behaviors.\nDebugging: Trace request flows more effectively when troubleshooting unexpected behavior.\nComplex Integrations: Understand how to wire MCP into applications where standard hosting models don’t quite fit.\n\nC# SDK: DI, Sessions, and Transport Interaction\nThe C# SDK’s low-level architecture is tightly integrated with .NET’s hosting and DI patterns, even at its core.\nKey Components:\n\nMcpServer (Internal Class - src/.../Server/McpServer.cs):\n\nThis is the concrete implementation behind the IMcpServer interface, often resolved via DI.\nIt likely extends the internal McpEndpoint base class (shared client/server logic, analogous to Protocol in TS).\nResponsibilities: Holds configuration (McpServerOptions), manages the core McpSession, potentially coordinates with the hosting layer (IHostedService).\nHandlers: Stores registered request handlers (delegates) internally, likely in dictionaries keyed by method name (RequestHandlers). These are populated by the IMcpServerBuilder extensions or direct configuration. Similarly for NotificationHandlers.\n\n\nMcpSession (Internal Class - src/.../Shared/McpSession.cs):\n\nRepresents a single active MCP communication session over a specific transport.\nResponsibilities: Manages the lifecycle of a connection via an ITransport, handles JSON-RPC message framing, correlates requests and responses using IDs (_pendingRequests), dispatches incoming messages to the correct handlers stored in McpServer, manages cancellation tokens for requests (_handlingRequests).\nProcessMessagesAsync: The core loop that reads from the transport’s MessageReader channel and calls HandleMessageAsync.\nHandleMessageAsync: Determines message type (Request, Response, Notification) and routes it appropriately. For requests, it looks up the handler in McpServer’s collection and invokes it.\n\n\nITransport (src/.../Protocol/Transport/ITransport.cs):\n\nThe interface abstracting the communication channel (Stdio, HTTP Streamable/SSE, etc.).\nProvides MessageReader (a ChannelReader&lt;JsonRpcMessage&gt;) for the McpSession to consume incoming messages.\nProvides SendMessageAsync(JsonRpcMessage, CancellationToken) for the McpSession to send outgoing messages.\nHandles connection lifecycle (DisposeAsync).\n\n\nRequestContext&lt;TParams&gt; (src/.../Server/RequestContext.cs):\n\nA container passed to specific handler delegates (configured via builder extensions).\nProvides access to the IMcpServer instance, the specific request parameters (TParams), and crucially, the IServiceProvider (potentially scoped if ScopeRequests is true). This enables DI within handlers even when using the lower-level handler registration mechanisms.\n\n\n\nConceptual Flow (Request):\nTransport (ITransport) receives raw data → Parses into JsonRpcMessage → Writes to MessageReader Channel → McpSession.ProcessMessagesAsync reads from channel → Calls HandleMessageAsync → Identifies as Request → Looks up handler in McpServer.RequestHandlers → Invokes handler (potentially creating DI scope, passing RequestContext) → Handler returns result → McpSession sends JsonRpcResponse via ITransport.SendMessageAsync.\nLow-Level Configuration (Less Common):\nWhile typically done via IMcpServerBuilder, you could theoretically instantiate McpServer more directly (if its constructor were public or via internal access) and configure McpServerOptions with handler delegates manually:\n// Conceptual C# Low-Level Configuration (Illustrative)\nvar options = new McpServerOptions { /* ... server info, capabilities ... */ };\n \n// Manually populate handler delegates in capabilities\noptions.Capabilities.Tools ??= new();\noptions.Capabilities.Tools.ListToolsHandler = async (requestContext, ct) =&gt; {\n    // Access DI via requestContext.Services if needed\n    // IMyToolService toolService = requestContext.Services.GetRequiredService&lt;IMyToolService&gt;();\n    var tools = /* ... logic to get tools ... */;\n    return new ListToolsResult { Tools = tools };\n};\noptions.Capabilities.Tools.CallToolHandler = async (requestContext, ct) =&gt; {\n    var toolName = requestContext.Params?.Name;\n    var args = requestContext.Params?.Arguments;\n    // ... find and execute tool logic ...\n    // Use requestContext.Server.SendMessageAsync for notifications if needed\n    return new CallToolResponse { /* ... */ };\n};\n// ... add other handlers similarly ...\n \n// Create transport and server (DI usually handles this)\nITransport transport = new StdioServerTransport(options); // Or other transport\nIMcpServer server = new McpServer(transport, options, loggerFactory, serviceProvider);\n \n// Start the server&#039;s processing loop\nawait server.RunAsync();\nThis demonstrates that the core mechanism relies on populating the handler delegates within McpServerOptions.Capabilities.\nJava SDK: Transport Providers and Session Focus\nThe Java SDK employs a slightly different architectural pattern, notably the Transport Provider model for handling connections.\nKey Components:\n\nMcpServerTransportProvider (spec/McpServerTransportProvider.java):\n\nAn interface responsible for accepting client connections and creating per-session transports.\nImplementations exist for Stdio, Servlets, WebFlux, WebMvc.\nsetSessionFactory(McpServerSession.Factory): This method is called by the McpServer during its setup. The provider stores this factory.\nWhen a new client connects (e.g., HTTP request arrives), the provider:\n\nCreates an appropriate McpServerTransport instance for that specific connection (e.g., HttpServletMcpSessionTransport, WebFluxMcpSessionTransport).\nUses the stored sessionFactory to create a new McpServerSession linked to that transport.\n\n\nAlso handles broadcasting notifications (notifyClients) and graceful shutdown (closeGracefully).\n\n\nMcpServerTransport (spec/McpServerTransport.java):\n\nAn interface representing the communication channel for a single client session.\nImplementations (like StdioMcpSessionTransport, WebFluxMcpSessionTransport) handle sending messages (sendMessage) for their specific session. Receiving is implicitly handled by routing incoming data (from the Provider) to the correct McpServerSession.\n\n\nMcpServerSession (spec/McpServerSession.java):\n\nThe core logic unit for managing one client connection. Analogous to C#‘s internal McpSession.\nResponsibilities: Holds the McpServerTransport for its connection, handles incoming messages (handle(JSONRPCMessage)), correlates requests/responses (pendingResponses), manages request/notification handler dictionaries (requestHandlers, notificationHandlers), performs initialization handshake logic.\nIt receives handler maps during construction (populated by the McpAsync/SyncServer builders).\n\n\nMcpAsyncServer / McpSyncServer (server/):\n\nThese are the public-facing server classes. They act more like configurators and orchestrators than the central processing unit.\nTheir builders configure McpServerFeatures (containing handler lists/maps).\nWhen built, they primarily configure the McpServerTransportProvider by calling setSessionFactory, passing a factory that creates McpServerSession instances configured with the collected handlers. They don’t directly handle individual messages in the same way C#‘s McpServer does via its McpSession.\n\n\nMcpAsync/SyncServerExchange (server/):\n\nPassed to the user-defined handler functions (provided in the *Specification objects to the builder).\nProvides access to the specific McpServerSession for that request, client capabilities/info, and convenience methods (createMessage, listRoots, loggingNotification). This is the primary way handlers interact with the MCP context.\n\n\n\nConceptual Flow (Request):\nNetwork Listener (e.g., Tomcat, Netty) receives connection → McpServerTransportProvider implementation accepts connection → Creates McpServerTransport for the connection → Calls sessionFactory.create(transport) → Creates McpServerSession → McpServerSession starts listening on its transport → Transport receives raw data → Parses to JsonRpcMessage → Calls McpServerSession.handle(message) → Session looks up handler in its requestHandlers map → Invokes handler, passing an Exchange object → Handler returns result → Session sends JsonRpcResponse via its McpServerTransport.sendMessage.\nLow-Level Configuration:\nIn Java, configuring the server involves creating the McpServerFeatures object (which holds the handler maps/lists) and passing it to the McpAsync/SyncServer constructor directly, bypassing the builder.\n// Conceptual Java Low-Level Configuration (Illustrative)\nimport io.modelcontextprotocol.server.*;\nimport io.modelcontextprotocol.server.transport.*;\nimport io.modelcontextprotocol.spec.*;\nimport io.modelcontextprotocol.spec.McpSchema.*;\nimport reactor.core.publisher.Mono;\nimport java.util.List;\nimport java.util.Map;\nimport com.fasterxml.jackson.databind.ObjectMapper;\n \n// 1. Create Transport Provider\nMcpServerTransportProvider transportProvider = new StdioServerTransportProvider();\n \n// 2. Define Handlers (as BiFunctions taking Exchange and Params)\nBiFunction&lt;McpAsyncServerExchange, Map&lt;String, Object&gt;, Mono&lt;CallToolResult&gt;&gt; echoHandler =\n    (exchange, args) -&gt; Mono.just(new CallToolResult(\n        List.of(new TextContent(&quot;Echo: &quot; + args.get(&quot;message&quot;))), false\n    ));\n \nBiFunction&lt;McpAsyncServerExchange, ReadResourceRequest, Mono&lt;ReadResourceResult&gt;&gt; resourceHandler =\n    (exchange, req) -&gt; Mono.just(new ReadResourceResult(\n        List.of(new TextResourceContents(req.uri(), &quot;text/plain&quot;, &quot;Data for &quot; + req.uri()))\n    ));\n \n// 3. Create Feature Specifications\nTool echoToolMeta = new Tool(&quot;echo&quot;, &quot;Echoes&quot;, &quot;{\\&quot;type\\&quot;:\\&quot;object\\&quot;, ...}&quot;);\nAsyncToolSpecification echoToolSpec = new AsyncToolSpecification(echoToolMeta, echoHandler);\n \nResource configResourceMeta = new Resource(&quot;config://app&quot;, &quot;Config&quot;, &quot;app/json&quot;, null, null);\nAsyncResourceSpecification configResourceSpec = new AsyncResourceSpecification(configResourceMeta, resourceHandler);\n \n// 4. Create McpServerFeatures\nMcpServerFeatures.Async features = new McpServerFeatures.Async(\n    new Implementation(&quot;LowLevelJavaServer&quot;, &quot;0.9&quot;),\n    ServerCapabilities.builder().tools(true).resources(true, false).build(),\n    List.of(echoToolSpec),                 // List of Tool Specs\n    Map.of(configResourceMeta.uri(), configResourceSpec), // Map of Resource Specs\n    List.of(),                             // List of Resource Templates\n    Map.of(),                              // Map of Prompt Specs\n    Map.of(),                              // Map of Completion Specs\n    List.of(),                             // List of Root Change Handlers\n    &quot;Manual Server Instructions&quot;\n);\n \n// 5. Instantiate the server directly\nDuration timeout = Duration.ofSeconds(10);\nObjectMapper mapper = new ObjectMapper();\n// Note: McpUriTemplateManagerFactory might be needed if using URI templates\nMcpAsyncServer lowLevelServer = new McpAsyncServer(transportProvider, mapper, features, timeout, null);\n \n// 6. Run the server (often managed by the application host)\n// transportProvider.setSessionFactory(...); // Implicitly done by McpAsyncServer constructor\n// --&gt; Start listening via the transport provider...\nComparison: Server Internals\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFeatureC# SDKJava SDKNotesCore Session LogicMcpSession (internal)McpServerSessionManages a single client connection, request/response mapping, basic handlers.Connection ManagementITransport (individual)McpServerTransportProvider (accepts connections)Java has an explicit provider layer for handling new connections and creating per-session transports.Handler StorageRequestHandlers/NotificationHandlers in McpServerHandler Maps within McpServerSessionHandlers are associated with the central server (C#) or the per-client session (Java).Handler InvocationMcpSession calls handler via McpServerMcpServerSession calls handler directlyContext for HandlersRequestContext (includes IServiceProvider)McpAsync/SyncServerExchange (includes McpServerSession)Both provide request/session context. C# leans on DI; Java uses the explicit Exchange object parameter.Sync/AsyncUnified async/await (Task)Explicit McpAsyncServer/McpSyncServer typesJava makes the sync/async programming model choice explicit at the server class level.Hosting/LifecycleIntegrates with IHostedServiceRelies on McpServerTransportProvider lifecycleC# lifecycle often tied to .NET Host; Java lifecycle depends on how the Provider is managed (e.g., Servlet container, Spring Boot).\nConclusion: Architecture Reflects Ecosystems\nDelving into the low-level server internals reveals how each SDK adapts MCP concepts to its platform’s strengths and conventions.\n\nC# provides a unified IMcpServer experience heavily integrated with Dependency Injection. The McpServer acts as the central brain, configured via DI, while the internal McpSession manages the protocol details over an ITransport.\nJava utilizes a Transport Provider pattern, clearly separating connection management (McpServerTransportProvider) from per-connection communication (McpServerTransport used by McpServerSession). The public McpAsync/SyncServer classes act primarily as configurators, setting up the handlers that the McpServerSession will invoke, passing an Exchange object for context.\n\nUnderstanding these internal architectures is crucial for debugging, extending the SDKs, or integrating MCP into non-standard hosting environments. While the high-level APIs abstract much of this, the core session and transport logic ensures robust MCP communication under the hood.\nWith both client and server architectures explored, we’ll next look at some of the Advanced Capabilities like dynamic updates, context injection, and CLI tooling in Blog 9.\n"},"2-Official-c-and-java-sdk-tutes/Blogs/blog-5":{"slug":"2-Official-c-and-java-sdk-tutes/Blogs/blog-5","filePath":"2 Official c# and java sdk tutes/Blogs/blog-5.md","title":"Blog 5: Client APIs - Consuming MCP Services in .NET and Java","links":["2-Official-c-and-java-sdk-tutes/Blogs/blog-3","2-Official-c-and-java-sdk-tutes/Blogs/blog-4"],"tags":[],"content":"Blog 5: Client APIs - Consuming MCP Services in .NET and Java\nSeries: Deep Dive into the Model Context Protocol SDKs (C# &amp; Java)\r\nPost: 5 of 10\nIn our series exploring the Model Context Protocol (MCP) SDKs, we’ve spent the last few posts dissecting the server-side architecture – from the high-level APIs to the low-level internals. Now, we pivot to the other essential half of the equation: the MCP Client.\nClients are the applications that consume the context (Resources) and capabilities (Tools, Prompts) exposed by MCP servers. They might be AI chatbots needing to call external tools, IDE extensions providing code context, or any application aiming to leverage services offered through the standardized MCP interface.\nThis post focuses on the primary interfaces and classes provided by the C# and Java SDKs for building these clients:\n\nC# SDK: The IMcpClient interface and its creation via McpClientFactory.\nJava SDK: The McpAsyncClient and McpSyncClient classes, configured via the McpClient.async/sync builders.\n\nWe’ll examine how developers use these APIs to connect to servers, perform the initialization handshake, make requests (like listing/calling tools, reading resources, getting prompts), and handle server-sent notifications.\nThe Client Interfaces: Your Window to the MCP World\nBoth SDKs provide well-defined entry points for client-side operations:\n\n\nC# (IMcpClient - src/ModelContextProtocol/Client/IMcpClient.cs):\n\nAn interface defining the contract for an MCP client.\nInherits from IMcpEndpoint (shared methods like SendMessageAsync, SendRequestAsync, RegisterNotificationHandler, DisposeAsync).\nAdds properties specific to a connected client: ServerCapabilities, ServerInfo, ServerInstructions.\nConcrete implementation (McpClient) is typically obtained via McpClientFactory.CreateAsync.\nInteraction is primarily through extension methods defined in McpClientExtensions (e.g., client.ListToolsAsync(), client.CallToolAsync(...)).\n\n\n\nJava (McpAsyncClient / McpSyncClient - mcp/src/.../client/):\n\nTwo distinct concrete classes offering either asynchronous (Project Reactor Mono/Flux) or synchronous (blocking) APIs.\nCreated using the McpClient.async(...) or McpClient.sync(...) static builder methods.\nBoth classes provide direct methods for MCP operations (e.g., client.listTools(), client.callTool(...), client.readResource(...)).\nThey internally manage an McpClientSession which handles the core protocol logic over a chosen transport.\n\n\n\nConnecting and Initializing: The Handshake Revisited\nAs we saw from the server perspective, establishing an MCP connection requires an initialization handshake. The client SDKs manage this process.\nC# (McpClientFactory.CreateAsync):\nThe factory pattern in C# encapsulates both transport connection and the MCP initialize handshake.\nusing ModelContextProtocol.Client;\nusing ModelContextProtocol.Protocol.Transport;\nusing Microsoft.Extensions.Logging; // Optional\n \n// 1. Create Transport (e.g., Stdio)\nvar transport = new StdioClientTransport(new StdioClientTransportOptions {\n    Command = &quot;path/to/server/executable&quot;,\n    // ... other options\n});\n \n// 2. Define Client Options (Optional)\nvar clientOptions = new McpClientOptions {\n    ClientInfo = new() { Name = &quot;MyDotNetClient&quot;, Version = &quot;1.0&quot; },\n    Capabilities = new() { Sampling = new() { /* ... handler ... */ } }\n    // InitializationTimeout = TimeSpan.FromSeconds(45)\n};\n \n// 3. Create and Connect using the Factory\n// This single call:\n//   - Calls transport.ConnectAsync() to get an ITransport session\n//   - Creates the internal McpClient/McpSession\n//   - Sends the &#039;initialize&#039; request\n//   - Processes the &#039;initialize&#039; response\n//   - Sends the &#039;notifications/initialized&#039; notification\n//   - Returns the ready-to-use IMcpClient\nIMcpClient client = await McpClientFactory.CreateAsync(\n    transport,\n    clientOptions,\n    loggerFactory // Optional\n    // CancellationToken can be passed here\n);\n \nConsole.WriteLine($&quot;Connected to: {client.ServerInfo.Name} v{client.ServerInfo.Version}&quot;);\n// Client is now ready to use\nJava (McpClient.async/sync(...).build() then client.initialize()):\nJava uses the builder pattern, and initialization is an explicit first step after building the client instance.\nimport io.modelcontextprotocol.client.*;\nimport io.modelcontextprotocol.client.transport.*;\nimport io.modelcontextprotocol.spec.*;\nimport io.modelcontextprotocol.spec.McpSchema.*;\nimport reactor.core.publisher.Mono; // If using async\n \n// 1. Create Transport (e.g., Stdio)\nMcpClientTransport transport = new StdioClientTransport(\n    ServerParameters.builder(&quot;path/to/server/executable&quot;).build()\n);\n \n// 2. Configure and Build Client (Async example)\nMcpAsyncClient asyncClient = McpClient.async(transport)\n    .requestTimeout(Duration.ofSeconds(10))\n    .clientInfo(new Implementation(&quot;MyJavaClient&quot;, &quot;1.0&quot;))\n    .capabilities(ClientCapabilities.builder().sampling().build())\n    // .sampling(...) - Register sampling handler if needed\n    .build();\n \n// 3. Explicitly Initialize (Performs the handshake)\ntry {\n    // initialize() returns the InitializeResult (or throws McpError)\n    InitializeResult initResult = asyncClient.initialize().block(); // block() for sync example\n    System.out.println(&quot;Connected to: &quot; + initResult.serverInfo().name());\n    // Client is ready\n} catch (McpError e) {\n    System.err.println(&quot;Initialization failed: &quot; + e.getMessage());\n    asyncClient.close(); // Important to close if init fails\n    return;\n} catch (Exception e) {\n    System.err.println(&quot;Connection failed: &quot; + e.getMessage());\n    asyncClient.close();\n    return;\n}\n \n// ... use client ...\n \nasyncClient.closeGracefully().block(); // Close when done\nComparison: C#‘s factory method provides a slightly more convenient “connect and initialize” single step. Java’s explicit initialize() call makes the handshake boundary clearer in the code flow. Both achieve the same outcome: a connected and initialized client ready for MCP operations.\nInteracting with Server Primitives\nOnce initialized, clients interact with the server’s Tools, Resources, and Prompts using intuitive methods.\nListing Primitives:\n// C# (using extension methods on IMcpClient)\nIList&lt;McpClientTool&gt; tools = await client.ListToolsAsync();\nIList&lt;McpClientPrompt&gt; prompts = await client.ListPromptsAsync();\nIList&lt;Resource&gt; resources = await client.ListResourcesAsync();\nIList&lt;ResourceTemplate&gt; templates = await client.ListResourceTemplatesAsync();\n// Java (using methods on McpAsyncClient/McpSyncClient)\n// Async example\nListToolsResult toolsResult = asyncClient.listTools().block(); // or subscribe()\nListPromptsResult promptsResult = asyncClient.listPrompts().block();\nListResourcesResult resourcesResult = asyncClient.listResources().block();\nListResourceTemplatesResult templatesResult = asyncClient.listResourceTemplates().block();\n \n// Sync example\n// ListToolsResult toolsResult = syncClient.listTools();\n// ... etc ...\nCalling a Tool:\n// C# (using extension method)\nCallToolResponse response = await client.CallToolAsync(\n    &quot;calculate_sum&quot;,\n    new Dictionary&lt;string, object?&gt; { [&quot;a&quot;] = 5, [&quot;b&quot;] = 10 }\n);\n// Access response.Content, response.IsError\n \n// Or using the McpClientTool wrapper (integrates with Microsoft.Extensions.AI)\nMcpClientTool sumTool = tools.First(t =&gt; t.Name == &quot;calculate_sum&quot;);\nJsonElement rawResult = (JsonElement)(await sumTool.InvokeAsync(\n    new() { [&quot;a&quot;] = 5, [&quot;b&quot;] = 10 }\n));\nCallToolResponse typedResponse = JsonSerializer.Deserialize&lt;CallToolResponse&gt;(rawResult /* ... */);\n// Java (using direct method)\n// Async example\nCallToolRequest request = new CallToolRequest(\n    &quot;calculate_sum&quot;,\n    Map.of(&quot;a&quot;, 5, &quot;b&quot;, 10)\n);\nCallToolResult result = asyncClient.callTool(request).block(); // or subscribe()\n// Access result.content(), result.isError()\n \n// Sync example\n// CallToolResult result = syncClient.callTool(request);\nReading a Resource:\n// C# (using extension method)\nReadResourceResult result = await client.ReadResourceAsync(&quot;config://app/settings.json&quot;);\n// Access result.Contents\n// Java (using direct method)\nReadResourceRequest request = new ReadResourceRequest(&quot;config://app/settings.json&quot;);\nReadResourceResult result = asyncClient.readResource(request).block(); // or subscribe()\n// Access result.contents()\nGetting a Prompt:\n// C# (using extension method)\nGetPromptResult result = await client.GetPromptAsync(\n    &quot;summarize_topic&quot;,\n    new Dictionary&lt;string, object?&gt; { [&quot;topic&quot;] = &quot;MCP Transports&quot; }\n);\n// Access result.Messages, result.Description\n// Java (using direct method)\nGetPromptRequest request = new GetPromptRequest(\n    &quot;summarize_topic&quot;,\n    Map.of(&quot;topic&quot;, &quot;MCP Transports&quot;)\n);\nGetPromptResult result = asyncClient.getPrompt(request).block(); // or subscribe()\n// Access result.messages(), result.description()\nComparison: C# relies heavily on extension methods for a fluent API directly on IMcpClient. Java provides direct methods on the McpAsync/SyncClient classes, requiring manual construction of request objects (CallToolRequest, ReadResourceRequest, etc.). C#‘s McpClientTool provides useful integration with Microsoft.Extensions.AI’s function calling.\nHandling Server Notifications\nServers can send unsolicited notifications (logging, list changes, resource updates). Clients need to register handlers.\nC# (RegisterNotificationHandler):\nUses an IAsyncDisposable pattern. You register a handler for a specific method name and dispose of the registration when done.\n// C#\nusing ModelContextProtocol.Protocol.Messages;\nusing ModelContextProtocol.Protocol.Types;\nusing System.Text.Json;\n \n// Assuming &#039;client&#039; is an initialized IMcpClient\n \n// Register handler for logging messages\nawait using var loggingRegistration = client.RegisterNotificationHandler(\n    NotificationMethods.LoggingMessageNotification, // Method constant\n    async (notification, cancellationToken) =&gt; { // Async lambda handler\n        var logParams = JsonSerializer.Deserialize&lt;LoggingMessageNotificationParams&gt;(\n            notification.Params, /* options */);\n        if (logParams != null) {\n            Console.WriteLine($&quot;[SERVER LOG {logParams.Level}]: {logParams.Data}&quot;);\n        }\n    }\n);\n \n// Register handler for tool list changes\nawait using var toolsChangedRegistration = client.RegisterNotificationHandler(\n    NotificationMethods.ToolListChangedNotification,\n    async (notification, cancellationToken) =&gt; {\n        Console.WriteLine(&quot;Server tool list changed! Refreshing...&quot;);\n        // Trigger refresh logic, e.g., call client.ListToolsAsync() again\n    }\n);\n \n// Handlers remain active until &#039;loggingRegistration&#039; or &#039;toolsChangedRegistration&#039;\n// are disposed (e.g., at the end of an &#039;await using&#039; block or manually).\nJava (Builder Configuration):\nHandlers (Consumers or Functions returning Mono&lt;Void&gt;) are passed to the McpClient.async/sync builder during setup.\n// Java\nimport io.modelcontextprotocol.client.*;\nimport io.modelcontextprotocol.spec.McpSchema.*;\nimport reactor.core.publisher.Mono;\nimport java.util.List;\nimport java.util.function.Consumer;\nimport java.util.function.Function;\n \n// Define consumers/functions\nConsumer&lt;List&lt;Tool&gt;&gt; toolsChangedConsumer = tools -&gt; {\n    System.out.println(&quot;Tools changed (Sync): &quot; + tools.size());\n    // Refresh logic\n};\n \nFunction&lt;LoggingMessageNotification, Mono&lt;Void&gt;&gt; loggingConsumerAsync = notification -&gt; {\n    return Mono.fromRunnable(() -&gt;\n        System.out.println(&quot;[SERVER LOG ASYNC &quot; + notification.level() + &quot;]: &quot; + notification.data())\n    );\n};\n \n// Configure client builder (Async example)\nMcpAsyncClient asyncClient = McpClient.async(transport)\n    // ... other configurations ...\n    .loggingConsumer(loggingConsumerAsync) // For async handlers\n    .build();\n \n// Configure client builder (Sync example)\nMcpSyncClient syncClient = McpClient.sync(transport)\n    // ... other configurations ...\n    .toolsChangeConsumer(toolsChangedConsumer) // For sync handlers\n    .build();\n \n// Handlers are active for the lifetime of the client object.\nComparison: C# uses a dynamic registration model via RegisterNotificationHandler returning an IAsyncDisposable, allowing handlers to be added/removed during the client’s lifetime. Java registers handlers upfront via the builder, tying their lifetime to the client instance.\nConclusion: Consistent Access Across Platforms\nBoth the C# and Java MCP SDKs provide robust and idiomatic ways for client applications to interact with MCP servers.\n\nC# leverages the IMcpClient interface, extension methods, and the McpClientFactory for a streamlined connection and interaction experience, integrating well with async/await and System.Text.Json. Its McpClientTool offering smooths integration with Microsoft.Extensions.AI.\nJava offers distinct McpSyncClient and McpAsyncClient classes catering to different programming models, configured via a comprehensive builder pattern and utilizing Project Reactor for asynchronous operations.\n\nWhile the API styles differ, both SDKs successfully abstract the underlying JSON-RPC communication and MCP specifics, allowing developers to focus on consuming Tools, Resources, and Prompts to build powerful, context-aware applications on their preferred enterprise platform.\nNext, we revisit the transports, focusing specifically on the C# SDK’s ASP.NET Core integration and comparing it to Java’s Spring/Servlet-based approaches in Blog 8: Framework Integration.\n"},"2-Official-c-and-java-sdk-tutes/Blogs/blog-6":{"slug":"2-Official-c-and-java-sdk-tutes/Blogs/blog-6","filePath":"2 Official c# and java sdk tutes/Blogs/blog-6.md","title":"Blog 6: Local Channels - The Stdio Transport in .NET and Java MCP","links":["2-Official-c-and-java-sdk-tutes/Blogs/blog-2","2-Official-c-and-java-sdk-tutes/Blogs/blog-3","2-Official-c-and-java-sdk-tutes/Blogs/blog-4","2-Official-c-and-java-sdk-tutes/Blogs/blog-5"],"tags":[],"content":"Blog 6: Local Channels - The Stdio Transport in .NET and Java MCP\nSeries: Deep Dive into the Model Context Protocol SDKs (C# &amp; Java)\r\nPost: 6 of 10\nWelcome back! In our exploration of the Model Context Protocol (MCP) SDKs for C# and Java, we’ve covered the protocol’s definition, the high-level and low-level server APIs, and the client architecture. Today, we shift focus to the communication pathways themselves – the Transports.\nTransports are the fundamental mechanism for exchanging MCP messages (requests, responses, notifications) between a client and a server. They abstract the underlying communication channel, whether it’s network sockets, HTTP streams, or, as we’ll explore today, the standard streams of a local process.\nThis post dives into the Stdio (Standard Input/Output) transport, a crucial component for enabling local interactions in both the C# and Java SDKs.\nWhat is Stdio Transport?\nImagine you have a powerful command-line tool, a script, or even a full desktop application written in C# or Java that you want an AI assistant (the MCP client) to interact with. You don’t want to expose this tool over the network for security or simplicity reasons. This is where Stdio shines.\nThe Stdio transport facilitates communication between two processes running on the same machine:\n\nThe Client: Launches the MCP server application as a child process.\nThe Server: Runs as this child process.\nCommunication:\n\nThe client sends JSON-RPC messages (encoded as newline-delimited JSON strings) to the server process’s standard input (stdin).\nThe server sends its JSON-RPC messages (responses, notifications) to its standard output (stdout).\nThe client reads these messages from the server’s stdout.\nThe server’s standard error (stderr) is typically captured or redirected by the client for logging and debugging.\n\n\n\nThis creates a secure, local, and direct communication channel without requiring network ports or complex setup.\nC# SDK: Leveraging .NET Processes and Hosting\nThe C# SDK provides idiomatic implementations using standard .NET process and stream APIs, integrating well with the Microsoft.Extensions.Hosting model.\nKey Components:\n\n\nStdioClientTransport (src/.../Transport/StdioClientTransport.cs):\n\nResponsible for launching and managing the server process.\nTakes StdioClientTransportOptions (command, arguments, environment variables, working directory, shutdown timeout).\nUses System.Diagnostics.Process to start the server (Process.Start).\nConfigures ProcessStartInfo to redirect stdin, stdout, and stderr.\nInternally creates an StdioClientSessionTransport (which implements ITransport) to handle the actual stream communication once the process starts.\nCrucially uses ProcessHelper.KillTree (src/.../Utils/ProcessHelper.cs) upon disposal to ensure the server process and any child processes it spawned are terminated cleanly, especially important on Windows.\n\n\n\nStdioClientSessionTransport (Internal - src/.../Transport/StdioClientSessionTransport.cs):\n\nThe ITransport implementation used by the client after the process is started.\nInherits from StreamClientSessionTransport, using TextWriter (for stdin) and TextReader (for stdout) wrappers around the process streams.\nHandles the line-delimited JSON framing.\n\n\n\nStdioServerTransport (src/.../Transport/StdioServerTransport.cs):\n\nThe ITransport implementation used by a server launched via Stdio.\nAssumes it’s running as the child process.\nInherits from StreamServerTransport.\nWraps Console.OpenStandardInput() and Console.OpenStandardOutput() (using a special CancellableStdinStream for better cancellation handling).\nReads line-delimited JSON from stdin and writes it to stdout.\n\n\n\nIntegration (WithStdioServerTransport):\n\nThe IMcpServerBuilder.WithStdioServerTransport() extension method registers StdioServerTransport as the ITransport implementation in the DI container.\nIt also registers SingleSessionMcpServerHostedService, an IHostedService that retrieves the IMcpServer and ITransport from DI and runs the server’s message processing loop when the host starts. This service ensures the server exits when stdin closes.\n\n\n\nExample Flow (Client Starting Server):\n// C# Client launching a Stdio Server\nusing ModelContextProtocol.Client;\nusing ModelContextProtocol.Protocol.Transport;\n \nvar options = new StdioClientTransportOptions {\n    Command = &quot;dotnet&quot;, // Command to run the server\n    Arguments = [&quot;MyMcpServer.dll&quot;], // Arguments for the command\n    Name = &quot;MyLocalServer&quot;\n};\n \n// 1. Create the client transport - defines how to launch the server\nIClientTransport clientTransport = new StdioClientTransport(options);\n \n// 2. Create the client - this connects and initializes\n// McpClientFactory internally calls clientTransport.ConnectAsync(),\n// which starts the process and returns an ITransport (StdioClientSessionTransport)\nawait using IMcpClient client = await McpClientFactory.CreateAsync(clientTransport);\n \n// 3. Interact with the server\nvar tools = await client.ListToolsAsync();\nConsole.WriteLine($&quot;Server Tools: {string.Join(&quot;, &quot;, tools.Select(t =&gt; t.Name))}&quot;);\n \n// 4. Disposing the client will dispose the transport, which terminates the process\nJava SDK: ProcessBuilder and Explicit Session Management\nThe Java SDK uses standard java.lang.ProcessBuilder and relies on the server-side McpServerTransportProvider pattern.\nKey Components:\n\n\nStdioClientTransport (mcp/src/.../client/transport/StdioClientTransport.java):\n\nImplements McpClientTransport.\nTakes ServerParameters (command, args, env).\nUses java.lang.ProcessBuilder to configure and start the server process (processBuilder.start()).\nIts connect method returns a Mono&lt;Void&gt; and sets up internal threads/schedulers (inboundScheduler, outboundScheduler, errorScheduler) using Executors.newSingleThreadExecutor() and Reactor Schedulers.fromExecutorService.\nThese schedulers manage dedicated threads for reading stdout, writing to stdin, and reading stderr, handling the blocking nature of Java’s stream I/O.\nUses BufferedReader and direct OutputStream.write for message framing.\n\n\n\nStdioServerTransportProvider (mcp/src/.../server/transport/StdioServerTransportProvider.java):\n\nImplements McpServerTransportProvider.\nDesigned for servers launched via Stdio.\nReads from System.in and writes to System.out.\nCrucially, it’s designed for a single session. When setSessionFactory is called by the McpServer, it immediately creates one McpServerSession using an internal StdioMcpSessionTransport.\nIt doesn’t “accept” connections like network providers; it assumes the connection exists via the process’s standard streams.\n\n\n\nStdioMcpSessionTransport (Internal to Provider):\n\nThe McpServerTransport created by the provider.\nManages writing outgoing messages to System.out. Receiving is handled by the provider reading System.in and pushing messages into the session via the McpServerSession.handle method (which is a bit different from the ITransport.MessageReader channel model in C#).\n\n\n\nExample Flow (Client Starting Server):\n// Java Client launching a Stdio Server\nimport io.modelcontextprotocol.client.McpClient;\nimport io.modelcontextprotocol.client.McpSyncClient; // Using Sync for simplicity\nimport io.modelcontextprotocol.client.transport.ServerParameters;\nimport io.modelcontextprotocol.client.transport.StdioClientTransport;\nimport io.modelcontextprotocol.spec.McpClientTransport;\nimport io.modelcontextprotocol.spec.McpSchema.*;\n \n// 1. Define Server Parameters\nServerParameters serverParams = ServerParameters.builder(&quot;java&quot;)\n    .args(&quot;-jar&quot;, &quot;my-mcp-server.jar&quot;)\n    .build();\n \n// 2. Create the client transport\nMcpClientTransport transport = new StdioClientTransport(serverParams);\n \n// 3. Build the client\n// The connect() method is called internally by the builder/client constructor\nMcpSyncClient client = McpClient.sync(transport)\n    .requestTimeout(Duration.ofSeconds(10))\n    .build();\n \ntry {\n    // 4. Explicitly Initialize\n    client.initialize();\n    System.out.println(&quot;Connected!&quot;);\n \n    // 5. Interact\n    ListToolsResult tools = client.listTools();\n    System.out.println(&quot;Server Tools: &quot; + tools.tools().stream()\n            .map(Tool::name).collect(Collectors.joining(&quot;, &quot;)));\n \n} finally {\n    // 6. Close the client (which closes the transport and terminates the process)\n    client.closeGracefully();\n}\nComparison: Stdio Transports\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFeatureC# SDKJava SDKNotesProcess APISystem.Diagnostics.Processjava.lang.ProcessBuilder / ProcessStandard APIs for each platform.Async IO.NET Async Streams (TextReader/Writer)Manual Threads/Schedulers + Blocking IOC# leverages built-in async stream capabilities. Java uses Reactor/Schedulers for background IO.Server ModelStdioServerTransport (implements ITransport)StdioServerTransportProvider (creates Session)C# treats Stdio server as a standard transport. Java uses the Provider pattern for servers.Session HandlingSingle session via IHostedServiceSingle session created by ProviderBoth are fundamentally single-session on the server-side for Stdio.ShutdownProcessHelper.KillTree (robust)Process.destroy() / onExit() (standard)C# includes specific logic to kill the entire process tree.ConfigurationStdioClientTransportOptions (Client)ServerParameters (Client)Similar configuration options.\nEnd-User Nuance: Secure Local Power\nThe Stdio transport is the unsung hero enabling powerful, secure local AI integrations. Because it doesn’t involve network sockets, it’s inherently more secure for accessing local user data or executing local commands.\n\nFile Access: An AI assistant connected via Stdio to a server running in the context of an IDE or text editor can read the actual content of the user’s open file (exposed as a file:// Resource) without the file ever leaving the local machine.\nLocal Automation: A tool like “run current script” can be safely exposed via Stdio, allowing the AI to execute code locally as the user, respecting their permissions, without needing complex sandboxing or remote execution.\nSystem Information: Tools providing local system stats (CPU, memory, running processes) can be offered securely.\nOffline Functionality: Stdio-based tools work even when the user is offline.\nSimplified Deployment: For tools meant only for local use (like the Claude Desktop plugin model implicitly supported by the Python SDK’s CLI), Stdio avoids needing to package a web server or manage ports.\n\nConclusion\nThe Stdio transport is a cornerstone of MCP for local application integration in both the .NET and Java ecosystems. While the implementation details differ – C# leans on modern async streams and DI/Hosting, while Java uses ProcessBuilder with dedicated threads managed via Reactor Schedulers and a Transport Provider pattern – both SDKs provide robust mechanisms for launching and communicating with local MCP servers.\nThis transport enables a class of secure, powerful integrations that leverage local context and capabilities, bridging the gap between general-purpose AI models and the specific tasks users perform on their own machines.\nNext up, we’ll contrast the web-based communication strategies, focusing on Java’s HTTP+SSE approach and C#‘s integration with ASP.NET Core (likely using Streamable HTTP) in Blog 7: Web Transports.\n"},"2-Official-c-and-java-sdk-tutes/Blogs/blog-7":{"slug":"2-Official-c-and-java-sdk-tutes/Blogs/blog-7","filePath":"2 Official c# and java sdk tutes/Blogs/blog-7.md","title":"Blog 7: Web Transports - Java's HTTP+SSE vs. C#'s ASP.NET Core Integration","links":["2-Official-c-and-java-sdk-tutes/Blogs/blog-6"],"tags":[],"content":"Blog 7: Web Transports - Java’s HTTP+SSE vs. C#‘s ASP.NET Core Integration\nSeries: Deep Dive into the Model Context Protocol SDKs (C# &amp; Java)\r\nPost: 7 of 10\nHaving explored the secure local channel provided by the Stdio transport in our previous post, we now turn our attention to enabling Model Context Protocol (MCP) communication over the web using HTTP. This is essential for scenarios where the MCP client (e.g., a web application, a remote AI assistant) needs to interact with an MCP server hosted elsewhere, potentially across the internet or within a corporate network.\nBoth the C# and Java SDKs provide solutions for HTTP-based communication, but they exhibit significant differences in their primary approaches, reflecting both historical MCP specification versions and common framework patterns in their respective ecosystems.\nThis post examines:\n\nJava SDK’s HTTP+SSE Approach: Its reliance on the dual-endpoint Server-Sent Events model and implementations for Servlets, Spring WebFlux, and Spring WebMvc.\nC# SDK’s ASP.NET Core Integration: Its unified endpoint approach (MapMcp), likely implementing the newer Streamable HTTP specification, leveraging ASP.NET Core features.\nKey Differences: Single vs. Dual Endpoints, Session Management, Resumability, and Framework Integration.\n\nJava SDK: Embracing HTTP + Server-Sent Events (SSE)\nThe Java SDK’s primary mechanism for web communication adheres closely to the HTTP+SSE transport model described in earlier versions of the MCP specification (like 2024-11-05).\nThe Dual-Endpoint Model:\n\nSSE Endpoint (GET, e.g., /sse):\n\nThe client initiates a long-lived GET request here to establish the SSE connection.\nThe server keeps this connection open, sending text/event-stream data.\nThe first event sent by the server is the crucial event: endpoint, providing the URL (with a unique sessionId) for the client to send messages back to the server.\nSubsequent event: message events carry server-to-client JSON-RPC responses and notifications.\n\n\nMessage Endpoint (POST, e.g., /mcp/message?sessionId=...):\n\nThe client sends its JSON-RPC requests and notifications to this endpoint via standard HTTP POST requests.\nThe sessionId query parameter (obtained from the endpoint event) is essential for the server to route the incoming message to the correct client session (and its associated SSE connection).\nThe server typically responds with 202 Accepted immediately, sending the actual JSON-RPC response (if any) back asynchronously over the client’s specific SSE connection.\n\n\n\nImplementations:\nThe Java SDK provides several McpServerTransportProvider implementations catering to different Java web environments:\n\n\nHttpServletSseServerTransportProvider (mcp/ module):\n\nUses the standard Jakarta Servlet API (specifically async servlets).\nSuitable for traditional Servlet containers like Tomcat, Jetty, Undertow.\nManages SSE connections using jakarta.servlet.AsyncContext.\nRequires manual setup (e.g., registering the provider as a Servlet).\nSee HttpServletSseServerTransportProviderIntegrationTests.java for testing examples.\n\n\n\nWebFluxSseServerTransportProvider (mcp-spring-webflux/ module):\n\nBuilt for reactive Spring applications using WebFlux.\nUses org.springframework.web.reactive.function.server.RouterFunction to define the /sse (GET) and message (POST) routes.\nLeverages Project Reactor (Flux, Mono) and Spring’s reactive SSE support (ServerResponse.sse()).\nIntegrates naturally with Spring Boot WebFlux applications via @Bean configuration.\n\n// Spring WebFlux Configuration Example\n@Configuration\nstatic class MyConfig {\n    @Bean\n    public WebFluxSseServerTransportProvider sseTransportProvider() {\n        return new WebFluxSseServerTransportProvider(new ObjectMapper(), &quot;/mcp/message&quot;);\n    }\n \n    @Bean\n    public RouterFunction&lt;?&gt; mcpRouterFunction(WebFluxSseServerTransportProvider provider) {\n        return provider.getRouterFunction(); // Provides GET /sse and POST /mcp/message\n    }\n    // ... other beans ...\n}\n\n\nWebMvcSseServerTransportProvider (mcp-spring-webmvc/ module):\n\nAdapts the SSE model for traditional Spring MVC (Servlet-based) applications.\nAlso provides a RouterFunction (using Spring MVC’s functional endpoints introduced in Spring Framework 6) for easy integration.\nInternally likely uses Servlet async features similar to the HttpServlet provider but wrapped for Spring MVC.\n\n\n\nClient-Side (HttpClientSseClientTransport / WebFluxSseClientTransport):\n\nThe clients handle connecting to the /sse endpoint, receiving the endpoint event, storing the message URL + session ID, listening for message events, and sending outgoing messages via POST to the correct URL.\n\nKey Java SSE Aspects:\n\nAdherence to Older Spec: Follows the dual-endpoint HTTP+SSE model.\nFramework Flexibility: Provides implementations for standard Servlets, reactive Spring (WebFlux), and traditional Spring (WebMvc).\nSession Linking: Relies entirely on the sessionId query parameter in POST requests to correlate client messages with the correct server-side SSE stream.\nNo Built-in Resumability: The protocol itself doesn’t inherently support resuming a connection if the SSE stream drops.\n\nC# SDK: Unified Endpoint via ASP.NET Core Integration\nThe C# SDK takes a more modern approach, tightly integrating with ASP.NET Core and appearing to implement the newer Streamable HTTP transport specification (though it also includes handlers for legacy SSE compatibility).\nThe Unified Endpoint Model (MapMcp):\n\nSingle Pattern (e.g., /mcp, or user-defined): The McpEndpointRouteBuilderExtensions.MapMcp(pattern) method registers handlers for GET, POST, and DELETE verbs under a single route prefix.\nStreamableHttpHandler (src/ModelContextProtocol.AspNetCore/StreamableHttpHandler.cs): This internal class seems to be the primary handler for requests mapped by MapMcp. It likely manages:\n\nPOST Requests: Receiving client messages. It checks Accept headers (requiring both application/json and text/event-stream). It determines whether to respond with direct JSON or an SSE stream based on whether the incoming message(s) require responses. Handles session creation/validation using the mcp-session-id header.\nGET Requests: Handling requests for the optional standalone SSE stream for unsolicited server notifications. Requires Accept: text/event-stream. Manages only one GET stream per session. Includes logic for handling Last-Event-ID if resumability is configured.\nDELETE Requests: Handling explicit session termination requests from the client (validating mcp-session-id).\n\n\nSession Management (HttpMcpSession): An internal class likely used by StreamableHttpHandler to represent and track active sessions (mapping session IDs to transports, user principals, activity timestamps). Stored in a ConcurrentDictionary.\nTransport (StreamableHttpServerTransport): The underlying ITransport implementation used per-session, created by the StreamableHttpHandler when a new session starts via POST. It uses IDuplexPipe (likely from the HttpContext) for efficient request/response body streaming.\nResumability: While no explicit EventStore is visible in the AspNetCore project, the underlying StreamableHttpServerTransport in the core ModelContextProtocol project does support an EventStore. It’s plausible this could be configured via DI if needed, enabling resumability.\nIdle Session Tracking (IdleTrackingBackgroundService): An IHostedService periodically checks for inactive sessions (no active requests or GET stream) and disposes of them after a configurable timeout (HttpServerTransportOptions.IdleTimeout), preventing resource leaks.\nLegacy SSE Support (SseHandler): The MapMcp extension also maps /sse (GET) and /message (POST) routes handled by SseHandler.cs. This provides backwards compatibility for older clients expecting the dual-endpoint setup.\n\nExample (ASP.NET Core Program.cs):\n// C# ASP.NET Core Example\nusing ModelContextProtocol.Server; // For Tool/Prompt attributes\nusing Microsoft.AspNetCore.Builder; // For MapMcp\nusing Microsoft.Extensions.DependencyInjection; // For AddMcpServer/WithHttpTransport\n \nvar builder = WebApplication.CreateBuilder(args);\n \n// 1. Configure MCP Server services &amp; transport\nbuilder.Services.AddMcpServer(options =&gt; {\n        options.ServerInfo = new() { Name = &quot;MyAspNetCoreMcpServer&quot;, Version = &quot;1.0&quot; };\n    })\n    .WithHttpTransport(httpOptions =&gt; { // Configure HTTP transport options\n        httpOptions.IdleTimeout = TimeSpan.FromMinutes(30);\n        // httpOptions.ConfigureSessionOptions = async (httpCtx, mcpOpts, ct) =&gt; { ... };\n    })\n    .WithToolsFromAssembly(); // Discover tools via attributes\n \nvar app = builder.Build();\n \n// 2. Map MCP endpoints under the root (&quot;/&quot;) path\n// This registers handlers for GET/POST/DELETE on &quot;/&quot;\n// AND handlers for GET /sse and POST /message for compatibility\napp.MapMcp(&quot;/&quot;);\n \napp.Run(); // Start the web server\nKey C# Aspects:\n\nASP.NET Core Native: Deeply integrated with the standard web framework.\nUnified Endpoint: Primarily uses the Streamable HTTP model with a single route pattern.\nHeader-Based Session: Uses the Mcp-Session-Id header for stateful sessions.\nBuilt-in Compatibility: MapMcp includes handlers for the older SSE endpoints automatically.\nPotential Resumability: The underlying transport supports EventStore, although not explicitly configured in basic examples.\nRobust Lifecycle: Leverages IHostedService for tasks like idle session cleanup.\n\nComparison: Web Transports\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFeatureJava (HTTP+SSE Providers)C# (ASP.NET Core Integration)NotesPrimary SpecHTTP+SSE (Dual Endpoint)Streamable HTTP (Likely, Single Endpoint) + SSE CompatC# aligns with the newer, more efficient spec. Java focuses on the older, widely understood SSE model.EndpointsSeparate GET /sse, POST /messageSingle pattern (/mcp) handles GET/POST/DELETE + Legacy EndpointsC#‘s unified approach simplifies routing configuration.Session IdentificationsessionId Query Parameter (POST)Mcp-Session-Id HeaderHeader usage is generally preferred over query parameters for session IDs.Framework IntegrationSpecific Providers (Servlet, WebFlux, WebMvc)Unified via MapMcp in ASP.NET CoreC# offers a single integration point. Java requires choosing the provider matching the web framework.ResumabilityNo (Inherent in HTTP+SSE spec used)Yes (Potential via EventStore config)C#‘s underlying transport supports it, giving it an edge for reliability. Java’s SSE providers would need significant custom work.ConfigurationVia McpServer.async/sync buildersVia AddMcpServer().WithHttpTransport() DI extensionsBoth offer configuration, but C# ties into the standard DI/Options patterns.Server ImplementationSseServerTransportProvider subclassesStreamableHttpHandler / SseHandlerInternal implementation details differ significantly based on the chosen spec and framework.\nEnd-User Impact: Reliability and Integration\nThe choice of web transport impacts the user experience, particularly for non-local interactions:\n\nStreamable HTTP (C#):\n\nPotentially More Efficient: Fewer connections needed compared to classic SSE + POST.\nMore Resilient: Built-in resumability means long-running operations (like complex tool calls with progress) are less likely to fail completely due to temporary network drops, providing a smoother UX.\nModern Standard: Aligns with newer web practices.\n\n\nHTTP+SSE (Java):\n\nWidely Understood: SSE is a mature technology.\nFramework Support: Good integration options across various Java web frameworks (Servlet, Spring).\nLess Resilient (by default): A dropped SSE connection usually means the client loses subsequent server messages until it reconnects, potentially missing progress updates or final results of long tasks without custom client/server logic.\n\n\n\nConclusion\nWhen taking MCP servers to the web, the C# and Java SDKs present different primary strategies. Java offers robust implementations of the classic HTTP+SSE transport, providing flexibility across Servlet, WebFlux, and WebMvc environments. C#, through its ModelContextProtocol.AspNetCore package, provides tight integration with ASP.NET Core, likely implementing the more modern and resilient Streamable HTTP protocol while thoughtfully including handlers for backwards compatibility with older SSE clients.\nThe C# approach, with its potential for built-in resumability and unified endpoint handling, appears more aligned with the latest MCP specification for web transports. However, Java’s explicit support for various established web frameworks ensures broad applicability within the JVM ecosystem using the well-understood SSE model. Developers choosing between them should consider their target framework, the need for resumability, and their preference for framework integration style.\nOur next post shifts focus back to security, examining Blog 8: Authentication approaches in the C# and Java SDKs.\n"},"2-Official-c-and-java-sdk-tutes/Blogs/blog-8":{"slug":"2-Official-c-and-java-sdk-tutes/Blogs/blog-8","filePath":"2 Official c# and java sdk tutes/Blogs/blog-8.md","title":"Blog 8: Framework Integration - ASP.NET Core (C#) vs. Spring/Servlets (Java)","links":["2-Official-c-and-java-sdk-tutes/Blogs/blog-7"],"tags":[],"content":"Blog 8: Framework Integration - ASP.NET Core (C#) vs. Spring/Servlets (Java)\nSeries: Deep Dive into the Model Context Protocol SDKs (C# &amp; Java)\r\nPost: 8 of 10\nThroughout this series comparing the C# and Java Model Context Protocol (MCP) SDKs, we’ve seen how foundational choices in language and libraries shape the developer experience. Nowhere is this more apparent than in how the SDKs integrate with the dominant web application frameworks in their respective ecosystems: ASP.NET Core for C#/.NET and Spring (WebFlux/WebMvc) / Jakarta Servlets for Java.\nWhile Blog 7 focused on the specifics of the HTTP transports (Streamable HTTP vs. HTTP+SSE), this post examines how developers wire the MCP server logic into these frameworks. We’ll explore:\n\nC# SDK: Seamless integration using Microsoft.Extensions.DependencyInjection, IHostedService, and ASP.NET Core routing extensions (MapMcp).\nJava SDK: Dedicated modules for Spring WebFlux and WebMvc, plus a provider for standard Jakarta Servlets, leveraging framework-specific patterns.\nHow these integrations impact configuration, service lifecycles, request handling, and dependency injection.\n\nC# SDK: Native ASP.NET Core / Generic Host Integration\nThe C# SDK is designed from the ground up to feel like a natural extension of the modern .NET application hosting model. Integration is typically achieved in Program.cs (or Startup.cs in older styles).\nKey Integration Points:\n\n\nDependency Injection (IServiceCollection):\n\nAddMcpServer(): This is the starting point. It registers core services needed by the MCP server (like McpServerOptions, internal handlers, potentially the McpServer itself) into the standard .NET DI container.\nIMcpServerBuilder Extensions: Methods like WithTools&lt;T&gt;(), WithPromptsFromAssembly(), WithListResourcesHandler(...) primarily work by configuring McpServerOptions or registering specific handler implementations or McpServerTool/McpServerPrompt instances within the DI container.\nTool/Prompt Dependencies: Because tools and prompts are often resolved from the DI container (especially when using attribute discovery or WithTools&lt;T&gt;), they can directly request other registered application services (like DbContext, HttpClient, custom business logic services) via constructor injection.\n\n\n\nHosting (IHostedService):\n\nWithStdioServerTransport(): Registers the StdioServerTransport and the SingleSessionMcpServerHostedService. When the .NET host starts (app.RunAsync()), this hosted service automatically retrieves the IMcpServer and ITransport from DI and starts the server’s message processing loop (server.RunAsync()). It handles graceful shutdown linked to the host lifetime.\nWithHttpTransport(): Registers services needed by the ASP.NET Core integration (StreamableHttpHandler, SseHandler, IdleTrackingBackgroundService). It does not register a service to automatically call IMcpServer.RunAsync(), as the request handling is driven by incoming HTTP requests mapped via MapMcp. The IdleTrackingBackgroundService runs alongside the web host to clean up inactive sessions.\n\n\n\nRouting (ASP.NET Core - IEndpointRouteBuilder):\n\nMapMcp(pattern): This extension method (from ModelContextProtocol.AspNetCore) is the key piece for web hosting. It registers the necessary endpoints within the ASP.NET Core routing system.\nInternally, it maps the specified route pattern (e.g., /mcp) to the internal StreamableHttpHandler for GET, POST, and DELETE methods.\nIt also maps the legacy /sse (GET) and /message (POST) routes to the SseHandler for backwards compatibility.\nIt leverages ASP.NET Core’s built-in features like request/response streaming, header handling, and potentially authentication/authorization middleware applied to the mapped routes.\n\n\n\nExample (Program.cs Snippet):\n// C# ASP.NET Core Integration\nvar builder = WebApplication.CreateBuilder(args);\n \n// Configure standard ASP.NET Core services (logging, config, etc.)\nbuilder.Services.AddHttpClient(); // Example dependency\n \n// Configure MCP Server via DI\nbuilder.Services.AddMcpServer(options =&gt; {\n    options.ServerInfo = new() { Name = &quot;MyWebAppServer&quot;, Version = &quot;1.0&quot; };\n})\n    .WithHttpTransport(httpOptions =&gt; { // Configures ASP.NET Core handlers\n        httpOptions.IdleTimeout = TimeSpan.FromMinutes(30);\n    })\n    .WithTools&lt;MyWebServiceTools&gt;(); // Register tools (can use DI)\n \nvar app = builder.Build();\n \n// Add standard ASP.NET Core middleware (auth, CORS, etc.)\n// app.UseAuthentication();\n// app.UseAuthorization();\n \n// Map MCP endpoints (e.g., to &quot;/mcp&quot;)\napp.MapMcp(&quot;/mcp&quot;);\n \n// Run the web application host\napp.Run();\n \n// Tool class potentially using DI\n[McpServerToolType]\npublic class MyWebServiceTools(HttpClient httpClient, ILogger&lt;MyWebServiceTools&gt; logger)\n{\n    [McpServerTool]\n    public async Task&lt;string&gt; FetchData(string url)\n    {\n        logger.LogInformation(&quot;Fetching data from {Url}&quot;, url);\n        return await httpClient.GetStringAsync(url);\n    }\n}\nSummary (C#): Integration is seamless and idiomatic for .NET developers, leveraging standard DI, Hosting, and ASP.NET Core patterns. Configuration is centralized through IServiceCollection extensions.\nJava SDK: Adapters for Spring and Servlets\nThe Java SDK provides specific adapter modules to bridge MCP communication with common Java web frameworks, primarily focusing on the HTTP+SSE transport model.\nKey Integration Points:\n\n\nTransport Providers: Instead of direct hosting integration, the Java SDK uses the McpServerTransportProvider pattern. You choose the provider that matches your web framework.\n\n\nWebFluxSseServerTransportProvider (mcp-spring-webflux/):\n\nTarget: Reactive Spring applications using WebFlux.\nMechanism: Provides a getRouterFunction() method. This returns a Spring WebFlux RouterFunction that defines the GET /sse and POST /message routes.\nIntegration: You register this RouterFunction as a @Bean in your Spring configuration. WebFlux handles the incoming HTTP requests and routes them to the provider’s internal handlers.\nInternals: Uses ServerResponse.sse() to create the SSE stream and handles POST bodies using WebFlux request handling (request.bodyToMono(String.class)).\n\n// Java Spring WebFlux Configuration\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.context.annotation.Configuration;\nimport org.springframework.web.reactive.function.server.RouterFunction;\nimport org.springframework.web.reactive.function.server.ServerResponse;\nimport io.modelcontextprotocol.server.transport.WebFluxSseServerTransportProvider;\n// ... other imports\n \n@Configuration\npublic class McpConfig {\n \n    @Bean\n    public WebFluxSseServerTransportProvider mcpTransportProvider(ObjectMapper objectMapper) {\n        // Assumes ObjectMapper bean exists\n        return new WebFluxSseServerTransportProvider(objectMapper, &quot;/mcp/message&quot;);\n    }\n \n    @Bean\n    public RouterFunction&lt;ServerResponse&gt; mcpRoutes(WebFluxSseServerTransportProvider provider) {\n        // Integrates MCP routes into the WebFlux routing system\n        return provider.getRouterFunction();\n    }\n \n    @Bean\n    public McpAsyncServer mcpServer(WebFluxSseServerTransportProvider provider /*, other dependencies */) {\n        McpAsyncServer server = McpServer.async(provider)\n            .serverInfo(&quot;MyWebFluxServer&quot;, &quot;1.0&quot;)\n            // .tools(...) - Tools might need manual wiring or Spring component scanning\n            // .resources(...)\n            // .prompts(...)\n            .build();\n        // The server logic is configured, but WebFlux handles the HTTP requests\n        return server;\n    }\n}\n\n\nWebMvcSseServerTransportProvider (mcp-spring-webmvc/):\n\nTarget: Traditional Spring applications using Spring MVC (Servlet-based).\nMechanism: Also provides getRouterFunction() using Spring MVC’s functional routing support (available since Spring Framework 6). This defines the same /sse and /message routes but uses Servlet API primitives underneath (likely async servlets for SSE).\nIntegration: Register the RouterFunction as a @Bean. Spring MVC’s DispatcherServlet routes requests appropriately.\n\n\n\nHttpServletSseServerTransportProvider (mcp/ core module):\n\nTarget: Generic Jakarta Servlet containers (Tomcat, Jetty, etc.) without Spring MVC.\nMechanism: Implements the jakarta.servlet.http.HttpServlet.\nIntegration: You must manually register this class as a Servlet in your web.xml or using Servlet container-specific configuration, mapping it to the desired URL patterns (one for /sse, one for /message). It uses request.startAsync() for handling SSE connections.\n\n\n\nDependency Injection (Java):\n\nThe core Java SDK builder doesn’t have direct integration with a DI framework like Spring (unlike C#‘s builder).\nWhen using the Spring modules (mcp-spring-*), you typically register your Tool/Resource/Prompt handler implementations as Spring @Components or @Services.\nYou would then manually create the Async/SyncToolSpecification (etc.) objects, likely within a Spring @Configuration class, retrieving the handler bean instances from the Spring context and passing them to the specification constructor before adding them to the McpServer builder.\n\n// Conceptual Java Spring DI for Handlers\n@Service\npublic class MyToolHandler { // Your actual tool logic bean\n    private final MyDependency dep;\n    public MyToolHandler(MyDependency dep) { this.dep = dep; }\n \n    public CallToolResult handleEcho(McpSyncServerExchange exchange, Map&lt;String, Object&gt; args) {\n        // use this.dep\n        return new CallToolResult(List.of(new TextContent(&quot;Echo &quot; + args.get(&quot;msg&quot;))), false);\n    }\n}\n \n@Configuration\npublic class McpServerConfiguration {\n    @Bean\n    public McpSyncServer mcpServer(\n        McpServerTransportProvider transportProvider,\n        MyToolHandler myToolHandler // Inject the handler bean\n    ) {\n        Tool echoToolMeta = new Tool(&quot;echo&quot;, &quot;...&quot;, &quot;{}&quot;);\n        // Manually create spec, passing the handler bean&#039;s method reference\n        SyncToolSpecification echoSpec = new SyncToolSpecification(\n            echoToolMeta,\n            myToolHandler::handleEcho // Use method reference from injected bean\n        );\n \n        return McpServer.sync(transportProvider)\n            // ... other config ...\n            .tools(echoSpec)\n            .build();\n    }\n    // ... other beans (TransportProvider, MyDependency) ...\n}\nComparison: Framework Integration\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFeatureC# (ASP.NET Core)Java (Spring/Servlet)NotesPrimary MechanismDI Extensions + Middleware (MapMcp)Transport Providers + Framework AdaptersC# feels more “built-in” to the host; Java uses adapter providers for specific frameworks.Web Transport SetupSingle .WithHttpTransport().MapMcp()Choose Provider + Register Routes/ServletC# setup is simpler for web. Java requires selecting the correct provider for WebFlux/WebMvc/Servlet.Handler DINative via DI container (constructor/method)Manual wiring in @Configuration commonC# leverages DI more directly for injecting dependencies into handlers/tools.Lifecycle ManagementIHostedService integrationDepends on Provider/Framework (e.g., Servlet destroy, Spring context close)Both integrate with standard platform lifecycles.FlexibilityTied to ASP.NET Core / Generic HostAdapters for Servlet, WebFlux, WebMvcJava offers more explicit choices for different Java web stacks via separate providers.HTTP Spec ComplianceLikely Streamable HTTP + SSE CompatHTTP+SSEC# likely follows the newer spec via its unified handler.\nConclusion: Idiomatic Integration is Key\nBoth SDKs achieve successful integration with their platform’s dominant web frameworks, but through different means.\n\nC# offers a highly streamlined experience for developers already using ASP.NET Core or the Generic Host. AddMcpServer, the builder extensions, and MapMcp provide a cohesive way to configure and launch an MCP server, leveraging familiar DI and hosting patterns. The likely implementation of Streamable HTTP provides modern transport benefits.\nJava provides targeted solutions for the diverse Java web landscape with dedicated modules for Spring WebFlux, Spring WebMvc, and standard Servlets. While requiring the developer to choose the correct provider and perform more manual wiring (especially for DI into handlers), it offers clear integration paths for each major environment, primarily using the well-established HTTP+SSE transport model.\n\nThe choice again reflects the ecosystems: .NET’s more unified hosting and DI model lends itself to the extension method approach, while Java’s diverse framework landscape benefits from specific adapter modules built upon a core provider pattern. Both successfully enable developers to embed MCP server functionality within their existing web applications.\nWith client/server architecture and transports covered, the final posts will tackle Advanced Capabilities (Blog 9) and provide a Synthesis and Future Outlook (Blog 10)."},"2-Official-c-and-java-sdk-tutes/Blogs/blog-9":{"slug":"2-Official-c-and-java-sdk-tutes/Blogs/blog-9","filePath":"2 Official c# and java sdk tutes/Blogs/blog-9.md","title":"Blog 9: Advanced Capabilities & Ecosystem Fit - C# vs. Java MCP SDKs","links":["2-Official-c-and-java-sdk-tutes/Blogs/blog-2","2-Official-c-and-java-sdk-tutes/Blogs/blog-3","2-Official-c-and-java-sdk-tutes/Blogs/blog-4","2-Official-c-and-java-sdk-tutes/Blogs/blog-5","2-Official-c-and-java-sdk-tutes/Blogs/blog-6","2-Official-c-and-java-sdk-tutes/Blogs/blog-7","2-Official-c-and-java-sdk-tutes/Blogs/blog-8"],"tags":[],"content":"Blog 9: Advanced Capabilities &amp; Ecosystem Fit - C# vs. Java MCP SDKs\nSeries: Deep Dive into the Model Context Protocol SDKs (C# &amp; Java)\r\nPost: 9 of 10\nWe’ve journeyed through the core architecture, APIs, and transport layers of the C# and Java Model Context Protocol (MCP) SDKs. We’ve seen how they define schemas, configure servers, handle protocol internals, enable clients, and integrate with local and web/framework transports.\nNow, let’s explore some of the more advanced features, subtle capabilities, and how each SDK fits within its broader ecosystem. These aspects often highlight deeper design decisions and cater to specific, sophisticated use cases. We’ll examine:\n\nSync vs. Async APIs (Java): The implications of Java’s explicit dual API.\nDependency Injection Integration (C#): How deeply DI is woven into the C# SDK.\nEcosystem Integration: Leveraging platform strengths (Microsoft.Extensions.AI, Spring).\nExtensibility: How easy is it to add custom components?\nTesting Support: Utilities provided for writing reliable tests.\nMissing Features (vs. TS/Python): What’s not (yet) present in the C#/Java SDKs?\n\nJava’s Dual API: Sync vs. Async (McpSync*/McpAsync*)\nA standout feature of the Java SDK is its explicit provision of both synchronous (McpSyncClient, McpSyncServer) and asynchronous (McpAsyncClient, McpAsyncServer) APIs.\n\nMcpAsync*: Built on Project Reactor (Mono, Flux), designed for non-blocking I/O and integration with reactive frameworks like Spring WebFlux. Operations return Mono or Flux publishers. Handler functions (e.g., for tools) are typically BiFunction&lt;McpAsyncServerExchange, ..., Mono&lt;Result&gt;&gt;.\nMcpSync*: Provides a traditional, blocking API. It internally wraps and delegates to an McpAsync* instance, using .block() calls (often with a timeout specified during client/server build) to wait for results. Handler functions are simpler BiFunction&lt;McpSyncServerExchange, ..., Result&gt;.\n\nWhy offer both?\n\nDeveloper Ergonomics: Caters to different programming paradigms common in the Java world. Developers comfortable with blocking I/O can use the Sync API without needing deep reactive knowledge. Teams using WebFlux or other reactive systems can leverage the native Async API.\nIntegration: Allows MCP to fit into both traditional, thread-per-request applications (using Sync) and modern reactive applications (using Async).\nBridging: The Sync client/server acts as a bridge, allowing synchronous code to interact with the fundamentally asynchronous nature of network I/O managed by the underlying Async components and Reactor schedulers.\n\nTrade-offs:\n\nSync: Simpler to write and debug for developers unfamiliar with reactive streams. However, can lead to thread blocking and reduced scalability under high concurrency if not carefully managed (e.g., ensuring blocking calls happen on appropriate thread pools, which the SDK attempts via Schedulers.boundedElastic() in its sync→async adapters).\nAsync: More scalable and resource-efficient for I/O-bound tasks and high concurrency. Requires understanding reactive concepts (Mono, Flux, operators, backpressure).\n\nC# Approach: C# uses the standard async/await pattern built on Task/ValueTask throughout. There isn’t an explicit separate “Sync” API. Blocking calls within async methods are discouraged, and developers are expected to use async/await consistently.\nC#‘s Deep Dependency Injection Integration\nThe C# SDK is designed assuming a modern .NET application structure heavily reliant on Microsoft.Extensions.DependencyInjection.\n\nConfiguration: Server setup is DI configuration via IMcpServerBuilder extensions (AddMcpServer, WithTools&lt;T&gt;, etc.).\nTool/Prompt/Handler Resolution: Implementations of tools, prompts, or even custom low-level handlers are often registered as services themselves (e.g., services.AddScoped&lt;MyToolLogic&gt;()).\nParameter Injection: The SDK’s mechanism for creating McpServerTool and McpServerPrompt instances (especially via AIFunctionFactory) automatically attempts to resolve method parameters from the IServiceProvider associated with the request (or the root provider for static methods). This allows handlers to directly request dependencies (HttpClient, DbContext, application services) via constructor or method parameters.\n[McpServerToolType]\npublic class DatabaseTool(MyDbContext dbContext) // Constructor Injection\n{\n    [McpServerTool]\n    public async Task&lt;string&gt; QueryData(string filter, ILogger&lt;DatabaseTool&gt; logger) // Method Injection\n    {\n        logger.LogInformation(&quot;Querying data with filter: {Filter}&quot;, filter);\n        // Use dbContext injected via constructor\n        var result = await dbContext.Items.FirstOrDefaultAsync(i =&gt; i.Name == filter);\n        return result?.Value ?? &quot;Not found&quot;;\n    }\n}\n\nScoped Requests: The McpServerOptions.ScopeRequests option (defaulting to true) ensures that each incoming MCP request is processed within its own DI scope when using DI-resolved handlers. This is crucial for managing the lifetime of services like DbContext.\n\nJava Approach: While Java has DI frameworks (Spring being the most prominent), the core McpServer builder in the Java SDK doesn’t directly integrate DI for resolving handler parameters in the same automatic way C# does. As shown in Blog 8, developers using Spring typically inject their handler class instances into a @Configuration class and then manually pass method references (myToolHandler::handle) when creating the ToolSpecification. The McpAsync/SyncServerExchange objects provide access to client/session info but not directly to an application-wide DI container (unless manually plumbed through).\nComparison: C#‘s SDK offers tighter, more automatic integration with the platform’s standard DI system, simplifying dependency management within MCP primitives. Java requires more manual wiring when using DI with the core SDK, although Spring Boot starters likely provide more convention-based integration.\nEcosystem Integration: Leveraging Platform Strengths\n\nC# &amp; Microsoft.Extensions.AI: The McpClientTool class directly inherits from Microsoft.Extensions.AI.AIFunction. This is a significant advantage, allowing tools discovered from an MCP server to be seamlessly passed into the ChatOptions.Tools collection of an IChatClient (like OpenAIClient). The AI client can then automatically handle invoking the MCP tool via the SDK when the LLM requests it. The server-side McpServerTool.Create methods also leverage AIFunctionFactory internally.\nJava &amp; Spring: The dedicated mcp-spring-webflux and mcp-spring-webmvc modules provide first-class integration. They offer *TransportProvider beans and RouterFunction beans that plug directly into Spring Boot application configuration, handling the complexities of adapting MCP’s SSE model to reactive or traditional Spring web stacks.\nJava &amp; Servlets: The HttpServletSseServerTransportProvider allows deploying MCP servers in standard Jakarta Servlet containers (Tomcat, Jetty, etc.) outside of Spring.\n\nExtensibility\nBoth SDKs offer extensibility points:\n\nCustom Transports: Implement ITransport (C#) or McpClientTransport/McpServerTransport/McpServerTransportProvider (Java) to support communication channels beyond Stdio/SSE (e.g., WebSockets, gRPC, custom protocols).\nCustom Handlers: Use the low-level server APIs (Server.SetRequestHandler in C#, @server.call_tool decorators in Java low-level server) to handle non-standard MCP methods or override default behavior.\nCustom Primitives (Server): While not a direct extension point in the core server logic, you can create custom logic within tool/resource/prompt handlers to interact with any backend system.\n\nTesting Support\n\nC#: Provides ModelContextProtocol.Tests.Utils (like TestServerTransport, LoggedTest), and the ModelContextProtocol.AspNetCore.Tests.Utils (KestrelInMemoryTransport) for in-memory integration testing of ASP.NET Core applications. Standard .NET testing tools (xUnit, Moq) are used.\nJava: Provides the mcp-test module containing MockMcpTransport and abstract base classes (AbstractMcp*ClientTests, AbstractMcp*ServerTests) to facilitate writing tests against different transport implementations consistently. Uses JUnit 5, Mockito, Reactor-Test, AssertJ, and Testcontainers.\n\nBoth SDKs demonstrate a strong commitment to testability.\nMissing Features (vs. TS/Python)\nCompared to the TypeScript and (to some extent) Python SDKs, the C# and Java SDKs currently appear to lack built-in, high-level support for:\n\nOAuth Server Framework: Neither SDK provides a comprehensive, out-of-the-box OAuth 2.1 server implementation like TypeScript’s mcpAuthRouter. Authentication relies on integrating with platform-standard security frameworks (ASP.NET Core Identity/JWT/OAuth middleware, Spring Security).\nDynamic Capability Management Handles: No direct equivalent to the TS SDK’s RegisteredTool/Resource/Prompt handles with .enable(), .disable(), .update(), .remove() methods for easy post-connection modification and automatic notification. Dynamic changes would likely require manual notification sending.\nArgument Autocompletion: No equivalent to TypeScript’s Completable Zod wrapper for easily adding completion logic to prompt/resource arguments and handling completion/complete requests automatically.\nAdvanced CLI: Lack a dedicated developer CLI like Python’s mcp command for simplified development workflows or specific integrations (like Claude Desktop mcp install). Development relies on standard dotnet run or mvn exec/IDE execution.\nStreamable HTTP Resumability (Java): As Java focuses on HTTP+SSE, it lacks the built-in resumability offered by the Streamable HTTP transport + EventStore pattern found in the C# (potentially) and TS SDKs.\n\nConclusion: Platform-Native Powerhouses\nThe C# and Java MCP SDKs successfully bring the Model Context Protocol to two of the most dominant enterprise development platforms. They achieve this by deeply integrating with the idioms, frameworks, and tooling specific to each ecosystem.\n\nC# offers a modern .NET experience, tightly coupled with Dependency Injection, Hosting, ASP.NET Core, System.Text.Json source generation, and potentially the newer Streamable HTTP transport. Its integration with Microsoft.Extensions.AI is a notable plus.\nJava provides flexibility with its distinct Sync and Async APIs, catering to different programming styles. Its strength lies in the specific, robust integrations provided for the Spring ecosystem (WebFlux/WebMvc) and standard Servlets, primarily using the well-established HTTP+SSE transport model.\n\nWhile they might currently lack some of the advanced features found in the TypeScript SDK (like built-in OAuth server or dynamic handles), they provide solid, performant, and testable foundations. Developers choosing C# or Java can confidently leverage these SDKs to build sophisticated, context-aware AI integrations within their existing enterprise applications, using patterns and tools they are already familiar with.\nThis concludes our deep dive into the specifics of the SDKs. Thank you for joining us on this exploration!\n"},"2-Official-c-and-java-sdk-tutes/README":{"slug":"2-Official-c-and-java-sdk-tutes/README","filePath":"2 Official c# and java sdk tutes/README.md","title":"README","links":[],"tags":[],"content":"\nOfficial c# and java sdk tutes\n"},"2-Official-c-and-java-sdk-tutes/index":{"slug":"2-Official-c-and-java-sdk-tutes/index","filePath":"2 Official c# and java sdk tutes/index.md","title":"2 Official c# and java sdk tutes","links":[],"tags":[],"content":""},"3-Official-mcp-spec-tutes/069_model":{"slug":"3-Official-mcp-spec-tutes/069_model","filePath":"3 Official mcp spec tutes/069_model.md","title":"069_model","links":[],"tags":[],"content":"Okay, let’s analyze the modelcontextprotocol-modelcontextprotocol repository based on the provided file structure and content.\nRepository Purpose:\nThis repository serves as the canonical source of truth for the Model Context Protocol (MCP) specification and its official documentation. It does not contain an SDK implementation itself, but rather defines the rules, message formats, and concepts that the SDKs (TypeScript, Python, C#, Java) implement. It’s the central reference point for understanding the protocol.\nKey Components:\n\n\nSpecification Definition (schema/):\n\nSource of Truth: The protocol is formally defined using TypeScript interfaces and types within versioned directories (e.g., schema/2025-03-26/schema.ts, schema/draft/schema.ts). This leverages TypeScript’s strong typing system for defining the precise structure of requests, responses, notifications, and data types used in MCP.\nJSON Schema Generation: A corresponding JSON Schema (schema/{version}/schema.json) is automatically generated from the TypeScript source using the typescript-json-schema tool (configured in package.json). This provides a language-agnostic definition suitable for validation tools and code generation in other languages.\nVersioning: The schema directory structure clearly enforces the date-based versioning scheme (YYYY-MM-DD) outlined in the documentation, with separate definitions for released versions and the current draft.\n\n\n\nDocumentation (docs/):\n\nSource Files: Contains the source content for the official MCP documentation website (modelcontextprotocol.io).\nFormat: Uses .mdx files, indicating a framework like Mintlify (confirmed by docs.json and package.json) that allows embedding interactive components (like &lt;Tabs&gt;, &lt;CardGroup&gt;) within Markdown.\nStructure: Well-organized into sections covering:\n\nIntroduction &amp; Quickstarts\nCore Concepts (Architecture, Resources, Tools, Prompts, etc.)\nDetailed Specification (Versioned: 2024-11-05, 2025-03-26, draft) including Basic Protocol, Client/Server Features, Utilities (Ping, Progress, Logging, etc.), Authorization, and Transports.\nTutorials &amp; Tooling (Inspector, Debugging).\nLists of known Clients and Example Servers.\nDevelopment info (Contributing, Roadmap, Updates).\nSDK-Specific Docs: Notably includes dedicated sections for the Java SDK, suggesting this repository acts as the central documentation hub, not just for the spec itself but also linking to or hosting SDK guides.\n\n\nConfiguration: docs/docs.json defines the Mintlify site structure, navigation, theme, logo, SEO settings, and redirects.\n\n\n\nTooling (package.json, tsconfig.json, .github/workflows/):\n\nNode.js/npm: The repository is managed as a Node.js project, primarily for documentation generation and schema validation tooling.\nTypeScript: Used for defining the authoritative schema (schema.ts) and validating it (tsc via npm run validate:schema). tsconfig.json confirms noEmit: true, as the TS here is for definition, not execution.\nSchema Generation: npm run generate:json uses typescript-json-schema to create the .json schemas.\nDocumentation: npm run serve:docs uses mintlify dev to serve the documentation locally.\nFormatting: prettier is used to format Markdown files (npm run format).\nCI/CD: GitHub Actions (.github/workflows/):\n\nmain.yml: Validates the TS schema (tsc) and ensures the generated JSON schemas are up-to-date (git diff --exit-code) on pushes/PRs.\nmarkdown-format.yml: Checks markdown formatting using Prettier.\n(Workflows for publishing SDK packages are absent, as expected).\n\n\n\n\n\nGovernance Files: Standard LICENSE (MIT), CODE_OF_CONDUCT.md, CONTRIBUTING.md, and SECURITY.md files are present.\n\n\nKey Takeaways &amp; Observations:\n\nSpecification Authority: This repository is the definitive source for the MCP standard. Changes here dictate how SDKs should behave.\nSchema-First (TS): Uses TypeScript as the primary language for defining the protocol schema, benefiting from static typing, interfaces, and enums.\nLanguage Agnostic Output: Provides a generated JSON Schema for use by implementers in any language.\nVersioning Strategy: Employs clear, date-based versioning for the specification, allowing clients and servers to negotiate compatible versions. Tracks changes via changelog.mdx.\nCentral Documentation Hub: Hosts the source for the main modelcontextprotocol.io website, covering the protocol itself and linking to/including SDK-specific information.\nMintlify for Docs: Leverages a modern documentation framework for a rich user experience.\nAutomated Checks: CI enforces schema validity, up-to-date generated schemas, and markdown formatting.\nNot an SDK: Contains no runnable client/server code itself, only the definitions and documentation.\n\nConclusion:\nThe modelcontextprotocol-modelcontextprotocol repository serves a critical and distinct role in the MCP ecosystem. It is the foundation – defining the “language” (schema) and providing the “manual” (documentation) for the Model Context Protocol. Its use of TypeScript for schema definition provides precision, while the generated JSON Schema ensures broad applicability. The versioned structure allows the protocol to evolve systematically. Its integration with Mintlify provides comprehensive and user-friendly documentation, acting as the central knowledge base for developers building or using MCP clients, servers, and SDKs. It’s well-organized and employs appropriate tooling to maintain the integrity and accessibility of the specification."},"3-Official-mcp-spec-tutes/071_model":{"slug":"3-Official-mcp-spec-tutes/071_model","filePath":"3 Official mcp spec tutes/071_model.md","title":"071_model","links":[],"tags":[],"content":"Okay, here is a plan for a 10-part blog series focusing on the MCP specification repository (modelcontextprotocol-modelcontextprotocol), using the SDKs (TypeScript, Python, C#, Java) as concrete examples of how the specification is implemented and interpreted. This series targets advanced users and research coders interested in the “why” and “how” behind the protocol and its cross-language manifestations.\nTarget Audience: Protocol designers, SDK developers, advanced users building complex MCP integrations, researchers evaluating MCP for specific use cases, developers interested in cross-language API design.\nOverall Goal: To provide a deep, analytical understanding of the MCP specification by examining its structure, core definitions, and evolution, while simultaneously analyzing and comparing how these abstract concepts are translated into practical, idiomatic implementations across the official TypeScript, Python, C#, and Java SDKs. The series will explore design trade-offs, implementation nuances, and the implications for developers and researchers using these tools.\n\nBlog Series: Deconstructing the Model Context Protocol - Spec &amp; Implementation Deep Dive\nBlog 1: The Blueprint - Anatomy of the MCP Specification Repository\n\nCore Focus: Introduction to the specification repository itself as the source of truth.\nKey Spec Areas: README.md, directory structure (schema/, docs/), versioning strategy (docs/specification/versioning.mdx), contribution process (CONTRIBUTING.md).\nImplementation Insights: Briefly introduce the four main SDKs as consumers of this spec. How does a versioned spec repository facilitate multi-language SDK development? Discuss the choice of TypeScript as the schema’s source language and the generation of JSON Schema.\nCross-SDK Comparison: High-level view of the build/tooling used by the spec repo (Node.js/npm/tsc) vs. the SDKs’ native tooling.\nNuanced Take: Why a formal specification matters beyond just documentation – ensuring interoperability, providing a basis for compliance testing, guiding SDK design. The challenges of maintaining consistency across SDKs based on a central spec.\n\nBlog 2: The Core Language - JSON-RPC Framing and MCP Base Types\n\nCore Focus: Dissecting the foundational message structures derived from JSON-RPC 2.0.\nKey Spec Areas: docs/specification/{version}/basic/index.mdx, docs/specification/{version}/basic/messages.mdx. The base interfaces/types in schema/{version}/schema.ts (JSONRPCMessage, Request, Response, Notification, Error, Id, Result, Params). Explicit rejection of JSON-RPC Batching in draft.\nImplementation Insights:\n\nTS: Base Request, Notification, Result interfaces; JSONRPC* schemas; McpError class. Zod’s role.\nPython: Base Pydantic models (Request, Notification, Result); JSONRPC* models; McpError exception.\nC#: Abstract base JsonRpcMessage; JsonRpcRequest/Response/Notification/Error classes; McpException. System.Text.Json handling.\nJava: JSONRPCMessage interface/hierarchy; McpError exception. Jackson annotations.\n\n\nCross-SDK Comparison: How each SDK represents the core JSON-RPC structure (inheritance vs. composition, naming conventions). Handling of flexible params/result (TS/Python unknown/Any/Dict vs. C#/Java JsonNode/JsonElement/Object).\nNuanced Take: The trade-offs of building on JSON-RPC (simplicity, wide support) vs. potential drawbacks (text-based overhead, lack of streaming in base spec). Why was batching removed in the draft?\n\nBlog 3: The Handshake - Lifecycle and Capability Negotiation\n\nCore Focus: Analyzing the initialize/initialized flow and the concept of capability exchange.\nKey Spec Areas: docs/specification/{version}/basic/lifecycle.mdx. InitializeRequest, InitializeResult, InitializedNotification, ClientCapabilities, ServerCapabilities definitions in schema.ts.\nImplementation Insights:\n\nTS: Client.connect initiates; Server handles via internal handler; capabilities stored on instances.\nPython: ClientSession.__aenter__/initialize; ServerSession handles internally; capabilities stored.\nC#: McpClientFactory.CreateAsync initiates; McpServer handles via internal handler; capabilities stored. ServerCapabilities object often configured via DI/Options.\nJava: Explicit client.initialize(); McpServerSession handles; capabilities defined in McpServerFeatures passed to builder.\n\n\nCross-SDK Comparison: Implicit vs. explicit initialization on the client. How capabilities are defined and populated (DI/Attributes in C#, Builders/Specs in Java, Options in TS/Python). How strictly are capabilities enforced (enforceStrictCapabilities option in TS/Python)?\nNuanced Take: The importance of the handshake for version alignment and feature discovery. How capability negotiation enables graceful degradation and forward/backward compatibility (in theory). Challenges in ensuring SDKs correctly report and respect all declared capabilities.\n\nBlog 4: Exposing Actions - The Tool Primitive: Spec vs. Implementation\n\nCore Focus: Deep dive into the Tool definition, listing (tools/list), and execution (tools/call).\nKey Spec Areas: docs/specification/{version}/server/tools.mdx. Tool, ToolAnnotations, CallToolRequest, CallToolResult, ListToolsResult definitions in schema.ts. The inputSchema requirement (JSON Schema).\nImplementation Insights:\n\nTS: McpServer.tool() registration, Zod for inputSchema, RequestHandlerExtra for context, automatic error→isError:true conversion. McpClientTool on client.\nPython: @mcp.tool() decorator, type hints → Pydantic → inputSchema generation, Context injection, automatic result conversion, automatic error handling.\nC#: [McpServerTool] attribute, AIFunctionFactory for schema/invocation/DI, RequestContext + DI params for context, automatic error handling via wrapper. McpClientTool inherits AIFunction.\nJava: Tool record + Async/SyncToolSpecification registration via builder, manual inputSchema JSON, Exchange object for context, manual isError:true needed in handler.\n\n\nCross-SDK Comparison: Registration styles (method, decorator, attribute, spec object). Schema generation/validation approaches. Context provision mechanisms. Result/error handling patterns. Annotation support (ToolAnnotations).\nNuanced Take: The balance between developer ergonomics (Python decorators) and explicit control (TS/Java specs). The challenge of ensuring the inputSchema accurately reflects the handler’s actual parameter processing across languages. Implications of AIFunction integration (C#). Trust implications of ToolAnnotations.\n\nBlog 5: Providing Context - The Resource Primitive: Spec vs. Implementation\n\nCore Focus: Analyzing static Resources, dynamic Resource Templates, listing (resources/list, resources/templates/list), and reading (resources/read).\nKey Spec Areas: docs/specification/{version}/server/resources.mdx. Resource, ResourceTemplate, ResourceContents (Text/Blob) definitions in schema.ts. URI schemes (file://, etc.).\nImplementation Insights:\n\nTS: McpServer.resource() takes URI string or ResourceTemplate object. Callback receives parsed template variables. Internal UriTemplate class. list callback support on template.\nPython: @mcp.resource() decorator infers template from URI string syntax. Function parameters must match template variables. Automatic content conversion (str/bytes/JSON).\nC#: Requires manual URI matching/parsing within WithReadResourceHandler. No built-in template parameter binding to handler args. Handler returns ReadResourceResult. Manual base64 for blobs.\nJava: Requires manual URI matching/parsing within readHandler. McpUriTemplateManager helper available. Handler returns ReadResourceResult. Manual base64 for blobs.\n\n\nCross-SDK Comparison: Major difference in URI template handling/parameter binding automation (TS/Python automatic vs. C#/Java manual). Content return type handling. Resource listing (merging static/dynamic lists).\nNuanced Take: The power and complexity of URI templates. Security implications of file:// URIs (path traversal sanitization needed in handlers). The “application-controlled” nature of resources vs. model-controlled tools – how does this play out in practice?\n\nBlog 6: Guiding Interactions - The Prompt Primitive: Spec vs. Implementation\n\nCore Focus: Defining prompt templates (Prompt), arguments (PromptArgument), listing (prompts/list), and retrieval (prompts/get).\nKey Spec Areas: docs/specification/{version}/server/prompts.mdx. Prompt, PromptArgument, PromptMessage, GetPromptResult definitions. Content types within messages (Text, Image, Audio, EmbeddedResource).\nImplementation Insights:\n\nTS: McpServer.prompt(), Zod for arguments, handler returns { messages: [...] }. Completable for argument completion.\nPython: @mcp.prompt(), type hints for arguments, handler returns str, Message, dict, or sequences thereof (auto-converted).\nC#: [McpServerPrompt] attribute, handler returns ChatMessage/IEnumerable&lt;ChatMessage&gt;/string/PromptMessage/IEnumerable&lt;PromptMessage&gt;/GetPromptResult.\nJava: Prompt record + Async/SyncPromptSpecification registration, handler returns GetPromptResult or Mono&lt;GetPromptResult&gt;.\n\n\nCross-SDK Comparison: Registration styles. Argument definition (Zod vs. Type Hints vs. Attributes vs. Manual PromptArgument list). Result type flexibility (Python &gt; C# &gt; TS/Java). Built-in completion support (TS only).\nNuanced Take: The role of prompts as “user-controlled” entry points. How different return types facilitate different prompt construction patterns. Usefulness of EmbeddedResource.\n\nBlog 7: Client-Side Capabilities - Sampling and Roots\n\nCore Focus: Analyzing features where the client primarily implements the logic requested by the server.\nKey Spec Areas: docs/specification/{version}/client/sampling.mdx, docs/specification/{version}/client/roots.mdx. sampling/createMessage request/result, roots/list request/result, notifications/roots/list_changed. ModelPreferences definition.\nImplementation Insights:\n\nTS: ClientCapabilities.sampling object, ClientCapabilities.roots object. Handlers registered via Client.setRequestHandler.\nPython: sampling_callback, list_roots_callback, roots_list_changed_consumer passed to ClientSession constructor/builder.\nC#: SamplingCapability.SamplingHandler, RootsCapability.RootsHandler set in McpClientOptions. IMcpClient.SendNotificationAsync for roots/list_changed.\nJava: sampling(Function), listRoots(Function) methods on McpClient.async/sync builder. client.rootsListChangedNotification() method.\n\n\nCross-SDK Comparison: Handler registration (explicit methods vs. constructor callbacks vs. options object). How ModelPreferences are handled. How roots/list_changed notification is triggered by the client.\nNuanced Take: The “inverted” control flow of these features. Security/privacy implications of sampling (human-in-the-loop). Usefulness of roots for constraining server operations (e.g., filesystem access).\n\nBlog 8: Communication Channels - Transport Implementations Compared\n\nCore Focus: Comparing the implementation details of Stdio and HTTP-based transports across SDKs, based on the spec (docs/specification/{version}/basic/transports.mdx).\nKey Spec Areas: Stdio (newline delimited JSON). Streamable HTTP (single endpoint, GET/POST/DELETE, SSE/JSON responses, Mcp-Session-Id header, resumability via Last-Event-ID). HTTP+SSE (dual endpoint, endpoint event, sessionId query param). Backwards compatibility guidelines.\nImplementation Insights (Recap &amp; Deepen):\n\nTS: Stdio*Transport, StreamableHttp*Transport (implements spec fully), SSE*Transport (legacy compat). cross-spawn, fetch, EventSourceParserStream.\nPython: stdio_client/server (anyio), sse_client/SseServerTransport (implements legacy SSE spec via httpx-sse/sse-starlette). No Streamable HTTP.\nC#: Stdio*Transport, StreamableHttpHandler/SseHandler in ASP.NET Core (implements Streamable HTTP + legacy SSE compat). Core SseClientTransport can do either Streamable HTTP or legacy SSE via UseStreamableHttp flag. System.Diagnostics.Process, System.Net.Http, SseParser.\nJava: Stdio*Transport, HttpClientSseClientTransport (legacy SSE), WebFlux/WebMvc/HttpServlet Providers (legacy SSE). No Streamable HTTP. ProcessBuilder, java.net.http, Reactor/Servlet APIs.\n\n\nCross-SDK Comparison: The major divergence on primary HTTP transport (TS/C# favouring Streamable HTTP vs. Python/Java favouring HTTP+SSE). Resumability differences. Session ID handling (header vs. query param). Underlying libraries used (Node APIs vs. anyio vs. .NET BCL vs. Java stdlib/Reactor/Servlet).\nNuanced Take: Why the divergence in HTTP transport? Historical reasons? Ecosystem fit (ASGI vs. ASP.NET Core)? Impact on scalability, reliability, and firewall traversal. The practicalities of implementing backwards compatibility.\n\nBlog 9: Essential Utilities - Progress, Cancellation, Logging, Pagination\n\nCore Focus: How the cross-cutting utility features defined in the spec are implemented.\nKey Spec Areas: docs/specification/{version}/basic/utilities/, docs/specification/{version}/server/utilities/. ProgressNotification, CancelledNotification, LoggingMessageNotification, logging/setLevel, PaginatedResult, PaginatedRequest.\nImplementation Insights:\n\nProgress: progressToken in request _meta. TS uses onprogress callback. C# injects IProgress&lt;&gt;. Python Context has report_progress. Java requires manual sendNotification.\nCancellation: TS AbortSignal. C# CancellationToken. Python/Java rely on anyio/framework cancellation passed to handlers. All SDKs send/handle notifications/cancelled.\nLogging: Client sends logging/setLevel. Server sends notifications/message. All SDKs provide ways to send/receive these. C# offers AsClientLoggerProvider integration.\nPagination: cursor in request params, nextCursor in result. Client SDKs typically handle auto-pagination in List* methods; server handlers need to implement cursor logic.\n\n\nCross-SDK Comparison: Different mechanisms for progress reporting/handling. Integration with platform cancellation primitives. Logging API convenience. Transparency of pagination logic.\nNuanced Take: The importance of these utilities for building robust, user-friendly applications. How well do the SDKs abstract the underlying notification/request patterns for these features?\n\nBlog 10: The Spec Itself - Evolution, Contribution, and Future Directions\n\nCore Focus: The process of specification development and its impact on the SDKs.\nKey Spec Areas: docs/specification/versioning.mdx, docs/specification/contributing.mdx, CHANGELOG.mdx files within version directories, docs/development/roadmap.mdx. The draft/ schema/docs.\nImplementation Insights: How do SDKs typically track spec versions? (e.g., Constants like LATEST_PROTOCOL_VERSION). How are breaking changes managed? (Version negotiation in initialize). Observe differences between spec versions (e.g., Streamable HTTP vs. SSE, removal of batching in draft).\nCross-SDK Comparison: Do SDKs tend to implement spec versions uniformly, or do some lag/lead? How does the choice of “source of truth” language (TypeScript) impact other SDKs?\nNuanced Take: The challenges of maintaining a multi-language standard. Balancing stability vs. adopting new features. The role of the draft spec. How researchers or advanced users can contribute proposals or feedback directly to the specification repository. Discussing the roadmap items (Validation, Registry, Agents, Multimodality) and their potential impact on future SDK design.\n\n\nThis 12-part plan provides a comprehensive structure, starting with the spec repo itself and then systematically dissecting key protocol features, always comparing the abstract specification with the concrete implementations across the four major SDKs, while maintaining a perspective relevant to advanced users and researchers."},"3-Official-mcp-spec-tutes/Blogs/blog-1":{"slug":"3-Official-mcp-spec-tutes/Blogs/blog-1","filePath":"3 Official mcp spec tutes/Blogs/blog-1.md","title":"Blog 1: The Blueprint - Anatomy of the MCP Specification Repository","links":["3-Official-mcp-spec-tutes/Blogs/link-to-ts-py-series","3-Official-mcp-spec-tutes/Blogs/link-to-cs-java-series"],"tags":[],"content":"Blog 1: The Blueprint - Anatomy of the MCP Specification Repository\nSeries: Deep Dive into the Model Context Protocol SDKs\r\nPost: 1 of 12 (Advanced Topics)\nWelcome to a new deep-dive series exploring the Model Context Protocol (MCP) and its ecosystem! While our previous series examined the practical SDK implementations for Python and Java, this series takes a different tack. We’ll start from the source of truth – the specification itself – and use the various SDKs as lenses to understand how abstract protocol definitions translate into concrete, idiomatic code across different platforms.\nThis series is for advanced users, SDK developers, protocol designers, and researchers who want to understand not just how to use MCP, but why it’s designed the way it is, and the nuances involved in its multi-language implementation.\nOur first stop is the modelcontextprotocol/modelcontextprotocol repository. This isn’t an SDK; it’s the canonical reference, the blueprint defining the rules, messages, and concepts that all MCP clients, servers, and SDKs must adhere to.\nWhy a Dedicated Specification Repository?\nIn a multi-language, multi-implementation ecosystem like MCP aims to foster, having a central, authoritative specification is paramount. It serves several critical functions:\n\nSingle Source of Truth: Avoids ambiguity and ensures all implementations are working towards the same standard.\nInteroperability: Provides the common language necessary for clients and servers written in different languages (TS, Python, C#, Java, potentially others) to communicate reliably.\nFoundation for SDKs: Gives SDK developers a clear target to implement against.\nCompliance &amp; Validation: Establishes the basis for potential future compliance testing suites.\nFormal Process: Allows for structured evolution of the protocol through versioning and contribution guidelines.\nCentral Documentation: Acts as the primary hub for official protocol documentation.\n\nAnatomy of the Repository\nLet’s dissect the key parts of the modelcontextprotocol/modelcontextprotocol repository:\n1. The Schema (schema/)\nThis is the technical heart of the specification.\n\n\nTypeScript as Source (schema/{version}/schema.ts):\n\nWhy TypeScript? Its strong, structural type system (interfaces, types, enums, literals, unions) is exceptionally well-suited for precisely defining complex data structures like JSON-RPC messages. It provides excellent tooling support (like tsc for validation) and clarity.\nContent: Contains TypeScript interfaces and type aliases defining every request parameter, result structure, notification payload, capability object, and core data type (e.g., Resource, Tool, PromptMessage, TextContent) specified by MCP for a given protocol version. Includes constants like LATEST_PROTOCOL_VERSION and JSONRPC_VERSION.\nExample Snippet (schema/2025-03-26/schema.ts):\n/**\n * A known resource that the server is capable of reading.\n */\nexport interface Resource {\n  /** @format uri */\n  uri: string;\n  name: string;\n  description?: string;\n  mimeType?: string;\n  annotations?: Annotations;\n  size?: number; // Note: Size is integer in JSON Schema\n}\n\n\n\n\nGenerated JSON Schema (schema/{version}/schema.json):\n\nPurpose: Provides a language-agnostic, machine-readable definition of the protocol. Essential for code generation tools, validators in other languages, and general interoperability.\nGeneration: Automatically generated from the schema.ts file using the typescript-json-schema tool (invoked via npm run generate:json). This ensures the JSON Schema always stays in sync with the authoritative TypeScript definition.\nCI Check: The main.yml workflow verifies that the generated JSON schema hasn’t diverged from the TypeScript source after commits (git diff --exit-code), forcing developers to regenerate it if they modify schema.ts.\n\n\n\nVersioning (schema/{version}/):\n\nEach distinct, backwards-incompatible protocol version gets its own directory (e.g., 2024-11-05, 2025-03-26, draft). This clearly delineates changes between versions.\n\n\n\n2. The Documentation (docs/)\nThis directory contains the source files for the official modelcontextprotocol.io website.\n\nFramework: Built using Mintlify, a documentation platform that uses MDX (Markdown + JSX). This allows embedding interactive React components (like &lt;Tabs&gt;, &lt;CardGroup&gt;, sequence diagrams via Mermaid) within the documentation.\nContent Structure:\n\nHigh-level introductions, FAQs, client/server examples.\nDetailed Concepts section explaining primitives (Tools, Resources, etc.).\nThe Specification section, versioned mirroring the schema/ directory, provides human-readable explanations of each protocol message, capability, and flow. This is the narrative counterpart to the formal schema definitions.\nSDK-Specific Guides: Includes dedicated sections (currently for Java) demonstrating how to use the official SDKs, making it a central learning hub.\nDevelopment information (Roadmap, Contributing, Updates).\n\n\nConfiguration (docs/docs.json): Defines the site’s navigation structure, theme, logo, SEO metadata, and other Mintlify settings.\n\n3. Tooling &amp; CI/CD (package.json, tsconfig.json, .github/workflows/)\n\nNode.js Ecosystem: The repository itself is managed as a Node.js project, primarily for the tooling needed to validate the schema and build the documentation.\nSchema Validation (npm run validate:schema): Uses the TypeScript compiler (tsc with noEmit: true) to type-check the schema.ts files, ensuring internal consistency and correctness according to TypeScript’s rules.\nJSON Schema Generation (npm run generate:json): Executes typescript-json-schema to convert the TS definitions into standard JSON Schema.\nDocumentation Serving (npm run serve:docs): Uses mintlify dev for local previewing of the documentation site.\nFormatting (npm run format*): Uses prettier to maintain consistent formatting, especially for Markdown (.mdx) files.\nCI Workflows:\n\nmain.yml: Ensures the TS schema compiles and that the generated JSON schema is committed and up-to-date on every push/PR.\nmarkdown-format.yml: Checks Markdown formatting.\n(Note: SDK-specific workflows for testing/publishing reside in their respective repositories).\n\n\n\n4. Governance Files (LICENSE, CODE_OF_CONDUCT.md, etc.)\nStandard files defining the project’s open-source license (MIT), community standards, contribution process, and security policy reporting.\nHow the Specification Informs SDK Development\nThis central repository acts as the foundational reference for all official (and potentially community) SDKs:\n\nSchema as Contract: SDK developers use the schema.ts (if TS-based) or schema.json (for other languages) to generate or manually create the corresponding data structures (classes, records, structs) in their target language (e.g., Pydantic models in Python, POCOs in C#, POJOs in Java). This ensures message formats are consistent.\nDocumentation as Guide: The narrative documentation (docs/specification/) explains the intent and behavior associated with each message and feature, guiding the implementation of protocol logic (e.g., how initialization negotiation works, how errors should be handled, the flow for resource subscriptions).\nVersioning: The spec’s versioning dictates the protocolVersion field used in the initialize handshake. SDKs implement logic to handle version negotiation based on the versions they support and the versions defined here.\nConsistency Check: SDK implementations can (and should) be validated against the specification, potentially using automated tests that leverage the JSON Schema.\n\nNuances for Advanced Users &amp; Researchers\n\nDraft Specification: The schema/draft/ directory is crucial. It represents the bleeding edge of protocol development. Changes here signal potential future features or breaking changes that might impact upcoming SDK releases. Monitoring the draft is key for those wanting to provide early feedback or prepare for future versions. The removal of JSON-RPC batching in the draft is a significant example.\nTypeScript as Source: While providing precision, using TypeScript as the source can introduce subtle biases or challenges when translating concepts perfectly to other languages with different type systems or paradigms (e.g., representing complex union types, handling nullability consistently). Understanding the original TS definition can sometimes clarify intent when looking at a generated JSON schema or an SDK implementation.\nSpecification Gaps vs. SDK Features: Not every desirable feature is part of the protocol spec. Some features (like advanced CLIs, deep framework integration, specific helper utilities) are SDK-level additions built on top of the protocol. Distinguishing between what’s mandated by the spec versus what’s an SDK convenience is important for understanding portability and core requirements. The authorization framework in the TS SDK is a good example – while it uses MCP, the specific OAuth implementation details are an SDK feature, not mandated by the core MCP spec itself (though the newest spec version defines OAuth interaction patterns).\n\nConclusion\nThe modelcontextprotocol/modelcontextprotocol repository is more than just documentation; it’s the architectural blueprint and the legal code for MCP. Its rigorous definition using TypeScript and JSON Schema, combined with clear versioning and comprehensive narrative documentation, provides the stable foundation necessary for a thriving multi-language ecosystem.\nFor advanced users, understanding the structure of this repository, the role of the schemas, the versioning strategy, and the documentation framework (Mintlify/MDX) is essential for truly grasping the protocol’s design, anticipating its evolution, and even contributing to its future.\nWith this foundational understanding of the specification repository, we can now delve deeper into how specific protocol features defined here are realized in the different SDKs. Next time, we’ll tackle the JSON-RPC framing and MCP base types, comparing how Zod, Pydantic, System.Text.Json, and Jackson model the fundamental message structures.\n"},"3-Official-mcp-spec-tutes/Blogs/blog-10":{"slug":"3-Official-mcp-spec-tutes/Blogs/blog-10","filePath":"3 Official mcp spec tutes/Blogs/blog-10.md","title":"Blog 10: The Spec Itself - Evolution, Contribution, and Future Directions in MCP","links":["3-Official-mcp-spec-tutes/Blogs/blog-2","3-Official-mcp-spec-tutes/Blogs/blog-3","3-Official-mcp-spec-tutes/Blogs/blog-1.md1","3-Official-mcp-spec-tutes/Blogs/blog-1.md2","3-Official-mcp-spec-tutes/Blogs/blog-6","3-Official-mcp-spec-tutes/Blogs/blog-8","3-Official-mcp-spec-tutes/Blogs/blog-7","3-Official-mcp-spec-tutes/Blogs/blog-9","3-Official-mcp-spec-tutes/Blogs/blog-1"],"tags":[],"content":"Blog 10: The Spec Itself - Evolution, Contribution, and Future Directions in MCP\nSeries: Deep Dive into the Model Context Protocol SDKs (Advanced Topics)\r\nPost: 10 of 12\nThroughout this advanced series, we’ve meticulously dissected the Model Context Protocol (MCP) SDKs across TypeScript, Python, C#, and Java. We’ve compared their handling of core types, server lifecycles, primitives like Tools, Resources, and Prompts, examined transports, client capabilities, and essential utilities. Underlying all these implementations, however, is the MCP Specification itself – the blueprint residing in the modelcontextprotocol/modelcontextprotocol repository.\nFor advanced users, SDK implementers, and researchers, understanding the specification’s structure, evolution process, and future trajectory is as important as understanding any single SDK. This final technical post focuses on the specification as a living document:\n\nStructure and Authority: Revisiting the spec repo and the role of the TypeScript schema.\nVersioning Philosophy: The YYYY-MM-DD scheme and backwards compatibility.\nEvolution in Action: Comparing spec versions (2024-11-05 vs. 2025-03-26 vs. draft).\nContribution Process: How the community can shape MCP’s future.\nFuture Roadmap: Key areas under active discussion and development.\n\nThe Specification Repository: Revisited\nAs established in Blog 1, the modelcontextprotocol/modelcontextprotocol repository is the single source of truth. Its key components for spec evolution are:\n\nschema/{version}/schema.ts: The authoritative definition using TypeScript interfaces. Precision and type safety are paramount.\nschema/{version}/schema.json: The machine-readable artifact generated from TypeScript, used for validation and code generation in non-TS SDKs.\ndocs/specification/{version}/: The human-readable documentation explaining the intent and behavior defined in the schema, using Mintlify/MDX.\ndocs/specification/{version}/changelog.mdx: Summarizes key changes between official versions.\nCONTRIBUTING.md: Outlines the process for proposing changes.\nGitHub Issues &amp; Discussions: The forums for proposing, debating, and tracking changes.\nGitHub Project (Standards Track): Visualizes the progress of proposals towards standardization.\n\nVersioning Philosophy: Stability and Progress\nMCP employs a date-based versioning scheme (YYYY-MM-DD) for its protocol specification.\n\nMeaning: The date signifies the last time a backwards-incompatible change was introduced and finalized.\nBackwards Compatibility: Crucially, backwards-compatible additions or clarifications do not typically trigger a new version date. The specification document for a given version (e.g., 2025-03-26) might receive minor updates over time, but the version identifier remains stable as long as compatibility is maintained.\nNegotiation: The initialize handshake (Blog 3) is where client and server agree on a specific protocol version string to use for their session. Clients should request the latest version they support; servers respond with the version they will use (either the client’s requested version or the latest the server supports).\nSDK Support: SDKs typically define constants for the latest supported versions (e.g., LATEST_PROTOCOL_VERSION, SUPPORTED_PROTOCOL_VERSIONS in TS/Python types files). They use these during the initialize handshake.\n\nThis strategy aims to balance stability (allowing implementations targeting 2024-11-05 to continue working) with progress (introducing new features in later versions like 2025-03-26).\nEvolution in Action: Comparing Spec Versions\nComparing the schema and documentation across versions reveals the protocol’s trajectory:\n\n2024-11-05: The baseline version heavily referenced by the Python and Java SDKs. Key features:\n\nCore primitives (Tools, Resources, Prompts).\nClient capabilities (Sampling, Roots).\nUtilities (Logging, Pagination, Ping, Cancellation, Progress).\nTransports: Stdio and HTTP+SSE (dual endpoint).\n\n\n2025-03-26: A significant update, primarily reflected in the TypeScript and C# SDKs. Key changes:\n\nStreamable HTTP Transport: Replaced HTTP+SSE with a more robust single-endpoint model supporting SSE/JSON responses on POST, optional GET streams, header-based sessions, and resumability (Last-Event-ID). (Spec)\nOAuth 2.1 Authorization Framework: Introduced a detailed specification for OAuth-based authorization for HTTP transports. (Spec)\nTool Annotations: Added standardized hints (readOnlyHint, destructiveHint, etc.) to the Tool definition. (Spec)\nAudio Content: Added AudioContent type alongside TextContent and ImageContent.\nCompletions Capability: Formalized the server capability for argument autocompletion.\nAdded message to ProgressNotification.\n\n\ndraft: Represents ongoing work. Notable changes currently include:\n\nRemoval of JSON-RPC Batching: Simplifies message processing logic for both clients and servers (PR #416). Implementations must still receive batches per the base JSON-RPC spec, but the MCP spec no longer details specific batching semantics and SDKs might simplify their sending logic.\nOAuth Refinements: Incorporating OAuth 2.0 Protected Resource Metadata (RFC9728) for more standard authorization server discovery.\nSecurity Best Practices: Adding a dedicated document.\n\n\n\nImpact on SDKs: The evolution highlights why SDKs might differ. The Python/Java SDKs, while potentially supporting newer protocol messages, seem architecturally aligned with the 2024-11-05 transport model (HTTP+SSE). The TS/C# SDKs embrace the 2025-03-26 changes, particularly Streamable HTTP. Future SDK releases will likely converge towards newer spec versions.\nContributing to the Specification\nMCP is an open protocol, and community input is vital. The process typically involves:\n\nDiscussion: Proposing ideas, asking questions, or providing feedback on GitHub Discussions (Org-level or Spec repo).\nIssue Tracking: Filing specific bug reports or feature requests as GitHub Issues.\nProposals: More formal proposals for significant changes might involve writing up a design document or draft specification text.\nPull Requests: Submitting changes to the schema/draft/schema.ts and corresponding documentation (docs/specification/draft/) via Pull Requests against the specification repository. Adherence to contribution guidelines (CONTRIBUTING.md) and the Code of Conduct is required.\nReview &amp; Iteration: Maintainers and the community review proposals and PRs.\nStandardization Track: Accepted proposals move through stages (tracked potentially on the GitHub Project board) before being merged into draft and eventually potentially forming part of a new dated version release if they introduce breaking changes.\n\nAdvanced users and researchers with specific needs (e.g., handling novel scientific data types, needing specialized transport bindings) are encouraged to engage in this process.\nFuture Directions &amp; Roadmap Insights\nThe docs/development/roadmap.mdx outlines key focus areas (as of its last update):\n\nValidation &amp; Compliance: Creating reference implementations and test suites to ensure SDKs and servers correctly implement the spec. This is crucial for guaranteeing interoperability.\nRegistry: A potential API/service for discovering publicly available MCP servers, fostering an open ecosystem beyond private integrations.\nAgents: Enhancing MCP for multi-agent systems (Agent Graphs, namespacing) and improving human-in-the-loop workflows (granular permissions, direct user communication channels).\nMultimodality: Expanding beyond text/image/audio to potentially include video or other complex data types, possibly involving streaming mechanisms.\nGovernance: Formalizing the process for community contributions and potential standardization through industry bodies.\n\nImplications for Advanced Users:\n\nCompliance Testing: Will allow verifying custom server/client implementations against the standard.\nRegistry: Could simplify discovering and integrating third-party MCP services.\nAgentic Features: Enhancements could simplify building complex, multi-tool, multi-server AI agents.\nStreaming: Native support for streaming large resources or tool results would address current limitations noted in Blog 12.\n\nConclusion: The Living Standard\nThe Model Context Protocol specification is not a static document but a living blueprint, actively evolving to meet the needs of developers building context-aware AI applications. Housed in its dedicated repository, defined precisely using TypeScript and JSON Schema, and versioned carefully to balance stability and progress, it provides the essential foundation for the entire MCP ecosystem.\nFor advanced developers and researchers, engaging directly with the specification repository – understanding its structure, tracking the draft version, participating in discussions, and potentially contributing – offers the deepest insight into MCP’s design and trajectory. The specification dictates the capabilities and limitations faced by the SDKs, and its evolution will directly shape the future tools available for bridging the gap between AI and application context across diverse platforms like TypeScript, Python, C#, and Java.\n"},"3-Official-mcp-spec-tutes/Blogs/blog-12":{"slug":"3-Official-mcp-spec-tutes/Blogs/blog-12","filePath":"3 Official mcp spec tutes/Blogs/blog-12.md","title":"Blog 12: Extending MCP - Custom Transports, Capabilities, and SDK Modifications","links":["3-Official-mcp-spec-tutes/Blogs/blog-1.md1"],"tags":[],"content":"Blog 12: Extending MCP - Custom Transports, Capabilities, and SDK Modifications\nSeries: Deep Dive into the Model Context Protocol SDKs (Advanced Topics)\r\nPost: 12 of 12\nIn this series, we’ve thoroughly explored the standard features and architectures of the Model Context Protocol (MCP) SDKs for TypeScript, Python, C#, and Java. We’ve seen how they provide idiomatic ways to implement Tools, Resources, Prompts, and handle communication over standard transports like Stdio and HTTP variants.\nHowever, advanced use cases sometimes demand capabilities beyond the core specification or require integration with non-standard communication channels. For developers hitting the limits of the out-of-the-box features, understanding the extensibility points and customization strategies within the SDKs is crucial.\nThis post delves into advanced techniques for extending and modifying MCP implementations, targeting developers who need to:\n\nImplement Custom Transports for specialized communication needs (e.g., gRPC, MQTT, named pipes).\nDefine and handle Custom Capabilities and Methods beyond the standard MCP set.\nModify core SDK Behavior (use with caution!).\nCustomize JSON Serialization for specific data types or performance needs.\nTune Transport Performance.\n\n1. Why Extend or Customize?\nWhile sticking to the standard MCP specification ensures maximum interoperability, customization might be necessary for:\n\nProprietary Communication: Integrating MCP over existing internal message queues or RPC mechanisms (MQTT, gRPC, ZeroMQ).\nSpecialized Hardware/Protocols: Interfacing with devices or systems that don’t use standard TCP/IP or stdio (e.g., embedded systems, specific bus protocols).\nExperimental Features: Prototyping new MCP capabilities or methods before proposing them for standardization.\nPerformance Optimization: Implementing highly optimized transports or serialization for specific high-throughput scenarios.\nDeep Framework Integration: Embedding MCP communication logic more deeply within a specific application framework than the standard integrations allow.\n\nThe Caveat: Customizations, especially non-standard methods or transports, inherently limit interoperability. They are best suited for closed ecosystems or as precursors to standardization proposals.\n2. Implementing Custom Transports\nThe core requirement is to bridge your custom communication channel with the SDK’s expectation of sending and receiving JsonRpcMessage objects.\n\nThe Contract: Provide an implementation that can asynchronously:\n\nEstablish and tear down the underlying connection.\nSerialize outgoing JsonRpcMessage objects into the transport’s wire format (likely newline-delimited JSON for simplicity, but could be binary like Protobuf if paired with custom serialization) and send them.\nReceive raw data from the transport, frame it correctly (e.g., read until newline, decode packet), deserialize it into a JsonRpcMessage, and deliver it to the SDK’s core session logic.\nHandle transport-level errors and connection closure events.\n\n\nSDK Approaches:\n\nTypeScript: Implement the Transport interface (start, send, close, onmessage, onclose, onerror). Integrate with Node.js APIs (net.Socket, dgram, custom native modules) or Web APIs. Pass the custom transport instance to client.connect / server.connect.\nPython: Implement the transport factory pattern: an asynccontextmanager that yields two anyio.streams.memory.MemoryObjectReceiveStream / MemoryObjectSendStream pairs. Internally, start anyio tasks to read from your custom channel (e.g., mqtt client library, grpc stream) and push deserialized JsonRpcMessages into the read_stream_writer, and another task to read from the write_stream_reader, serialize, and send over your custom channel. Integrate by passing the streams from your context manager to ClientSession / Server.run.\nC#: Implement ITransport (for sessions) and optionally IClientTransport (for connection). Manage underlying connection (e.g., System.IO.Pipes, System.Net.Sockets, gRPC client/server streams). Use System.Threading.Channels for the MessageReader property. Implement SendMessageAsync and DisposeAsync. Integrate via DI or direct instantiation with McpServerFactory/McpClientFactory.\nJava: Implement McpTransport, McpClientTransport, and potentially McpServerTransportProvider. Handle connection lifecycle. Use ObjectMapper (Jackson) for serialization. Use concurrent queues (BlockingQueue) or reactive streams (FluxSink/MonoProcessor from Reactor) to bridge between your I/O thread/callbacks and the McpSession. Integrate via the McpClient.sync/async or McpServer.sync/async builders.\n\n\n\nExample Idea (Conceptual WebSocket Server Transport - TS):\n// Conceptual - Does NOT fully handle errors, lifecycle, etc.\nimport WebSocket, { WebSocketServer } from &#039;ws&#039;;\nimport { Transport, JSONRPCMessage, serializeMessage, deserializeMessage } from &#039;@modelcontextprotocol/sdk/shared&#039;; // Assuming serialize/deserialize helpers exist\n \nclass WebSocketServerTransport implements Transport {\n  private wss: WebSocketServer;\n  private clients = new Set&lt;WebSocket&gt;();\n  public onmessage?: (message: JSONRPCMessage) =&gt; void;\n  public onclose?: () =&gt; void; // Note: Needs logic for *which* client closed\n  public onerror?: (error: Error) =&gt; void;\n \n  constructor(port: number) {\n    this.wss = new WebSocketServer({ port });\n  }\n \n  async start(): Promise&lt;void&gt; {\n    this.wss.on(&#039;connection&#039;, (ws) =&gt; {\n      this.clients.add(ws);\n      console.log(&#039;MCP Client connected via WebSocket&#039;);\n \n      ws.on(&#039;message&#039;, (data) =&gt; {\n        try {\n          const message = deserializeMessage(data.toString()); // Assumes newline framing or similar\n          this.onmessage(message);\n        } catch (e) {\n          this.onerror(e instanceof Error ? e : new Error(String(e)));\n        }\n      });\n \n      ws.on(&#039;close&#039;, () =&gt; {\n        this.clients.delete(ws);\n        console.log(&#039;MCP Client disconnected&#039;);\n        // Potentially trigger onclose if *all* clients disconnect? Needs session mapping.\n      });\n \n      ws.on(&#039;error&#039;, (err) =&gt; this.onerror(err));\n    });\n    console.log(`WebSocket MCP Server listening on port ${this.wss.options.port}`);\n  }\n \n  // Send needs targeting - MCP session usually 1:1 with transport\n  // This simple broadcast isn&#039;t correct for standard MCP server logic\n  // A real implementation needs session mapping.\n  async send(message: JSONRPCMessage): Promise&lt;void&gt; {\n    const serialized = serializeMessage(message);\n    this.clients.forEach(client =&gt; {\n      if (client.readyState === WebSocket.OPEN) {\n        client.send(serialized);\n      }\n    });\n  }\n \n  async close(): Promise&lt;void&gt; {\n    this.wss.close();\n    this.clients.clear();\n    this.onclose();\n  }\n}\n(This example highlights the complexity - a real server needs to map incoming WS connections to individual MCP sessions and transports).\n3. Custom Capabilities and Methods\nMCP is extensible through the experimental capabilities field and by allowing arbitrary method strings.\n\nDeclaring: Add custom keys to the ClientCapabilities.experimental or ServerCapabilities.experimental object during the initialize handshake.\nHandling Custom Requests/Notifications:\n\nUse the low-level server APIs. The high-level APIs (McpServer/FastMCP) are typically focused on standard primitives.\n\nTS: server.setRequestHandler(&quot;my_company/my_custom_request&quot;, myHandler)\nPython (Low-level): @server.request_handler(&quot;my_company/my_custom_request&quot;)\nC#: Add to McpServerOptions.Capabilities handlers manually or create a custom IMcpServerBuilder extension. Handler receives RequestContext&lt;JsonNode?&gt;.\nJava: Add handler BiFunction to the map passed in McpServerFeatures. Handler receives Exchange and Map&lt;String, Object&gt;.\n\n\nDefine custom POCO/POJO/Record/Interface types for your parameters and results and handle their JSON serialization/deserialization.\n\n\nInvoking Custom Requests/Notifications (Client):\n\nUse the low-level client.request(...) or client.notification(...) methods (available in all SDKs), providing the custom method string.\nManually serialize parameters and deserialize results using your custom types and the platform’s JSON library.\n\n\n\nWarning: Custom methods break interoperability unless the peer explicitly supports them. Use standard methods where possible or prefix custom methods clearly (e.g., vendor_prefix/method_name).\n4. Modifying Core SDK Behavior\nAltering the SDK’s internal workings is risky and can lead to compatibility issues, but might be considered for deep integration or specialized needs.\n\nInheritance: Subclass core components (e.g., McpSession, McpServer, StdioClientTransport). Override methods to change behavior. Risk: Relies on internal APIs which may change between SDK versions. Test thoroughly.\nDependency Injection (C#): Replace default service implementations. For example, register a custom IMcpServer implementation or use a library like Scrutor to decorate existing services. Powerful but requires understanding the DI registrations.\nComposition/Wrapping: Wrap existing SDK clients or servers in your own classes, intercepting calls to add custom logic before/after delegating to the inner instance (e.g., DelegatingMcpServerTool in C#). Safer than inheritance.\nMonkey Patching (Python/TS): Discouraged. Replacing methods at runtime is fragile and breaks easily with SDK updates.\nForking: Last resort. You gain full control but lose upstream updates and bug fixes.\nContribution: The best approach for generally useful changes is to contribute them back to the official SDK repositories.\n\n5. Customizing JSON Serialization\nNeeded for handling domain-specific types or optimizing performance.\n\nC# (System.Text.Json): Provide custom JsonSerializerOptions (potentially with custom JsonConverters registered) to McpServerToolCreateOptions, McpServerPromptCreateOptions, or configure globally via DI (services.Configure&lt;JsonOptions&gt;(...)). Leverage JsonSerializerContext for AOT/performance.\nJava (Jackson): Configure the ObjectMapper instance used by the SDK (passed to Transport Providers or Builders). Register custom Modules, JsonSerializers, JsonDeserializers. Use features like @JsonCreator, @JsonValue.\nTypeScript (Zod/JSON): Zod primarily focuses on validation to/from standard JS types. For non-standard wire formats, you’d likely perform conversion before Zod validation (on read) or after Zod creates a plain JS object (on write), before passing to JSON.stringify. Libraries like superjson could be integrated at the transport boundary.\nPython (Pydantic/JSON): Use custom Pydantic types with @validator/@serializer, RootModel, custom JSON encoders/decoders passed to json.dumps/loads, or faster libraries like orjson integrated at the transport level.\n\n6. Performance Tuning Transports\nBeyond handler logic (Blog 11), transport tuning can help:\n\nBuffer Sizes: Adjust internal buffers for streams/pipes/channels (platform/library specific) to balance memory usage and throughput.\nThreading/Scheduling (Java/C#): Configure thread pools or Reactor schedulers used for I/O and handler execution. Ensure non-blocking operations don’t starve CPU-bound work. Use Java’s Virtual Threads for simpler scaling of blocking code.\nSerialization Choice: Benchmark different JSON libraries (e.g., System.Text.Json source-gen vs. reflection in C#, Jackson vs. Gson vs. LoganSquare in Java, built-in vs. orjson in Python) if serialization is a bottleneck.\nTransport Protocol Choice: For very high-frequency, low-latency needs where both ends are controllable, consider a custom binary transport (e.g., Protobuf over gRPC or WebSockets) instead of JSON-RPC over Stdio/HTTP. This is a significant departure from standard MCP.\n\nConclusion: Power Comes with Responsibility\nThe MCP SDKs provide well-defined extension points, allowing advanced developers to tailor communication to specific needs by implementing custom transports or handling non-standard methods. They also offer varying degrees of flexibility for modifying core behavior and customizing serialization, leveraging the strengths of their respective platforms (DI in C#, explicit builders in Java, dynamic patching in TS/Python).\nHowever, deviating from the standard specification, especially with custom methods or transports, inherently sacrifices interoperability. These advanced techniques should be employed judiciously, primarily for:\n\nIntegrating with legacy or specialized systems where standard transports aren’t feasible.\nPrototyping potential future MCP features within a controlled environment.\nOptimizing for extreme performance requirements where standard JSON/HTTP overhead is prohibitive.\n\nFor generally useful enhancements, contributing back to the official SDKs or proposing changes to the MCP specification itself remains the preferred path to ensure a healthy, interoperable ecosystem. Understanding these extensibility points empowers developers to push MCP’s boundaries while being mindful of the trade-offs involved.\n"},"3-Official-mcp-spec-tutes/Blogs/blog-13":{"slug":"3-Official-mcp-spec-tutes/Blogs/blog-13","filePath":"3 Official mcp spec tutes/Blogs/blog-13.md","title":"Blog 13: Ensuring Reliability - Advanced Testing Strategies for MCP SDKs","links":[],"tags":[],"content":"Blog 13: Ensuring Reliability - Advanced Testing Strategies for MCP SDKs\nSeries: Deep Dive into the Model Context Protocol SDKs (Advanced Topics)\r\nPost: 13 of 10\nWe’ve extensively analyzed the architecture, features, transports, and security aspects of the Model Context Protocol (MCP) SDKs for TypeScript, Python, C#, and Java. For advanced developers building production systems, the final crucial piece is ensuring these intricate client-server interactions are reliable, correct, and resilient through robust testing.\nMCP integrations involve multiple moving parts: protocol serialization/deserialization, transport communication, asynchronous message handling, capability negotiation, handler logic, framework integration, and interactions with external dependencies (LLMs, databases, APIs). A comprehensive testing strategy is essential to catch bugs early and maintain stability.\nThis post targets experienced developers, outlining advanced testing strategies and comparing the tools and patterns available within each SDK ecosystem:\n\nThe Testing Pyramid for MCP: Unit, Integration, and End-to-End testing levels.\nUnit Testing Handlers: Isolating Tool, Resource, and Prompt logic.\nMocking the Transport Layer: Testing protocol sessions without real I/O.\nIn-Memory Integration Testing: Connecting real clients and servers locally.\nFramework Integration Testing: Verifying web server setups (ASP.NET Core, Spring, ASGI, Node).\nExternal Process/Container Testing: Validating Stdio and network interactions.\nTesting Edge Cases: Simulating errors, timeouts, and cancellations.\n\n1. The Testing Pyramid Applied to MCP\nA layered approach is most effective:\n\nUnit Tests (Fastest, Most Numerous):\n\nFocus: Test individual Tool/Resource/Prompt handler functions in isolation.\nMocking: Mock external dependencies (database access, API clients, file system) and MCP context objects (Context, Exchange, RequestHandlerExtra, IMcpServer).\nGoal: Verify business logic, argument parsing, result formatting, and basic error handling within the handler itself.\n\n\nIntegration Tests (Medium Speed, Fewer):\n\nFocus: Test the interaction between MCP client and server components, often using mocked transports or frameworks.\nTypes:\n\nProtocol/Session Level: Connect client and server sessions using in-memory transports to verify message flows, capability negotiation, lifecycle, and core protocol logic handling (serialization, routing).\nFramework Level: Test the integration with web frameworks (ASP.NET Core, Spring, ASGI) using in-memory test servers to verify routing, middleware, and request handling through the framework stack.\n\n\nGoal: Verify that components work together correctly according to the MCP spec and framework integration functions as expected.\n\n\nEnd-to-End (E2E) Tests (Slowest, Fewest):\n\nFocus: Test the complete system, including real transports (Stdio, HTTP), potentially real external dependencies (or containerized versions), and real client/server processes.\nGoal: Verify the entire workflow under realistic conditions, catching issues related to process management, network configuration, and inter-process communication.\n\n\n\n2. Unit Testing Handlers\nThis is where the core logic resides. The goal is to test the handler function without involving the MCP session or transport layers.\n\nTypeScript:\n\nIsolate the handler function passed to mcpServer.tool/resource/prompt.\nMock the RequestHandlerExtra object. Use mocking libraries like jest.fn() or sinon to simulate sendNotification or check signal.aborted. Mock external dependencies.\nTest argument validation logic implicitly by calling the handler with test data (though Zod handles much of this before the handler is called). Test return value structure.\n\n\nPython (FastMCP):\n\nIsolate the decorated function (e.g., my_tool_func).\nMock the Context object if the function requires it (e.g., mock_context = Mock(spec=Context)). Configure mock methods like mock_context.info, mock_context.report_progress. Mock external dependencies.\nTest the function directly with various inputs. Pydantic handles input validation internally. Test the function’s return value for different scenarios.\n\n\nC#:\n\nIsolate the static or instance method marked with [McpServerTool/Prompt].\nIf using DI, leverage .NET’s testing support (Microsoft.Extensions.DependencyInjection testing helpers) to provide mock dependencies (Mock&lt;IMyService&gt;).\nMock context parameters like IMcpServer, RequestContext, IProgress&lt;&gt;, CancellationToken.\nUse standard unit testing (xUnit/NUnit/MSTest + Moq/NSubstitute) to invoke the method and assert results/interactions.\n\n\nJava:\n\nIsolate the BiFunction handler logic.\nMock the McpAsync/SyncServerExchange object and external dependencies using Mockito or similar. Configure mock behavior for methods like exchange.loggingNotification().\nTest the handler function directly, passing mock exchange and argument maps. Manually test argument validation logic within the handler. Assert the returned CallToolResult/ReadResourceResult/etc.\n\n\n\n3. Mocking the Transport Layer\nTo test the core session logic (McpSession, BaseSession) without real I/O:\n\nTypeScript: Use InMemoryTransport.createLinkedPair(). Pass one transport to the Client, the other to the Server. Allows testing the full initialize handshake and message exchange purely in memory.\nPython: Use create_client_server_memory_streams() from shared/memory.py. This yields pairs of anyio memory streams. Pass these streams directly to ClientSession and ServerSession (or the low-level Server.run method). The mcp-test module also provides MockMcpTransport.\nC#: The tests/Common/Utils directory contains TestServerTransport, an ITransport implementation using System.Threading.Channels internally for in-memory message passing. Instantiate this and pass it to McpServerFactory.Create and potentially a custom client setup using StreamClientTransport wrapping the channels.\nJava: The mcp-test module provides MockMcpTransport. Instantiate McpServer.async/sync and McpClient.async/sync using this mock transport to test session logic directly.\n\nUse Cases: Verifying initialization sequences, capability negotiation logic, request/response correlation, handling of notifications (like cancelled, progress), basic error propagation.\n4. In-Memory Integration Testing\nSimilar to transport mocking, but uses the full Client and Server (or FastMCP/McpServer) instances connected via memory streams/transports.\n\nGoal: Verify the interaction between the high-level client APIs and the high-level server APIs, including handler registration and dispatch, but without real process/network overhead.\nSetup: Identical to transport mocking setup (using InMemoryTransport, create_client_server_memory_streams, TestServerTransport, MockMcpTransport).\nExample (tests/shared/test_memory.py, tests/shared/test_session.py): These tests demonstrate connecting ClientSession and Server via memory streams and performing initialize/ping/tool calls.\n\n5. Framework Integration Testing\nFor servers using web frameworks, testing the full HTTP stack is crucial.\n\nC# (ASP.NET Core):\n\nWebApplicationFactory&lt;TEntryPoint&gt;: The standard way to test ASP.NET Core apps. It boots the application in-memory.\nKestrelInMemoryTransport: (As used in ModelContextProtocol.AspNetCore.Tests) A custom IConnectionListenerFactory that replaces Kestrel’s socket listener with in-memory pipes, allowing HttpClient (configured with a special handler) to talk to the app without real networking.\nWorkflow: Create WebApplicationFactory, get HttpClient from it, make HTTP requests to the mapped MCP endpoints (/mcp, /sse), assert HTTP status codes and response bodies/SSE events. Tests the full pipeline including routing, middleware, DI scopes, and the MCP handlers (StreamableHttpHandler/SseHandler).\n\n\nJava (Spring):\n\n@SpringBootTest: Loads the full application context.\nWebTestClient (WebFlux): A non-blocking client for testing reactive endpoints. Make GET requests to /sse and POST requests to /message, assert responses and SSE stream content.\nMockMvc (WebMvc): For testing traditional Spring MVC endpoints. Similar usage pattern to WebTestClient.\nAllows testing controllers/router functions that host the McpServerTransportProvider.\n\n\nPython (ASGI):\n\nUse httpx.AsyncClient with the ASGI application instance (e.g., Starlette or FastAPI app).\nExample: async with httpx.AsyncClient(app=my_starlette_app, base_url=&quot;http://test&quot;) as client:\nMake GET requests to the SSE endpoint and POST requests to the message endpoint, validating responses.\n\n\nTypeScript (Node.js/Express):\n\nUse libraries like supertest to make requests against an in-memory instance of the express application.\nTest the routes configured to handle MCP requests. Requires more manual setup for SSE stream testing compared to integrated test clients.\n\n\n\n6. External Process/Container Testing\nFor the highest fidelity, especially for Stdio or complex network scenarios:\n\nStdio: Use the actual StdioClientTransport in tests to launch the server executable (dotnet run --project ..., python script.py, node script.js, java -jar ...). Assert against the client interaction results. Ensure proper process cleanup (KillTree in C#).\nHTTP: Launch the server as a separate process or, ideally, within a Docker container using libraries like Testcontainers (available for Java, .NET, Python, Go).\n\nTestcontainers: Manages container lifecycle, networking, and cleanup. The test connects to the container’s exposed port using a real HTTP client transport (SseClientTransport, StreamableHTTPClientTransport).\nExamples: C# (DockerEverythingServerTests), Java (mcp-test likely uses it).\n\n\nGoal: Validate real process communication, environment variable handling, network behavior, and interoperability with canonical server implementations (like the Everything Server).\n\n7. Testing Edge Cases\n\nMalformed Messages: Send invalid JSON or non-compliant JSON-RPC messages via a mock transport; verify the receiver handles errors gracefully (e.g., sends ParseError/InvalidRequest or logs and continues).\nTimeouts: Use test-controlled time providers (FakeTimeProvider in C#) or manipulate delays to test client/server request timeouts.\nCancellation: Use CancellationTokenSource / AbortController / etc., to cancel client requests or server-side handlers during execution; verify cancellation propagates correctly and resources are cleaned up.\nTransport Disconnection: Abruptly close mock transport streams/channels; verify onclose handlers fire and pending requests fail appropriately. Test resumability if using Streamable HTTP.\nConcurrency: Use task groups (anyio, Task.WhenAll) to send many concurrent requests and verify correct response correlation and lack of deadlocks.\n\nConclusion: Building Confidence Through Layers\nTesting MCP integrations requires a multi-layered strategy. Unit tests validate core handler logic, transport mocking verifies session mechanics, in-memory integration tests confirm client-server API interactions, framework integration tests ensure web hosting works correctly, and external process/container tests provide the highest fidelity end-to-end validation.\nEach SDK provides tools and patterns suited to its ecosystem: C# leverages DI and ASP.NET Core testing, Java utilizes its mcp-test module and Testcontainers, Python uses anyio and httpx test clients, and TypeScript employs InMemoryTransport and Node testing frameworks. By combining these techniques and focusing on edge cases like errors and cancellations, advanced developers can build confidence in the reliability and correctness of their complex MCP applications.\n"},"3-Official-mcp-spec-tutes/Blogs/blog-2":{"slug":"3-Official-mcp-spec-tutes/Blogs/blog-2","filePath":"3 Official mcp spec tutes/Blogs/blog-2.md","title":"Blog 2: The Core Language - JSON-RPC Framing and MCP Base Types Across SDKs","links":["3-Official-mcp-spec-tutes/Blogs/blog-1"],"tags":[],"content":"Blog 2: The Core Language - JSON-RPC Framing and MCP Base Types Across SDKs\nSeries: Deep Dive into the Model Context Protocol SDKs\r\nPost: 2 of 12 (Advanced Topics)\nIn Blog 1, we established the modelcontextprotocol/modelcontextprotocol repository as the definitive blueprint for the Model Context Protocol (MCP). Now, we peel back the first layer of that blueprint: the fundamental message structure based on JSON-RPC 2.0 and the core MCP base types that build upon it.\nUnderstanding how each SDK (TypeScript, Python, C#, Java) models these foundational elements is crucial, as it dictates how all subsequent MCP requests, responses, and notifications are structured, serialized, validated, and processed. We’ll compare the implementation choices using Zod, Pydantic, System.Text.Json, and Jackson, referencing the authoritative definitions in the specification schema.\nJSON-RPC 2.0: The Chosen Wire Format\nMCP leverages the simplicity and widespread support of JSON-RPC 2.0 for its message structure. This choice provides:\n\nText-Based Format: Human-readable (JSON) and easily parseable.\nClear Message Types: Distinguishes between Requests (expecting responses), Responses (results/errors), and Notifications (one-way).\nRequest Correlation: Uses an id field (string or number) to match responses back to requests, essential for asynchronous communication.\nStandard Error Structure: Defines a consistent way (error object with code, message, data) to report failures.\n\nThe specification (basic section) mandates adherence to JSON-RPC 2.0, with a few MCP-specific constraints (e.g., request id cannot be null). The draft spec notably removes support for JSON-RPC batching, simplifying implementations.\nModeling the Core Structures: SDK Approaches\nLet’s examine how each SDK defines the fundamental JSON-RPC message types and related base MCP types (Request, Notification, Result, Params).\n1. TypeScript (src/types.ts) - Zod Schemas &amp; Interfaces\n\nApproach: Uses Zod schemas for validation and derives TypeScript interfaces using z.infer. Defines constants for versions and error codes.\nCore Types:\n\nJSONRPC_VERSION = &quot;2.0&quot; (Constant)\nRequestIdSchema = z.union([z.string(), z.number().int()]) → type RequestId = string | number\nRequestSchema (base with method, optional params): z.object({...})\nJSONRPCRequestSchema: Merges RequestSchema with jsonrpc literal and id, marked .strict() at the top level.\nNotificationSchema / JSONRPCNotificationSchema: Similar structure, no id.\nResultSchema: Base for results, allows _meta, marked .passthrough().\nJSONRPCResponseSchema: Contains id, jsonrpc, and result (linking to ResultSchema).\nJSONRPCErrorSchema: Contains id, jsonrpc, and nested error object schema.\nJSONRPCMessageSchema: A z.union of all possible top-level message schemas (Request, Notification, Response, Error). (Note: The draft spec removed batching, simplifying this).\nBaseRequestParamsSchema / BaseNotificationParamsSchema: Defines the optional _meta field, marked .passthrough().\n\n\nStrengths: Clear separation of schema definition (Zod) and static type (TS interface). Compile-time validation of schema usage. Fluent API for building complex types compositionally. .strict() enforces exact top-level structure while .passthrough() allows extensibility in params/result.\n\n2. Python (src/mcp/types.py) - Pydantic Models\n\nApproach: Uses Pydantic BaseModel subclasses, leveraging Python type hints. Requires explicit ConfigDict(extra=&quot;allow&quot;) on nearly every model due to MCP’s flexible params/result/_meta.\nCore Types:\n\nJSONRPC_VERSION: Literal[&quot;2.0&quot;] = &quot;2.0&quot;\nRequestId = str | int (Standard Python union type)\nRequest (Generic BaseModel): Defines method: MethodT, params: RequestParamsT. Includes model_config = ConfigDict(extra=&quot;allow&quot;).\nJSONRPCRequest (Inherits Request): Adds jsonrpc: Literal[JSONRPC_VERSION], id: RequestId.\nNotification / JSONRPCNotification: Similar structure, no id.\nResult (BaseModel): Defines optional meta: dict[str, Any] | None = Field(alias=&quot;_meta&quot;, ...). model_config = ConfigDict(extra=&quot;allow&quot;).\nJSONRPCResponse (BaseModel): Contains id, jsonrpc, result: dict[str, Any].\nJSONRPCError (BaseModel): Contains id, jsonrpc, error: ErrorData.\nJSONRPCMessage (RootModel[Union[...]]): Pydantic’s way to handle top-level discriminated unions based on message structure.\nRequestParams / NotificationParams (Base Models): Define optional meta: Meta | None = Field(alias=&quot;_meta&quot;, ...) with its own Meta BaseModel.\n\n\nStrengths: Uses native Python type hints and classes. Pydantic provides robust runtime validation. RootModel handles the top-level message discrimination. Explicit extra=&quot;allow&quot; clearly signals where extensibility is permitted.\n\n3. C# (src/ModelContextProtocol/Protocol/Messages/) - POCOs &amp; System.Text.Json\n\nApproach: Defines abstract base classes (JsonRpcMessage, JsonRpcMessageWithId) and concrete record/class types for each message. Uses [JsonPropertyName] for mapping and a custom [JsonConverter(typeof(JsonRpcMessageConverter))] on the base class for polymorphism. Relies on System.Text.Json (often with source generation via JsonContext).\nCore Types:\n\nJsonRpcMessage (Abstract class): Defines JsonRpc { get; init; } = &quot;2.0&quot;. Has [JsonConverter].\nJsonRpcMessageWithId (Abstract class, inherits JsonRpcMessage): Adds Id { get; init; }.\nJsonRpcRequest (Class, inherits JsonRpcMessageWithId): Adds Method, Params (often JsonNode?).\nJsonRpcNotification (Class, inherits JsonRpcMessage): Adds Method, Params (JsonNode?).\nJsonRpcResponse (Class, inherits JsonRpcMessageWithId): Adds Result (JsonNode?).\nJsonRpcError (Class, inherits JsonRpcMessageWithId): Adds Error (linking to JsonRpcErrorDetail record).\nJsonRpcErrorDetail (Record): Defines Code, Message, Data (object?).\nRequestId / ProgressToken: Structs wrapping object? with custom JsonConverter to handle string/number duality.\n(Note: Base RequestParams/Result with _meta aren’t strictly defined as separate base types but handled within specific message parameter/result types where needed).\n\n\nStrengths: Idiomatic C# using classes/records. required modifier enforces necessary fields. System.Text.Json is performant, especially with source generation (JsonContext defined in Utils/Json/McpJsonUtilities.cs). Custom converters provide flexibility (polymorphism, RequestId).\n\n4. Java (mcp/src/.../spec/McpSchema.java) - POJOs &amp; Jackson\n\nApproach: Defines most types as nested static records or sealed interfaces within a single McpSchema class. Heavy reliance on Jackson annotations (@JsonProperty, @JsonInclude, @JsonIgnoreProperties, @JsonTypeInfo, @JsonSubTypes).\nCore Types:\n\nJSONRPCMessage (Sealed Interface): Base marker.\nJSONRPCRequest (Record, implements JSONRPCMessage): jsonrpc, method, id (Object), params (Object). Annotations @JsonInclude(Include.NON_ABSENT), @JsonIgnoreProperties(ignoreUnknown = true).\nJSONRPCNotification (Record, implements JSONRPCMessage): Similar, no id.\nJSONRPCResponse (Record, implements JSONRPCMessage): jsonrpc, id (Object), result (Object), error (JSONRPCError).\nJSONRPCResponse.JSONRPCError (Nested Record): code, message, data (Object).\n(Note: Java SDK also defines base Request, Notification, Result interfaces, often used as markers or for generic constraints, but the concrete types usually define fields directly).\nRequestId / ProgressToken: Often represented directly as Object in records, requiring runtime checks or careful casting after deserialization, although custom serializers/deserializers could be used.\n\n\nStrengths: Uses standard Java records/interfaces. Jackson is powerful and highly configurable via annotations. @JsonIgnoreProperties(ignoreUnknown = true) is essential for MCP’s forward compatibility. @JsonSubTypes handles polymorphism well.\n\nComparing the Foundations\n\nPolymorphism (Top-Level Message):\n\nTS/Python: Handled by schema union (z.union / RootModel).\nC#: Custom JsonRpcMessageConverter.\nJava: Sealed interface JSONRPCMessage likely works with Jackson’s subtype deduction or a custom deserializer.\n\n\nExtensibility (params/result/_meta):\n\nTS: .passthrough() on nested Zod objects.\nPython: ConfigDict(extra=&quot;allow&quot;) explicitly on models.\nC#: Default System.Text.Json behavior often allows extra fields; can use [JsonExtensionData] for explicit capture if needed.\nJava: @JsonIgnoreProperties(ignoreUnknown = true) is the key annotation.\n\n\nOptionality/Nullability:\n\nTS: Zod .optional().\nPython: Standard | None type hint.\nC#: Nullable reference types (?).\nJava: Standard reference types are nullable. Jackson’s @JsonInclude(Include.NON_ABSENT) controls serialization.\n\n\nString/Number Unions (RequestId, ProgressToken):\n\nTS/Python: Native language union types + schema definitions.\nC#: Custom struct + JsonConverter.\nJava: Often uses base Object, requiring runtime type checking or casting.\n\n\nSchema Definition Location:\n\nTS/Python/C#: Types generally defined in dedicated files within logical namespaces/modules.\nJava: Concentrated within nested types inside McpSchema.java.\n\n\n\nNuances for Advanced Users\n\nStrictness vs. Extensibility: MCP requires extensibility in fields like params, result, _meta, and content blocks. All SDKs achieve this, but the mechanism differs (Zod .passthrough, Pydantic extra=&#039;allow&#039;, C# default behavior / JsonExtensionData, Jackson @JsonIgnoreProperties). Understanding where strictness is applied (e.g., top-level JSON-RPC fields in TS Zod’s .strict()) versus where extensibility is allowed is vital.\nFlexible Payloads (params/result): Handling variable params and result structures poses a challenge. TS/Python often use generic unknown/Any/Dict, requiring further validation in handlers. C# uses JsonNode?/JsonElement?, allowing structured access but still needing type-specific deserialization. Java often uses Object, necessitating runtime casting or deserialization within handlers. Type safety for specific request/response pairs is typically enforced at the handler registration level (e.g., C#‘s RequestHandlers.Set or TS’s setRequestHandler taking specific schemas).\nPerformance: C#‘s source-generated System.Text.Json context likely offers the best raw serialization/deserialization performance and minimal allocation, especially relevant for high-throughput servers or AOT compilation. Jackson (Java) is highly optimized. Zod and Pydantic add a validation layer which, while essential, introduces some overhead compared to purely generated serializers.\n\nConclusion\nThe foundation of MCP communication rests on JSON-RPC 2.0, and each SDK meticulously models these core message structures using idiomatic tools from its ecosystem. TypeScript leverages Zod’s explicit schemas and type inference. Python uses Pydantic’s type-hint-driven models. C# employs standard POCOs/records with System.Text.Json attributes and source generation. Java relies heavily on Jackson annotations and nested types.\nWhile the end result is interoperable JSON, the internal representations and the developer experience of defining and validating these base types differ significantly. Understanding these foundational choices is key to appreciating the subsequent design decisions made in the higher-level server and client APIs, which we will continue to explore in the next posts, starting with Blog 3: High-Level Server APIs.\n"},"3-Official-mcp-spec-tutes/Blogs/blog-3":{"slug":"3-Official-mcp-spec-tutes/Blogs/blog-3","filePath":"3 Official mcp spec tutes/Blogs/blog-3.md","title":"Blog 3: The Handshake - MCP Lifecycle and Capability Negotiation","links":[],"tags":[],"content":"Blog 3: The Handshake - MCP Lifecycle and Capability Negotiation\nSeries: Deep Dive into the Model Context Protocol SDKs\r\nPost: 3 of 12 (Advanced Topics)\nBefore any meaningful exchange of Tools, Resources, or Prompts can occur in the Model Context Protocol (MCP), the client and server must perform a crucial initialization handshake. This isn’t just about establishing a connection; it’s a formal negotiation defined by the MCP specification to ensure both parties speak the same protocol version and understand each other’s capabilities.\nThis post dissects the initialize / initialized flow, focusing on how the TypeScript, Python, C#, and Java SDKs implement this critical lifecycle phase and manage the crucial Capability Negotiation. Understanding this handshake is vital for debugging connection issues, ensuring compatibility, and controlling the features available during an MCP session.\nThe Initialization Sequence (MCP Spec Recap)\n\n\nClient → Server: initialize Request:\n\nThe first message sent by the client after the transport connection is established.\nMUST contain:\n\nprotocolVersion: The latest MCP spec version the client supports (e.g., &quot;2025-03-26&quot;).\nclientInfo: An Implementation object ({ name: string, version: string }).\ncapabilities: A ClientCapabilities object declaring what the client can do (e.g., handle sampling/createMessage, process roots/list_changed notifications).\n\n\nMUST NOT be part of a JSON-RPC batch.\n\n\n\nServer → Client: initialize Response (Result or Error):\n\nOn Success (result):\n\nprotocolVersion: The version the server chooses to use for this session. This MUST be a version the server supports and SHOULD be the version the client requested if possible, otherwise the latest version the server does support.\nserverInfo: The server’s Implementation object.\ncapabilities: A ServerCapabilities object declaring what the server can do (e.g., supports tools, resources with subscribe, prompts with listChanged, logging).\ninstructions (Optional): Human-readable hints for using the server.\n\n\nOn Error (error): If the server cannot proceed (e.g., unsupported client protocolVersion, invalid request), it sends a standard JSON-RPC error response.\n\n\n\nClient Validation: The client receives the initialize response.\n\nIt MUST check if it supports the protocolVersion chosen by the server. If not, it SHOULD disconnect.\nIt stores the server’s capabilities and serverInfo.\n\n\n\nClient → Server: initialized Notification:\n\nIf the client accepts the server’s response, it sends this parameter-less notification.\nSignals that the client is ready for normal operation using the negotiated version and capabilities.\n\n\n\nSession Active: Both sides can now send any requests/notifications allowed by the negotiated capabilities.\n\n\nSDK Implementations of the Handshake\nHow do the SDKs orchestrate this dance?\n1. TypeScript (Client.connect / Server handler):\n\nClient (Client.connect):\n\nCalled after new Client(...).\nTakes a Transport instance.\nInternally calls transport.start().\nAutomatically sends the initialize request using ClientInfo and Capabilities provided during Client construction (or defaults).\nWaits for the server’s response using the core Protocol.request logic.\nValidates the returned protocolVersion against SUPPORTED_PROTOCOL_VERSIONS. Throws an error and closes the transport if incompatible.\nStores serverInfo, serverCapabilities, serverInstructions on the Client instance.\nAutomatically sends the initialized notification.\nResolves the connect promise upon successful completion.\n\n\nServer (Server internal handler):\n\nThe low-level Server has a built-in handler for the initialize method (registered in its constructor).\nThis handler (_oninitialize in src/server/index.ts) receives the InitializeRequest.\nIt stores the clientInfo and clientCapabilities on the Server instance.\nIt determines the best compatible protocolVersion to use.\nIt constructs the InitializeResult using its own ServerInfo and Capabilities (provided during Server construction or via McpServer configuration).\nThe core Protocol layer sends the response back.\nIt also has a handler for initialized notification which triggers the optional oninitialized callback.\n\n\n\n2. Python (ClientSession.__aenter__ / ServerSession handler):\n\nClient (ClientSession.__aenter__ / initialize()):\n\nThe async with ClientSession(...) context manager automatically calls session.initialize() upon entering the block.\ninitialize() sends the initialize request using client_info and capabilities derived from constructor arguments (e.g., presence of sampling_callback).\nIt waits for the response, validates the protocolVersion against SUPPORTED_PROTOCOL_VERSIONS, raises RuntimeError on mismatch.\nStores server info/capabilities internally (less explicitly exposed via properties than TS client).\nSends the initialized notification.\nReturns the InitializeResult object.\n\n\nServer (ServerSession internal handler):\n\nThe internal _received_request method within ServerSession specifically checks if the request method is initialize.\nIf it is, it marks the session state as Initializing, stores the client_params (including capabilities and info), and constructs the InitializeResult based on the InitializationOptions passed when the ServerSession was created by the Server.\nIt sends the response.\nThe internal _received_notification method checks for InitializedNotification and updates the session state to Initialized, allowing subsequent requests/notifications.\n\n\n\n3. C# (McpClientFactory.CreateAsync / McpServer handler):\n\nClient (McpClientFactory.CreateAsync):\n\nThis factory method orchestrates the entire connection and initialization.\nIt takes an IClientTransport.\nCalls transport.ConnectAsync() to get an ITransport.\nCreates the internal McpClient/McpSession.\nAutomatically sends the initialize request using McpClientOptions (passed to the factory).\nWaits for the response, validates protocolVersion. Throws McpException or TimeoutException.\nStores server details (ServerInfo, ServerCapabilities, ServerInstructions) on the IMcpClient instance.\nAutomatically sends the initialized notification.\nReturns the fully connected and initialized IMcpClient.\n\n\nServer (McpServer internal handler):\n\nSimilar to TS, the internal McpServer sets up a handler for initialize (SetInitializeHandler).\nReceives the request, stores client info/caps.\nDetermines response protocolVersion.\nConstructs InitializeResult using configured McpServerOptions (often populated via DI builder extensions).\nSends the response.\nHandles initialized notification internally.\n\n\n\n4. Java (client.initialize() / McpServerSession handler):\n\nClient (McpAsync/SyncClient.initialize()):\n\nExplicitly called by the developer after the client object is built (McpClient.async/sync(...).build()).\nSends the initialize request using clientInfo and capabilities configured via the builder.\nWaits for the response (blocking in Sync, returning Mono&lt;InitializeResult&gt; in Async).\nValidates protocolVersion. Throws McpError on mismatch or other errors.\nStores server details internally.\nSends the initialized notification.\nReturns the InitializeResult object.\n\n\nServer (McpServerSession internal handler):\n\nThe handle(JSONRPCMessage) method within McpServerSession checks for InitializeRequest.\nIt performs state checks (must be first request), stores clientCapabilities/clientInfo, validates version, constructs InitializeResult based on the McpServerFeatures it was created with, and sends the response via its dedicated McpServerTransport.\nIt also handles the InitializedNotification to transition its internal state.\n\n\n\nCapability Negotiation in Practice\nThe capabilities objects exchanged during initialization are crucial dictionaries telling each side what the other side supports.\n\nClient Declares: Support for sampling, roots (and roots.listChanged).\nServer Declares: Support for tools, resources, prompts (and their respective listChanged flags), resources.subscribe, logging, completions (newer specs).\n\nHow SDKs Use Negotiated Capabilities:\n\nClient-Side Checks: Before sending a request like tools/call, a well-behaved client SDK should check if the stored serverCapabilities actually includes tools.\n\nTS/Python: The enforceStrictCapabilities option controls whether the base Protocol/BaseSession throws an error if a capability is missing on the server side before sending.\nC#/Java: This check seems less explicit in the core client methods; developers might need to check client.ServerCapabilities manually before calling certain methods if strict adherence is required.\n\n\nServer-Side Checks: Before sending a request like sampling/createMessage, the server SDK should check if the stored clientCapabilities includes sampling.\n\nTS/Python: enforceStrictCapabilities also controls checks for missing client capabilities before the server sends a request.\nC#/Java: The IMcpServer interface includes ClientCapabilities property. Server logic (especially within Tools/Prompts needing sampling or roots) should check this property. McpServerExtensions like AsSamplingChatClient (C#) perform this check internally.\n\n\n\nNuance: While the spec defines capabilities, ensuring SDKs consistently and correctly check them before all relevant operations can be challenging. The enforceStrictCapabilities flag in TS/Python acknowledges that older or simpler implementations might not perfectly advertise or check capabilities, offering a compatibility mode. C#/Java appear to rely more on developers performing explicit checks where needed.\nError Handling during Handshake\n\nVersion Mismatch: Server responds with its version, client disconnects if incompatible.\nInvalid Initialize Request: Server sends JSONRPCError (e.g., code -32600 Invalid Request).\nTimeout: Client or server times out waiting for initialize response or initialized notification (SDKs typically have specific InitializationTimeout settings).\nTransport Failure: Underlying transport fails during handshake (e.g., process fails to start in Stdio, HTTP connection error).\n\nConclusion: The Foundation of Trust\nThe MCP initialization handshake is more than just establishing a connection; it’s a critical negotiation that sets the stage for the entire session. It ensures both client and server agree on the protocol version and are aware of each other’s capabilities.\nAll four SDKs implement this lifecycle faithfully, albeit with slightly different orchestration:\n\nTypeScript and C# largely automate the handshake within their connect/CreateAsync methods.\nPython and Java require an explicit initialize() call after creating the client session object.\n\nUnderstanding how capabilities are declared (DI/Attributes in C#, Builder/Options in TS/Java/Python) and how they are checked (explicitly by developers or implicitly by the SDK with flags like enforceStrictCapabilities) is vital for advanced users building interoperable and robust MCP applications. This handshake ensures that subsequent interactions only use features that both parties have agreed to support, forming the foundation of trust for the complex operations MCP enables.\nNext, we’ll dive back into the server internals, specifically focusing on how requests are dispatched to the correct handlers once the session is active.\n"},"3-Official-mcp-spec-tutes/Blogs/blog-4":{"slug":"3-Official-mcp-spec-tutes/Blogs/blog-4","filePath":"3 Official mcp spec tutes/Blogs/blog-4.md","title":"Blog 4: Exposing Actions - The Tool Primitive: Spec vs. Implementation Across MCP SDKs","links":["3-Official-mcp-spec-tutes/Blogs/blog-1","3-Official-mcp-spec-tutes/Blogs/blog-2","3-Official-mcp-spec-tutes/Blogs/blog-3"],"tags":[],"content":"Blog 4: Exposing Actions - The Tool Primitive: Spec vs. Implementation Across MCP SDKs\nSeries: Deep Dive into the Model Context Protocol SDKs (Advanced Topics)\r\nPost: 4 of 12\nHaving established the protocol’s blueprint, the core language, and the vital initialization handshake, we now turn to the most dynamic of the Model Context Protocol (MCP) primitives: Tools.\nTools are the mechanism by which MCP servers expose executable actions to clients and, crucially, to the Language Models (LLMs) interacting through those clients. They transform MCP from a context-sharing protocol into an action-enabling one, allowing AI to query databases, call external APIs, manipulate files, control devices, or perform virtually any computational task the server developer exposes.\nThis post targets advanced users by dissecting the Tool primitive, comparing its definition in the MCP specification with its concrete implementation across the TypeScript, Python, C#, and Java SDKs. We’ll examine:\n\nTool Definition: Metadata (name, description), Input Schema (inputSchema), and Annotations (annotations).\nRegistration Mechanisms: How developers register tool logic within each SDK (Methods, Decorators, Attributes, Specifications).\nInput Validation: How argument schemas are defined and enforced.\nExecution Context: Accessing session state, server capabilities, and DI services within tool handlers.\nResult &amp; Error Handling: Returning structured content or signaling execution failures.\n\nThe Tool Specification: Blueprint for Action\nThe MCP specification defines a Tool object communicated during the tools/list exchange:\n// Simplified Spec Definition\n{\n  &quot;name&quot;: &quot;string (unique identifier)&quot;,\n  &quot;description&quot;: &quot;string (natural language for LLM/user)&quot;,\n  &quot;inputSchema&quot;: {\n    &quot;type&quot;: &quot;object&quot;,\n    &quot;properties&quot;: { /* JSON Schema for arguments */ },\n    &quot;required&quot;: [ /* list of required property names */ ]\n  },\n  &quot;annotations&quot;: { /* Optional hints: title, readOnlyHint, etc. */ }\n}\nAnd the interaction flow:\n\ntools/list: Client discovers available Tools and their schemas.\ntools/call: Client (often prompted by an LLM) invokes a tool by name, providing arguments matching the inputSchema.\nServer Response (CallToolResult): Contains content (a list of TextContent, ImageContent, AudioContent, or EmbeddedResource) and an isError flag.\n\nThe core challenge for SDKs is providing an ergonomic way for developers to define the tool’s logic and automatically generate/manage the corresponding metadata and schema, while handling the request/response flow.\nSDK Implementations: Defining and Handling Tools\n1. TypeScript (McpServer.tool()): Explicit Schemas, Typed Handlers\n\nDefinition: Uses the mcpServer.tool() method. Requires explicit Zod object schema (inputSchema) for arguments. Optional description and annotations are passed as arguments.\nSchema: Defined using Zod (z.object({...})). Descriptions added via .describe().\nHandler: An async function receiving a type-safe args object (inferred from the Zod schema via generics) and the RequestHandlerExtra context object.\nValidation: Zod schema validation is performed automatically by the McpServer before the handler is called. Invalid arguments result in an InvalidParams JSON-RPC error response sent by the SDK.\nContext: Accessed via the RequestHandlerExtra parameter (signal, sessionId, requestId, authInfo, sendNotification, etc.).\nResult/Error: Handler must return Promise&lt;CallToolResult&gt;. Exceptions are caught by McpServer and converted to CallToolResult { isError: true }.\n\n// TypeScript Tool Definition\nconst argsSchema = z.object({ query: z.string().describe(&quot;Search query&quot;) });\nmcpServer.tool&lt;typeof argsSchema&gt;(\n  &quot;web_search&quot;,\n  &quot;Performs a web search&quot;,\n  argsSchema, // Explicit Zod schema\n  { readOnlyHint: true }, // Annotations\n  async (args, extra): Promise&lt;CallToolResult&gt; =&gt; {\n    extra.signal.throwIfAborted(); // Check cancellation\n    const results = await performWebSearch(args.query);\n    await extra.sendNotification({ /* ... logging ... */});\n    return { content: [{ type: &quot;text&quot;, text: JSON.stringify(results) }] };\n  }\n);\n2. Python (@mcp.tool()): Decorators, Type Hint Inference\n\nDefinition: Uses the @mcp.tool() decorator on a standard Python function (sync or async). name defaults to function name, description to docstring.\nSchema: Inferred automatically from function parameter type hints using Pydantic internally (func_metadata). Pydantic Field or Annotated provide descriptions/defaults.\nHandler: The decorated function itself. Receives validated arguments directly.\nValidation: Performed automatically by the underlying tool runner logic (Tool.run via fn_metadata.call_fn_with_arg_validation). Handles basic type coercion and JSON string parsing. Validation errors result in a ToolError caught by FastMCP, returning CallToolResult { isError: true }.\nContext: Optional injection via ctx: Context type hint. Provides high-level helpers (.info, .report_progress).\nResult/Error: Handler can return various types (str, list, dict, model, Image, Content), automatically converted by FastMCP to CallToolResult.content. Exceptions are caught and converted to isError: true results.\n\n# Python Tool Definition\nfrom mcp.server.fastmcp import FastMCP, Context\nfrom pydantic import Field\nfrom typing import Annotated\n \nmcp = FastMCP(&quot;PyServer&quot;)\n \n@mcp.tool()\nasync def web_search_py(\n    query: Annotated[str, Field(description=&quot;Search query&quot;)],\n    ctx: Context\n) -&gt; list[dict]: # Return type helps schema but primarily for documentation here\n    &quot;&quot;&quot;Performs a web search (docstring description).&quot;&quot;&quot;\n    ctx.info(f&quot;Searching for: {query}&quot;)\n    # ctx.signal not directly exposed, cancellation handled internally?\n    results = await performWebSearch(query) # Assume async search function\n    return results # Returns list of dicts, converted to text content JSON\n3. C# ([McpServerTool]): Attributes, DI, AIFunction\n\nDefinition: Uses [McpServerTool] attribute on static or instance methods within a class marked [McpServerToolType]. Name, Description, and ToolAnnotations (ReadOnly, Destructive, etc.) are properties on the attribute.\nSchema: Generated internally by AIFunctionFactory based on method parameter reflection (excluding context/DI params). Parameter descriptions use [Description] attribute.\nHandler: The attributed method itself.\nValidation: Performed automatically by the AIFunction invocation mechanism using the generated schema. Validation failures likely surface as exceptions caught by the AIFunctionMcpServerTool wrapper.\nContext: Injected as method parameters: IMcpServer, RequestContext&lt;CallToolRequestParams&gt;, CancellationToken, IProgress&lt;&gt;, IServiceProvider, plus other services via DI.\nResult/Error: Handler can return various types (string, Content, AIContent, IEnumerable&lt;&gt; thereof, CallToolResponse), automatically converted by AIFunctionMcpServerTool wrapper. Exceptions are caught and converted to isError: true results.\n\n// C# Tool Definition\nusing ModelContextProtocol.Server;\nusing System.ComponentModel;\nusing Microsoft.Extensions.AI; // For AIContent\n \n[McpServerToolType]\npublic class SearchTools(HttpClient httpClient) // Constructor DI\n{\n    [McpServerTool(Name = &quot;web_search_cs&quot;, ReadOnly = true)]\n    [Description(&quot;Performs a web search (attribute description)&quot;)]\n    public async Task&lt;List&lt;AIContent&gt;&gt; WebSearch( // Can return AIContent directly\n        RequestContext&lt;CallToolRequestParams&gt; context,\n        [Description(&quot;Search query&quot;)] string query,\n        CancellationToken cancellationToken)\n    {\n        cancellationToken.ThrowIfCancellationRequested(); // Manual cancellation check\n        var results = await performWebSearch(httpClient, query); // Uses injected HttpClient\n        await context.Server.SendNotificationAsync(/* ... logging ... */);\n        return results.Select(r =&gt; new TextContent(r)).ToList&lt;AIContent&gt;();\n    }\n}\n4. Java (Async/SyncToolSpecification): Explicit Specs, Exchange Object\n\nDefinition: Requires creating a Tool record (with name, description, inputSchema as a JSON string or Map) and pairing it with a handler BiFunction within an Async/SyncToolSpecification. These specs are passed to the McpServer builder.\nSchema: Developer must provide the JSON Schema definition manually when creating the Tool record.\nHandler: A BiFunction taking McpAsync/SyncServerExchange and Map&lt;String, Object&gt; (raw arguments).\nValidation: Not automatically performed by the core SDK before calling the handler. The handler receives the raw Map and is responsible for validating it against the schema provided in the Tool metadata (likely using Jackson’s schema validation features if desired).\nContext: Accessed via the McpAsync/SyncServerExchange object (first parameter to the handler), providing methods like .loggingNotification(), .getClientCapabilities(), etc. Access to the underlying McpServerSession allows sending arbitrary notifications/requests.\nResult/Error: Handler must explicitly return a CallToolResult (Sync) or Mono&lt;CallToolResult&gt; (Async). It must manually catch its own exceptions and construct an isError: true result if needed. Uncaught exceptions may terminate the session processing.\n\n// Java Tool Definition\nBiFunction&lt;McpAsyncServerExchange, Map&lt;String, Object&gt;, Mono&lt;CallToolResult&gt;&gt; searchHandler =\n    (exchange, args) -&gt; Mono.defer(() -&gt; {\n        // Manual validation recommended here using args and toolMeta.inputSchema()\n        String query = (String) args.get(&quot;query&quot;);\n        if (query == null) {\n            return Mono.just(new CallToolResult(List.of(new TextContent(&quot;Missing query&quot;)), true));\n        }\n        // Access context: exchange.loggingNotification(...); exchange.getSessionId();\n        // Check cancellation: exchange.getCancellationToken().isCancellationRequested()\n        return performWebSearchAsync(query) // Assume returns Mono&lt;List&lt;String&gt;&gt;\n            .map(results -&gt; new CallToolResult(\n                results.stream().map(r -&gt; (Content) new TextContent(r)).collect(Collectors.toList()),\n                false // Explicitly set isError\n            ))\n            .onErrorResume(e -&gt; Mono.just(\n                new CallToolResult(List.of(new TextContent(e.getMessage())), true) // Manual error result\n            ));\n    });\n \nString schemaJson = &quot;{\\&quot;type\\&quot;:\\&quot;object\\&quot;, \\&quot;properties\\&quot;: {\\&quot;query\\&quot;: {\\&quot;type\\&quot;:\\&quot;string\\&quot;}}, \\&quot;required\\&quot;:[\\&quot;query\\&quot;]}&quot;;\nTool searchToolMeta = new Tool(&quot;web_search_java&quot;, &quot;Performs web search&quot;, schemaJson);\nAsyncToolSpecification searchSpec = new AsyncToolSpecification(searchToolMeta, searchHandler);\n \n// Register with builder\nMcpServer.async(provider).tools(searchSpec).build();\nAdvanced Considerations Synthesized\n\nSchema Definition &amp; Validation: TS/Python/C# offer more integrated approaches where the schema is derived from or linked directly to the code signature, enabling automatic validation before the handler runs. Java requires manual schema provision and validation within the handler is the developer’s responsibility in the core SDK.\nBoilerplate: Python’s decorators are the most concise. Java’s Specification objects require the most boilerplate. TS and C# fall in between.\nContext Provision: Python’s Context injection and C#‘s DI parameter injection are arguably the most ergonomic for accessing contextual features or dependencies. Java’s Exchange object and TS’s RequestHandlerExtra are functional but slightly less direct.\nResult Handling: Python’s automatic conversion of various return types is highly convenient. C# also handles several common types well. TS and Java require more explicit construction of the CallToolResult object.\nError Handling: TS, Python, and C# wrappers provide automatic conversion of uncaught exceptions to isError: true results. Java handlers must generally manage their own exceptions and construct the error result manually.\nDynamic Updates: Only the TS SDK provides a clear high-level API (via RegisteredTool handles) for modifying tools post-connection. Others require interacting with lower-level mechanisms or manual notification sending.\nAnnotations: TS and C# attributes allow specifying ToolAnnotations declaratively alongside the tool definition. Python and Java require manual creation and association if needed (though not shown in Java’s core Spec objects).\n\nConclusion: Matching Tooling to Task and Team\nExposing application logic as MCP Tools is a powerful way to enhance AI capabilities. Each SDK provides viable mechanisms, but with distinct trade-offs suiting different developer preferences and project needs:\n\nTypeScript: Best for explicit control, strong typing via Zod, integrated annotations, and dynamic updates. Requires clear schema definition.\nPython: Offers the most rapid development experience with FastMCP decorators, type-hint inference, and flexible result conversion. Ideal for wrapping existing Python code.\nC#: Excels in DI integration, leveraging attributes for discovery and configuration, and integrating seamlessly with Microsoft.Extensions.AI. Provides robust type safety and performance.\nJava: Provides clear Sync/Async separation and targeted Spring/Servlet integration. Requires more explicit configuration via Specification objects and manual error/result construction in handlers.\n\nAdvanced developers choosing an SDK for complex tool implementation should weigh the importance of automatic schema generation/validation, ease of dependency injection, required transport features (resumability), and the desired level of explicitness versus convention in their server definition. Understanding these nuances ensures the selection of the SDK best aligned with the project’s technical requirements and the development team’s workflow.\n"},"3-Official-mcp-spec-tutes/Blogs/blog-6":{"slug":"3-Official-mcp-spec-tutes/Blogs/blog-6","filePath":"3 Official mcp spec tutes/Blogs/blog-6.md","title":"Blog 6: Guiding Interactions - The Prompt Primitive Across MCP SDKs","links":["3-Official-mcp-spec-tutes/Blogs/blog-2","3-Official-mcp-spec-tutes/Blogs/blog-3","3-Official-mcp-spec-tutes/Blogs/blog-4","3-Official-mcp-spec-tutes/Blogs/blog-5","3-Official-mcp-spec-tutes/Blogs/blog-1.md1"],"tags":[],"content":"Blog 6: Guiding Interactions - The Prompt Primitive Across MCP SDKs\nSeries: Deep Dive into the Model Context Protocol SDKs (Advanced Topics)\r\nPost: 6 of 12\nIn our ongoing deep dive into the Model Context Protocol (MCP) SDKs, we’ve analyzed the core protocol (Blog 2), server architecture (Blog 3, Blog 4), client APIs (Blog 5), and the action-oriented Tool primitive. Now, we examine another crucial server feature: Prompts.\nWhile Tools allow AI models to act, Prompts provide predefined templates and workflows designed primarily for user control. They act as standardized starting points for common interactions, often surfaced in client UIs as slash commands, buttons, or menu items. Unlike Resources (application-controlled data) or Tools (model-controlled actions), Prompts guide the initiation of a specific task or conversation flow, potentially involving arguments supplied by the user.\nThis post targets advanced developers, comparing how the MCP Prompt specification is implemented across the TypeScript, Python, C#, and Java SDKs. We’ll explore:\n\nPrompt Definition: Metadata (name, description) and Argument (arguments) specification.\nRegistration: How prompt logic is registered (Methods, Decorators, Attributes, Specifications).\nArgument Handling: Schema definition, validation, and binding to handler parameters.\nMessage Generation: Handler return types and conversion to PromptMessage lists containing various Content types (including EmbeddedResource).\nDiscovery &amp; Retrieval: The prompts/list and prompts/get flow.\nAdvanced Features: Argument completion (where available).\n\nThe Prompt Specification: Templated Interactions\nThe MCP specification defines a Prompt metadata object and a prompts/get request/response flow.\n\nPrompt Metadata: Advertised via prompts/list, includes:\n\nname: Unique identifier.\ndescription: For UI/LLM understanding.\narguments (Optional): A list of PromptArgument objects (name, description, required) defining parameters the prompt accepts.\n\n\nprompts/get Request: Client requests a prompt by name, providing user-supplied arguments as a string dictionary.\nGetPromptResult Response: Server returns:\n\ndescription (Optional).\nmessages: A list of PromptMessage objects (role, content).\n\n\nPromptMessage.content: Can be TextContent, ImageContent, AudioContent, or EmbeddedResource.\n\nThe core idea is that the client fetches the prompt structure (often based on user action), providing arguments, and the server returns the initial set of messages to kick off the interaction with the LLM.\nSDK Implementations: Defining and Handling Prompts\n1. TypeScript (McpServer.prompt()): Explicit Schemas, Structured Results\n\nDefinition: Uses mcpServer.prompt() method. Takes name, optional description, an optional explicit Zod object schema (argsSchema) for arguments, and the handler callback.\nArgument Schema: Defined using Zod (z.object({...})). Completable wrapper (completable(z.string(), ...)) can be used for arguments needing autocompletion.\nHandler: An async function receiving a type-safe args object (inferred from Zod schema) and the RequestHandlerExtra context.\nValidation: Zod schema validation performed automatically by McpServer before calling the handler.\nResult Handling: Handler must return Promise&lt;GetPromptResult&gt;, explicitly constructing the { messages: [...] } structure containing PromptMessage objects. No automatic conversion from simpler types.\nDiscovery/Retrieval: McpServer automatically handles prompts/list (generating PromptArgument metadata from Zod schema) and prompts/get (finding handler, validating args, calling handler).\n\n// TypeScript Prompt Definition\nimport { McpServer } from &quot;@modelcontextprotocol/sdk/server/mcp.js&quot;;\nimport { z } from &quot;zod&quot;;\nimport { completable } from &quot;@modelcontextprotocol/sdk/server/completable.js&quot;;\nimport { GetPromptResult, PromptMessage } from &quot;@modelcontextprotocol/sdk/types.js&quot;;\n \nconst mcpServer = new McpServer(/* ... */);\n \nconst reviewArgsSchema = z.object({\n  filePath: completable(z.string(), async (partial) =&gt; findFiles(partial)) // Autocomplete file paths\n              .describe(&quot;Path to the code file&quot;),\n  focusArea: z.enum([&quot;performance&quot;, &quot;security&quot;, &quot;style&quot;]).optional()\n});\n \nmcpServer.prompt&lt;typeof reviewArgsSchema&gt;(\n  &quot;review_code_ts&quot;,\n  &quot;Generate prompt for code review&quot;,\n  reviewArgsSchema, // Explicit Zod schema\n  async (args, extra): Promise&lt;GetPromptResult&gt; =&gt; {\n    const fileContent = await readFileContent(args.filePath); // Assume helper function\n    const messages: PromptMessage[] = [\n      { role: &quot;user&quot;, content: { type: &quot;text&quot;, text: `Review this file: ${args.filePath}` } },\n      {\n        role: &quot;user&quot;,\n        content: {\n          type: &quot;resource&quot;, // Embed the file content\n          resource: { uri: `file://${args.filePath}`, text: fileContent, mimeType: &#039;text/plain&#039; }\n        }\n      }\n    ];\n    if (args.focusArea) {\n      messages.push({ role: &quot;user&quot;, content: { type: &quot;text&quot;, text: `Focus on ${args.focusArea}.` } });\n    }\n    return { description: &quot;Code review prompt&quot;, messages }; // Explicit GetPromptResult\n  }\n);\n2. Python (@mcp.prompt()): Decorators, Flexible Returns\n\nDefinition: Uses @mcp.prompt() decorator on a function. name defaults to function name, description to docstring.\nArgument Schema: Inferred from function parameter type hints (using Pydantic). Field or Annotated add metadata.\nHandler: The decorated function. Receives validated arguments. Optional Context injection.\nValidation: Automatic via Pydantic model derived from signature.\nResult Handling: Highly flexible. Handler can return:\n\nstr (→ single UserMessage with TextContent)\nmcp.server.fastmcp.prompts.base.Message (User/Assistant)\ndict (parsed as Message)\nSequence of the above.\r\nFastMCP automatically converts these into the required GetPromptResult containing PromptMessages.\n\n\nDiscovery/Retrieval: FastMCP automatically handles prompts/list (deriving arguments from signature) and prompts/get.\n\n# Python Prompt Definition\nfrom mcp.server.fastmcp import FastMCP\nfrom mcp.server.fastmcp.prompts.base import UserMessage, AssistantMessage, EmbeddedResource, TextResourceContents\nfrom typing import Annotated\nfrom pydantic import Field, FilePath\n \nmcp = FastMCP(&quot;PyServer&quot;)\n \n@mcp.prompt()\nasync def review_code_py(\n    file_path: Annotated[FilePath, Field(description=&quot;Path to code file&quot;)], # Use FilePath type\n    focus_area: Annotated[str | None, Field(description=&quot;Area to focus on&quot;)] = None\n) -&gt; list[Message]: # Return list of Message objects\n    &quot;&quot;&quot;Generates a code review prompt (docstring description).&quot;&quot;&quot;\n    # file_content = await read_file_async(file_path) # Assume helper\n    file_content = &quot;def hello(): pass&quot;\n    messages = [\n        UserMessage(f&quot;Review this file: {file_path}&quot;),\n        UserMessage(EmbeddedResource(type=&quot;resource&quot;, resource=TextResourceContents(\n            uri=f&quot;file://{file_path}&quot;, text=file_content, mimeType=&#039;text/plain&#039;\n        )))\n    ]\n    if focus_area:\n        messages.append(UserMessage(f&quot;Focus on {focus_area}.&quot;))\n    messages.append(AssistantMessage(&quot;Understood. Analyzing the code now...&quot;))\n    return messages # SDK converts this list to GetPromptResult\n3. C# ([McpServerPrompt]): Attributes, DI, Various Return Types\n\nDefinition: Uses [McpServerPrompt] attribute on methods within [McpServerPromptType] classes. Name and Description from attributes or reflection.\nArgument Schema: Inferred using AIFunctionFactory from method parameters (excluding DI/context params). [Description] attribute used for parameter descriptions.\nHandler: The attributed method. Can receive dependencies via DI.\nValidation: Automatic via AIFunction invocation mechanism.\nResult Handling: Flexible. Handler can return GetPromptResult, string, PromptMessage, IEnumerable&lt;PromptMessage&gt;, ChatMessage, or IEnumerable&lt;ChatMessage&gt;. The AIFunctionMcpServerPrompt wrapper converts these to the final GetPromptResult.\nDiscovery/Retrieval: Handled automatically by the configured McpServer based on registered McpServerPrompt instances (often discovered via DI extensions like WithPromptsFromAssembly).\n\n// C# Prompt Definition\nusing ModelContextProtocol.Server;\nusing System.ComponentModel;\nusing Microsoft.Extensions.AI; // For ChatMessage\nusing ModelContextProtocol.Protocol.Types; // For PromptMessage, Content etc.\n \n[McpServerPromptType]\npublic class ReviewPrompts(IFileSystemService fileService) // Constructor DI\n{\n    [McpServerPrompt(Name = &quot;review_code_cs&quot;)]\n    [Description(&quot;Generates a code review prompt&quot;)]\n    public async Task&lt;List&lt;ChatMessage&gt;&gt; GenerateReviewPrompt( // Returns ChatMessage list\n        RequestContext&lt;GetPromptRequestParams&gt; context, // MCP Context\n        [Description(&quot;Path to the code file&quot;)] string filePath,\n        [Description(&quot;Optional focus area&quot;)] string? focusArea = null)\n    {\n        var fileContent = await fileService.ReadFileAsync(filePath, context.RequestAborted);\n        var messages = new List&lt;ChatMessage&gt;\n        {\n            new(ChatRole.User, $&quot;Review this file: {filePath}&quot;),\n            new(ChatRole.User, new TextContent(fileContent)) // Simple text embedding\n            // Could also construct PromptMessage with EmbeddedResource for richer context\n        };\n        if (!string.IsNullOrEmpty(focusArea))\n        {\n            messages.Add(new(ChatRole.User, $&quot;Focus on {focusArea}.&quot;));\n        }\n        return messages; // SDK wrapper converts to GetPromptResult\n    }\n}\n4. Java (PromptSpecification): Explicit Specs, Structured Results\n\nDefinition: Requires creating a Prompt record (metadata including manually defined List&lt;PromptArgument&gt;) and pairing it with a handler BiFunction in an Async/SyncPromptSpecification, passed to the McpServer builder.\nArgument Schema: Manually defined when creating the Prompt metadata record.\nHandler: A BiFunction taking McpAsync/SyncServerExchange and GetPromptRequest, returning GetPromptResult (Sync) or Mono&lt;GetPromptResult&gt; (Async).\nValidation: Responsibility of the handler function to validate arguments from the GetPromptRequest.arguments() map against the defined schema.\nResult Handling: Handler must explicitly construct and return the GetPromptResult object containing PromptMessages.\nDiscovery/Retrieval: Handled by the core McpServerSession using registered listPromptsHandler and getPromptHandler (which were populated by the builder based on the provided specifications).\n\n// Java Prompt Definition\nimport io.modelcontextprotocol.server.*;\nimport io.modelcontextprotocol.spec.McpSchema.*;\nimport reactor.core.publisher.Mono;\nimport java.util.List;\nimport java.util.Map;\n \nPrompt reviewPromptMeta = new Prompt(\n    &quot;review_code_java&quot;,\n    &quot;Generates review prompt&quot;,\n    List.of(\n        new PromptArgument(&quot;filePath&quot;, &quot;Path to file&quot;, true),\n        new PromptArgument(&quot;focusArea&quot;, &quot;Focus area&quot;, false)\n    )\n);\n \n// Async Handler Function\nBiFunction&lt;McpAsyncServerExchange, GetPromptRequest, Mono&lt;GetPromptResult&gt;&gt; asyncHandler =\n    (exchange, req) -&gt; Mono.defer(() -&gt; {\n        // Manual Argument Validation Needed Here!\n        Map&lt;String, String&gt; args = req.arguments() != null ? req.arguments() : Map.of();\n        String filePath = args.get(&quot;filePath&quot;);\n        if (filePath == null) {\n            return Mono.error(new McpError(&quot;Missing required argument: filePath&quot;));\n        }\n        String focusArea = args.get(&quot;focusArea&quot;);\n        // String fileContent = readFileAsync(filePath); // Assume helper\n \n        List&lt;PromptMessage&gt; messages = new ArrayList&lt;&gt;();\n        messages.add(new PromptMessage(Role.USER, new TextContent(&quot;Review: &quot; + filePath)));\n        // messages.add(new PromptMessage(Role.USER, new EmbeddedResource(...)));\n        if (focusArea != null) {\n            messages.add(new PromptMessage(Role.USER, new TextContent(&quot;Focus: &quot; + focusArea)));\n        }\n \n        return Mono.just(new GetPromptResult(&quot;Code review prompt&quot;, messages)); // Explicit result\n    });\n \nAsyncPromptSpecification reviewSpec = new AsyncPromptSpecification(reviewPromptMeta, asyncHandler);\n \n// Register with builder\nMcpServer.async(provider).prompts(reviewSpec).build();\nSynthesis: Defining and Using Prompts\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFeatureTypeScriptPython (FastMCP)C#JavaDefinitionMcpServer.prompt()@mcp.prompt() decorator[McpServerPrompt] attributePromptSpecification + BuilderArg SchemaExplicit ZodInferred from Type HintsInferred from Method SignatureManual List&lt;PromptArgument&gt;Arg ValidationAutomatic (Zod)Automatic (Pydantic)Automatic (AIFunction)Manual (in Handler)Handler ContextRequestHandlerExtraContext (Injected)DI Params + RequestContextExchange objectReturn TypePromise&lt;GetPromptResult&gt;Flexible (str, Msg, list…)Flexible (str, Msg, list…)GetPromptResult/Mono&lt;GetPromptResult&gt;Result ConvertManualAutomaticAutomaticManualArg CompletionYes (Completable)NoNoNoDiscoveryAutomatic (prompts/list)Automatic (prompts/list)Automatic (prompts/list)Via listPromptsHandler specRetrievalAutomatic (prompts/get)Automatic (prompts/get)Automatic (prompts/get)Via getPromptHandler spec\nKey Observations:\n\nErgonomics: Python’s FastMCP offers the most concise definition and flexible return types. C#‘s attribute-based approach with DI is also quite clean. TypeScript requires explicit schemas and result construction. Java is the most verbose, requiring manual metadata and result construction.\nValidation: TS, Python, and C# provide automatic argument validation based on the schema/signature, reducing boilerplate in the handler. Java handlers must perform validation manually.\nContent Flexibility: All SDKs support TextContent, ImageContent, AudioContent (except Python currently?), and EmbeddedResource within the PromptMessage.content. Embedding resources is powerful for providing rich context directly within the prompt flow.\nAutocompletion: Only the TypeScript SDK has built-in support for providing completion suggestions for prompt arguments.\n\nAdvanced Use Cases &amp; Nuances\n\nEmbedding Resources: All SDKs allow returning PromptMessages with EmbeddedResource content. This is powerful for including file content, database results, or other server-managed data directly in the prompt sent to the LLM, without the client needing to perform a separate resources/read. The server handler constructs the Text/BlobResourceContents object.\nMulti-Turn Prompts: Handlers can return multiple PromptMessage objects, including alternating user and assistant roles, to set up a specific conversational flow or provide few-shot examples.\nDynamic Prompt Generation: Since the handler logic runs on prompts/get, servers can dynamically generate prompt content based on arguments, current application state, or external data sources.\nContextual Prompts: Prompt handlers can access session or lifespan context (via Extra, Context, DI, Exchange) to tailor prompts based on the specific user or session state.\n\nConclusion: Structuring User-Initiated AI Interactions\nPrompts are the MCP primitive for user-controlled interaction templates. They bridge the gap between specific user commands (like slash commands) and structured input for LLMs.\n\nPython (FastMCP) provides the most developer-friendly experience for defining prompts due to its decorators, type inference, and flexible return types.\nC# offers a strong, type-safe alternative closely tied to the .NET DI ecosystem and attributes.\nTypeScript requires more explicit schema definition (Zod) and result construction but benefits from built-in argument autocompletion.\nJava is the most explicit, requiring manual definition of metadata and arguments, handler validation, and result construction, but offers clear separation and framework adapters.\n\nChoosing the right SDK depends on the preferred level of abstraction and integration needs. Regardless of the SDK, well-designed Prompts, potentially incorporating EmbeddedResources, are key to creating intuitive and powerful user-driven workflows powered by MCP and LLMs.\n"},"3-Official-mcp-spec-tutes/Blogs/blog-7":{"slug":"3-Official-mcp-spec-tutes/Blogs/blog-7","filePath":"3 Official mcp spec tutes/Blogs/blog-7.md","title":"Blog 7: When the Server Asks - Client Capabilities (Sampling & Roots) Across MCP SDKs","links":["3-Official-mcp-spec-tutes/Blogs/blog-1.md1","3-Official-mcp-spec-tutes/Blogs/blog-1.md2","3-Official-mcp-spec-tutes/Blogs/blog-6","3-Official-mcp-spec-tutes/Blogs/blog-3"],"tags":[],"content":"Blog 7: When the Server Asks - Client Capabilities (Sampling &amp; Roots) Across MCP SDKs\nSeries: Deep Dive into the Model Context Protocol SDKs (Advanced Topics)\r\nPost: 7 of 12\nThus far in our advanced series on the Model Context Protocol (MCP) SDKs, we’ve primarily examined features where the server provides capabilities (like Tools, Resources, and Prompts) for the client to consume. However, MCP is bidirectional. There are specific capabilities where the roles are reversed: the client exposes functionality or information that the server can request.\nThis post delves into the two primary client-side capabilities defined in the MCP specification:\n\nSampling (sampling/createMessage): Allowing a server to request an LLM completion from the client.\nRoots (roots/list, notifications/roots/list_changed): Allowing a server to discover relevant filesystem entry points defined by the client/host application.\n\nWe’ll analyze how these capabilities are declared, implemented, and handled across the TypeScript, Python, C#, and Java SDKs, focusing on the nuances relevant to advanced developers and researchers.\nThe Inversion of Control: Why Client Capabilities?\nThese features represent an inversion of the typical client-server relationship:\n\nSampling: Enables “agentic” servers. A server handling a complex task might need LLM reasoning to proceed but may not have direct LLM access itself (due to cost, security, or architecture). It can delegate the LLM call back to the client (which likely does have configured LLM access), potentially incorporating context gathered by the server. This also keeps user control central, as the client application (Host) typically intermediates the sampling request for user approval.\nRoots: Allows servers (especially those interacting with local filesystems, like linters, indexers, or build tools) to understand the user’s relevant working directories or project scopes without needing hardcoded paths or complex configuration on the server side. The client/host application defines the relevant scope.\n\nDeclaring Client Capabilities\nLike servers, clients declare their supported capabilities during the initialization handshake.\n\nSpecification (ClientCapabilities):\n{\n  &quot;capabilities&quot;: {\n    &quot;sampling&quot;: {}, // Presence indicates support\n    &quot;roots&quot;: {\n      &quot;listChanged&quot;: true // Optional: Client will notify on changes\n    },\n    &quot;experimental&quot;: { /* ... */ }\n  }\n}\n\nTypeScript (new Client(..., options)): Capabilities passed in the options object during client construction.\nconst client = new Client(clientInfo, {\n  capabilities: {\n    sampling: { /* Potentially config, but just presence needed */ },\n    roots: { listChanged: true }\n  }\n});\n\nPython (McpClient.async/sync(...).capabilities(...)): Set via the builder pattern. Specific handlers are passed separately.\nclient = McpClient.async(transport)\n            .capabilities(ClientCapabilities.builder()\n                .sampling()\n                .roots(list_changed=True)\n                .build())\n            # .sampling(sampling_callback) # Handler passed separately\n            # .list_roots(list_roots_callback)\n            # ...\n            .build()\n\nC# (McpClientOptions): Set via the Capabilities property on McpClientOptions, which is passed to McpClientFactory.CreateAsync. Handlers are properties within the capability objects (SamplingCapability.SamplingHandler, RootsCapability.RootsHandler).\nvar options = new McpClientOptions {\n    Capabilities = new() {\n        Sampling = new() { SamplingHandler = MySamplingHandlerAsync },\n        Roots = new() { ListChanged = true, RootsHandler = MyRootsHandlerAsync }\n    }\n    // ... other options\n};\nIMcpClient client = await McpClientFactory.CreateAsync(transport, options);\n\nJava (McpClient.async/sync(...).capabilities(...)): Similar to Python, capabilities are enabled via the builder, and handlers are passed via separate builder methods (.sampling(handler), .listRoots(handler)).\nMcpAsyncClient client = McpClient.async(transport)\n    .capabilities(ClientCapabilities.builder()\n        .sampling()\n        .roots(true) // enables roots with listChanged\n        .build())\n    .sampling(mySamplingHandler) // Pass handler function\n    .listRoots(myListRootsHandler)\n    .build();\n\n\nHandling Server Requests: Implementing Client Logic\nWhen a server sends a sampling/createMessage or roots/list request, the client SDK needs to route it to the appropriate user-defined logic.\n1. Sampling (sampling/createMessage):\n\nInput: Server sends CreateMessageRequestParams (messages, modelPreferences, systemPrompt, maxTokens, etc.).\nClient Logic: The registered handler receives these parameters. It should:\n\nPresent the request to the user for approval/modification (crucial security step).\nSelect an appropriate LLM based on modelPreferences and available client models.\nPotentially inject context if includeContext was requested (implementation specific to the host app).\nCall the chosen LLM API.\nPresent the LLM’s response to the user for approval/modification.\nConstruct and return the CreateMessageResult (role, content, model, stopReason).\n\n\nSDK Handling:\n\nTS: Handler registered via client.setRequestHandler(CreateMessageRequestSchema, handler). Handler receives parsed request and RequestHandlerExtra.\nPython: Handler (sampling_callback) passed to ClientSession constructor. Receives RequestContext and parsed CreateMessageRequestParams. Returns CreateMessageResult or ErrorData.\nC#: Handler (SamplingHandler) set on SamplingCapability in McpClientOptions. Is a Func&lt;CreateMessageRequestParams?, IProgress&lt;...&gt;, CancellationToken, ValueTask&lt;CreateMessageResult&gt;&gt;. Progress reporting is integrated.\nJava: Handler (Function&lt;CreateMessageRequest, Mono&lt;CreateMessageResult&gt;&gt; or sync equivalent) passed to builder via .sampling(handler). Receives parsed CreateMessageRequest.\n\n\nKey Nuance: C#‘s CreateSamplingHandler extension method provides a convenient way to wrap any IChatClient from Microsoft.Extensions.AI into the required handler signature, automatically handling parameter conversion and progress reporting. Other SDKs require more manual implementation of the LLM call and result mapping.\n\n2. Roots (roots/list / notifications/roots/list_changed):\n\nInput (roots/list): Server sends the parameter-less request.\nClient Logic (roots/list Handler): The registered handler determines the relevant root URIs (e.g., current project folders, open workspace). It constructs and returns a ListRootsResult containing Root objects (uri, name). URIs MUST be file:// URIs.\nClient Logic (roots/list_changed Notification): When the relevant roots change (user opens/closes folder, switches projects), the client application logic detects this. If the client declared roots.listChanged=true, it sends the notifications/roots/list_changed notification to the server.\nSDK Handling:\n\nTS: roots/list handler registered via client.setRequestHandler(ListRootsRequestSchema, handler). roots/list_changed sent via client.sendRootsListChanged().\nPython: list_roots_callback passed to ClientSession constructor. roots/list_changed sent via session.send_roots_list_changed().\nC#: RootsHandler set on RootsCapability in McpClientOptions. roots/list_changed sent via client.SendNotificationAsync(NotificationMethods.RootsUpdatedNotification, ...).\nJava: listRoots handler passed to builder via .listRoots(handler). roots/list_changed sent via client.rootsListChangedNotification().\n\n\n\nAdvanced Considerations &amp; Comparison\n\nSecurity &amp; User Control (Sampling): This is paramount. The client/host application is the gatekeeper. SDKs provide the mechanism for the server request, but the client must implement the human-in-the-loop validation before calling the LLM and before returning the response. Failing to do so creates significant security risks.\nContext Injection (Sampling): The spec allows servers to request context (includeContext). How this context is gathered and injected into the LLM prompt is entirely up to the client/host application implementation. The SDKs don’t provide built-in mechanisms for this automatic context gathering.\nModel Mapping (Sampling): Clients need logic to interpret ModelPreferences (hints, priorities) and map them to locally available LLMs or APIs (OpenAI, Anthropic, Gemini, local models via Ollama, etc.). This mapping logic resides outside the core SDK handlers. C#‘s Microsoft.Extensions.AI integration might simplify using different backend providers.\nRoots Implementation: Defining “relevant” roots is application-specific. An IDE might use open workspace folders. A file manager might use the currently viewed directory. The logic lives within the client application, exposed via the handler.\nError Handling: Client handlers for sampling/createMessage and roots/list should return appropriate JSON-RPC errors if they fail (e.g., user rejects sampling, invalid roots, internal error).\nSync vs. Async (Java): For sampling, the Async API is almost always preferred due to the inherent latency of LLM calls. For roots/list, Sync might be acceptable if root discovery is fast, but Async is generally safer.\n\nConclusion: Empowering Servers Through Client Capabilities\nSampling and Roots invert the typical MCP flow, empowering servers by allowing them to leverage client-side LLM access and filesystem context awareness.\n\nSampling is the key to enabling complex, server-driven agentic workflows where the server might orchestrate tasks but delegates the core “thinking” (LLM calls) back to the client, keeping API keys and user control localized.\nRoots provide essential grounding for servers operating on local filesystems, ensuring they work within user-defined boundaries.\n\nAll four SDKs provide the necessary mechanisms to declare support for these capabilities and register handlers to respond to server requests. C# stands out with its convenient CreateSamplingHandler extension for integrating with IChatClient. Python and Java offer clear separation via dedicated builder methods or constructor arguments for callbacks. TypeScript uses its consistent setRequestHandler pattern.\nImplementing these client-side capabilities, especially Sampling with its critical human-in-the-loop requirements, requires careful design by the client application developer. However, when implemented correctly, they unlock powerful new interaction patterns within the MCP ecosystem.\nWith this exploration of client-side capabilities, we’ve covered the major functional aspects of the SDKs. Our final post will synthesize the entire series, offering concluding thoughts on the developer experience, use cases, and future directions for MCP across all four platforms.\n"},"3-Official-mcp-spec-tutes/Blogs/blog-8":{"slug":"3-Official-mcp-spec-tutes/Blogs/blog-8","filePath":"3 Official mcp spec tutes/Blogs/blog-8.md","title":"Blog 8: Communication Channels - Comparing Transport Implementations Across MCP SDKs","links":["3-Official-mcp-spec-tutes/Blogs/blog-1.md1","3-Official-mcp-spec-tutes/Blogs/blog-1.md2","3-Official-mcp-spec-tutes/Blogs/blog-6","3-Official-mcp-spec-tutes/Blogs/blog-7","3-Official-mcp-spec-tutes/Blogs/blog-3","3-Official-mcp-spec-tutes/Blogs/blog-8"],"tags":[],"content":"Blog 8: Communication Channels - Comparing Transport Implementations Across MCP SDKs\nSeries: Deep Dive into the Model Context Protocol SDKs (Advanced Topics)\r\nPost: 8 of 12\nWe’ve spent considerable time exploring the Model Context Protocol (MCP) primitives (Tools, Resources, Prompts) and capabilities (Roots, Caps). But how do the JSON-RPC messages carrying these interactions actually travel between client and server? The answer lies in the Transport Layer.\nTransports are the concrete communication mechanisms (Stdio, HTTP+SSE, Streamable HTTP, WebSockets) that bridge the gap between processes or machines. While the core MCP logic remains consistent, the choice and implementation of the transport significantly impact performance, scalability, deployment complexity, and available features like resumability.\nThis post dives deep into the specific transport implementations offered by the TypeScript, Python, C#, and Java SDKs, comparing their approaches, underlying libraries, and adherence to the MCP transport specifications.\nThe Transport Contract: Sending and Receiving\nAt a high level, all transports must fulfill a basic contract (explicitly defined via interfaces like ITransport in C#, implied via stream pairs/factories in Python/Java/TS):\n\nEstablish Connection: Initiate communication (e.g., start process, open HTTP stream/socket).\nSend Messages: Serialize outgoing JsonRpcMessage objects and transmit them over the channel (e.g., write JSON string to stdout/HTTP body/WebSocket).\nReceive Messages: Listen for incoming data, frame it correctly (e.g., read lines, parse SSE events), deserialize JSON into JsonRpcMessage objects, and make them available to the upper protocol layer (e.g., via a ChannelReader or callback).\nManage Lifecycle: Handle connection closure and errors, notifying the protocol layer.\n\nThe differences lie in how each SDK implements this for specific protocols.\n1. Stdio (Standard Input/Output)\n\nSpec: Newline-delimited JSON strings over stdin/stdout. Server stderr for logs.\nUse Case: Secure, low-latency communication with a locally launched child process server. Essential for desktop integrations.\nImplementations:\n\nTypeScript: StdioClientTransport (uses cross-spawn), StdioServerTransport (uses process.stdin/stdout), shared ReadBuffer/serializeMessage. Client manages process lifecycle.\nPython: stdio_client (async context manager using anyio.open_process, platform-specific helpers), stdio_server (async context manager wrapping sys.stdin/stdout with anyio). Client manages process lifecycle.\nC#: StdioClientTransport (uses System.Diagnostics.Process, includes ProcessHelper.KillTree), StdioServerTransport (wraps Console.OpenStandardInput/Output, integrates with IHostedService). Client manages process lifecycle.\nJava: StdioClientTransport (uses ProcessBuilder, manages IO threads via Reactor Schedulers), StdioServerTransportProvider (server-side provider wrapping System.in/out, assumes single session started externally).\n\n\nKey Differences:\n\nAsync Model: TS uses Node events, Python uses anyio, C# uses async/await on Streams/Pipes, Java uses dedicated threads coordinated by Reactor.\nProcess Management: All client transports handle process start/stop. C# includes explicit tree-killing. Java’s server provider doesn’t manage the process (assumes it is the process).\nAPI Style: TS/C# use transport classes. Python uses async context managers yielding streams. Java uses transport classes/providers.\n\n\nPerformance: Generally very high throughput and low latency due to direct IPC. Bottleneck is usually JSON serialization/deserialization speed and pipe buffer limits.\n\n2. HTTP + Server-Sent Events (SSE) - Legacy/Compatibility Focus\n\nSpec (2024-11-05): Dual endpoints. Client GET /sse establishes long-lived stream for Server→Client messages. Server sends event: endpoint with POST URL (including sessionId). Client sends POST /message?sessionId=... for Client→Server messages. Server responds 202 Accepted to POST, sends actual JSON-RPC response over the specific client’s SSE stream.\nUse Case: Web-based communication, server-push notifications. Standard, well-understood, firewall-friendly.\nImplementations:\n\nJava: Primary web transport. HttpClientSseClientTransport (core), WebFluxSseClientTransport (Spring), HttpServletSseServerTransportProvider, WebFluxSseServerTransportProvider, WebMvcSseServerTransportProvider. Uses java.net.http, Reactor, Servlets, Jackson.\nPython: Primary web transport. sse_client (context manager using httpx-sse/anyio), SseServerTransport (ASGI app using sse-starlette/anyio).\nC#: Compatibility. SseClientTransport (can be configured for legacy mode via UseStreamableHttp=false). SseHandler mapped by MapMcp provides legacy server endpoints alongside Streamable HTTP. Uses System.Net.Http, SseParser.\nTypeScript: Compatibility. SSEClientTransport (uses eventsource package), SSEServerTransport. Explicitly marked as deprecated in favor of Streamable HTTP in docs.\n\n\nKey Differences:\n\nSDK Priority: Primary in Java/Python, Compatibility in C#/TS.\nLibraries: Varies significantly (see above).\nFramework Integration: Java has dedicated Spring/Servlet providers. C# integrates via ASP.NET Core handlers. Python uses ASGI. TS requires manual Express/http setup.\n\n\nPerformance/Scalability: Efficient for server push. High number of short-lived client POST requests can add overhead vs. persistent connections. No built-in resumability – dropped GET connections lose messages. Session correlation relies on client correctly sending sessionId query param.\n\n3. Streamable HTTP - Modern Focus (TS/C#)\n\nSpec (2025-03-26/draft): Single HTTP endpoint. Client POST sends messages; server can respond with SSE stream (text/event-stream) for results/notifications related to that POST, or direct JSON (application/json), or 202 Accepted. Optional client GET establishes separate SSE stream for unsolicited server notifications. Session ID via Mcp-Session-Id header. Supports resumability via Last-Event-ID header + EventStore.\nUse Case: Modern, efficient, resilient web communication. Handles request/response, notifications, and long-polling/streaming patterns over potentially fewer connections than SSE+POST. Crucial for long-running tools needing resilience.\nImplementations:\n\nTypeScript: Primary web transport. StreamableHTTPClientTransport, StreamableHTTPServerTransport. Fully implements spec features including stateful/stateless modes, EventStore integration for resumability. Requires manual integration with web frameworks (Express examples provided). Uses fetch, EventSourceParserStream.\nC#: Likely primary web transport via ASP.NET Core. SseClientTransport configured with UseStreamableHttp=true. StreamableHttpHandler in ModelContextProtocol.AspNetCore implements server logic mapped via MapMcp. Core StreamableHttpServerTransport has EventStore support (though DI configuration isn’t shown in basic samples). Uses System.Net.Http, SseParser, ASP.NET Core features (IDuplexPipe).\nPython: Not currently implemented.\nJava: Not currently implemented.\n\n\nKey Differences (vs. SSE+POST): Single endpoint, header-based session ID, flexible response types (SSE or JSON on POST), built-in resumability spec/support.\nPerformance/Scalability: Potentially more efficient due to fewer connections (especially with HTTP/2 multiplexing). Resumability prevents wasted work on reconnects. Server implementation complexity might be slightly higher to handle different response modes and stream mapping.\n\n4. WebSocket (Client-Side Focus)\n\nSpec: Not formally defined as a standard MCP transport, but usable via custom transport implementations.\nUse Case: Low-latency, full-duplex, persistent connections. Good for high-frequency bidirectional messaging if supported by both ends.\nImplementations:\n\nTypeScript: WebSocketClientTransport available. No standard server implementation provided.\nPython: websocket_client available (using websockets library). websocket_server also provided (ASGI app using websockets).\nC#: No built-in WebSocket transport provided (would require custom ITransport using e.g., System.Net.WebSockets).\nJava: No built-in WebSocket transport provided (would require custom transport using e.g., Jakarta WebSocket API or Spring WebSockets).\n\n\nKey Differences: Full-duplex vs. half-duplex/request-response nature of HTTP. Lower overhead after initial handshake. Requires WebSocket support on both client and server infrastructure (firewalls, proxies).\nNuance: While Python provides both client and server, the general lack of emphasis suggests it’s not considered a primary standard transport for MCP currently, perhaps due to the added complexity vs. HTTP-based options.\n\nSynthesis for Advanced Users\n\nChoosing a Web Transport:\n\nIf building new TS or C# web services/clients, Streamable HTTP is generally preferred due to its efficiency, resilience (resumability), and alignment with the latest spec. Ensure you configure an EventStore (e.g., Redis-backed) for production resumability.\nIf building Java or Python web services/clients, HTTP+SSE is the current standard SDK approach. Be mindful of its limitations (dual endpoints, no built-in resumability) and design accordingly (e.g., use external state stores for long tasks).\nIf integrating with existing systems, implement backwards compatibility strategies (see Blog 7) where needed.\n\n\nPerformance Bottlenecks: For any transport, JSON (de)serialization and the actual handler logic are often the main bottlenecks, not necessarily the transport protocol itself (unless dealing with extreme scale or very high frequency messaging where WebSocket might offer advantages). Optimize your handlers and consider schema complexity.\nScalability &amp; State: Stateless servers using any transport scale easily horizontally. Stateful servers using HTTP+SSE or Streamable HTTP require careful session management (sticky sessions or external state stores). Resumability (Streamable HTTP) helps mitigate state loss issues caused by transport drops.\nSecurity: Stdio is inherently local. All HTTP-based transports require HTTPS, origin validation, and proper authentication (Blog 8).\n\nConclusion\nThe MCP SDKs provide robust implementations of the specified transports, tailored to their respective ecosystems. Stdio offers a secure, low-latency channel for local integrations across all platforms. For web communication, a divergence exists: TypeScript and C# embrace the modern, resilient Streamable HTTP standard (with C# tightly integrated into ASP.NET Core), while Java and Python provide solid implementations of the well-established, albeit less feature-rich, HTTP+SSE model with excellent framework adapters (Spring/ASGI).\nAdvanced developers must understand the trade-offs: Streamable HTTP’s resumability and efficiency vs. HTTP+SSE’s simplicity and broader current implementation across the Java/Python SDKs. Choosing the right transport, understanding its lifecycle and session management, and implementing appropriate error handling are crucial steps in building performant, scalable, and reliable MCP applications.\n"},"3-Official-mcp-spec-tutes/Blogs/blog-9":{"slug":"3-Official-mcp-spec-tutes/Blogs/blog-9","filePath":"3 Official mcp spec tutes/Blogs/blog-9.md","title":"Blog 9: Essential Utilities - Progress, Cancellation, Logging, & Pagination in MCP SDKs","links":[],"tags":[],"content":"Blog 9: Essential Utilities - Progress, Cancellation, Logging, &amp; Pagination in MCP SDKs\nSeries: Deep Dive into the Model Context Protocol SDKs (Advanced Topics)\r\nPost: 9 of 12\nBeyond the core primitives of Tools, Resources, and Prompts, the Model Context Protocol (MCP) specification defines several essential utility mechanisms that enhance the robustness, usability, and observability of client-server interactions. These aren’t standalone features but rather cross-cutting concerns integrated into the request/response and notification flows.\nFor advanced developers, understanding how the MCP SDKs implement these utilities – Progress Tracking, Request Cancellation, Structured Logging, and Result Pagination – is key to building responsive, resilient, and manageable applications. This post compares the implementation nuances across the TypeScript, Python, C#, and Java SDKs.\n1. Progress Reporting (notifications/progress)\nLong-running operations (often Tools, but potentially Resource reads) need a way to report status back to the requester without waiting for the final result.\n\nSpecification (docs/.../basic/utilities/progress.mdx):\n\nRequester includes an optional progressToken (unique string/number) in the request _meta.\nThe handler (server for client requests, client for server requests like sampling) may send notifications/progress messages containing the original progressToken, a monotonically increasing progress value (number), an optional total (number), and an optional message (string).\n\n\nImplementation Insights:\n\nTypeScript (Client.request option):\n\nClient provides an onprogress: (prog: Progress) =&gt; void callback in the RequestOptions.\nThe Client automatically generates a unique progressToken, adds it to the outgoing request’s _meta.\nIt registers an internal handler for notifications/progress. When a notification with the matching token arrives, it extracts the progress, total, and message and calls the user’s onprogress callback.\nServer-side handlers receive the progressToken via RequestHandlerExtra._meta and send notifications using extra.sendNotification({...}).\n\n\nPython (Context.report_progress / ProgressContext):\n\nClient side doesn’t have a direct onprogress callback in ClientSession.send_request. Handling incoming progress notifications would likely require inspecting them in the general message_handler.\nServer-side (FastMCP): The Context object provides ctx.report_progress(current, total, message). This checks if the incoming request (being handled by the current tool/resource function) had a progressToken in its _meta and, if so, uses ctx.session.send_progress_notification(...) to send the update. Python also offers a shared/progress.py utility ProgressContext for structured reporting.\n\n\nC# (IProgress&lt;T&gt; Injection / NotifyProgressAsync):\n\nClient-side (McpClientExtensions.CallToolAsync): Takes an optional IProgress&lt;ProgressNotificationValue&gt; progress argument. If provided, the client generates a token, adds it to the request, registers an internal handler for notifications/progress, and calls progress.Report(...) when updates arrive.\nServer-side (McpServerTool): If a tool method includes a parameter of type IProgress&lt;ProgressNotificationValue&gt;, the SDK (via AIFunctionFactory) automatically binds it. The handler calls progress.Report(...). The SDK wrapper checks if the incoming request had a progressToken and wires the IProgress&lt;&gt;.Report call to send the notifications/progress message via server.NotifyProgressAsync. If no token was sent by the client, Report calls become no-ops (using NullProgress.Instance).\n\n\nJava (Manual Sending / Handling):\n\nClient-side: No direct onprogress callback in the builder or sendRequest. Requires manually registering a handler for &quot;notifications/progress&quot; using the builder’s .notificationHandler(...) or session’s addNotificationHandler.\nServer-side: The Exchange object doesn’t have a dedicated progress method. Handlers must manually check exchange.getRequest().params().meta().progressToken() and call exchange.getSession().sendNotification(&quot;notifications/progress&quot;, ...) if a token exists.\n\n\n\n\nComparison: C# offers the most idiomatic integration using the standard IProgress&lt;T&gt; pattern. TypeScript’s callback approach is clear and effective. Python provides server-side helpers via Context. Java requires the most manual implementation on both client and server for handling progress.\n\n2. Request Cancellation (notifications/cancelled)\nProvides a way for the sender of a request to signal that the result is no longer needed.\n\nSpecification (docs/.../basic/utilities/cancellation.mdx):\n\nSender issues notifications/cancelled with the requestId of the original request.\nReceiver SHOULD stop processing and MUST NOT send a response. Receiver MAY ignore if already completed or uncancelable.\n\n\nImplementation Insights:\n\nTriggering Cancellation (Client → Server):\n\nTS: Pass an AbortSignal in RequestOptions. Calling abort() on the controller triggers sending the notification.\nPython: Pass an anyio.CancelScope? (Less explicit in docs). Relies on general async cancellation propagating. SDK likely sends notification on scope cancellation.\nC#: Pass a CancellationToken to request methods (e.g., client.CallToolAsync(..., cancellationToken)). Cancelling the token triggers sending the notification.\nJava: Use Reactor’s cancellation mechanisms (Mono.doOnCancel, subscribing with a Subscription and calling .cancel()). The SDK likely hooks into this to send the notification.\n\n\nHandling Cancellation (Server-Side Handler):\n\nTS: RequestHandlerExtra.signal (AbortSignal). Handlers check signal.aborted or signal.throwIfAborted().\nPython: Context doesn’t directly expose the signal. Relies on anyio cancellation propagating up to the handler task (e.g., awaiting a cancelled operation).\nC#: RequestContext&lt;TParams&gt; contains RequestAborted (CancellationToken). Handlers receive/inject CancellationToken and check IsCancellationRequested / ThrowIfCancellationRequested().\nJava: McpAsync/SyncServerExchange provides getCancellationToken(). Reactive handlers (Mono/Flux) should incorporate this or check exchange.isCancelled().\n\n\nReceiving Cancellation Notification: All SDKs have internal handlers for notifications/cancelled. They look up the requestId in their map of in-flight operations (_handlingRequests in C#, _in_flight in Python, etc.) and trigger the associated cancellation mechanism (e.g., CancellationTokenSource.Cancel() in C#).\n\n\nComparison: All SDKs support the cancellation flow using platform-standard cancellation primitives (AbortSignal, CancellationToken, CancelScope, Reactor Subscription). C# and TS make accessing the cancellation signal/token very explicit within handlers.\n\n3. Structured Logging (logging/setLevel, notifications/message)\nAllows servers to send structured logs to interested clients, with clients controlling the verbosity.\n\nSpecification (docs/.../server/utilities/logging.mdx):\n\nServer declares logging capability.\nClient may send logging/setLevel request (params: { level: LoggingLevel }).\nServer sends notifications/message (params: { level: LoggingLevel, logger?: string, data: unknown }). Server SHOULD only send messages at or above the level set by the client (if any).\n\n\nImplementation Insights:\n\nSetting Level (Client):\n\nTS: client.setLoggingLevel(level) extension method.\nPython: session.set_logging_level(level) method.\nC#: client.SetLoggingLevel(level) extension method.\nJava: client.setLoggingLevel(level) method (sync/async).\n\n\nHandling Level Request (Server):\n\nTS: Low-level server.setRequestHandler(SetLevelRequestSchema, ...). McpServer doesn’t handle automatically.\nPython: Low-level @server.set_logging_level() decorator. FastMCP doesn’t handle automatically.\nC#: Optional SetLoggingLevelHandler in LoggingCapability. The core McpServer always tracks the last set level in its LoggingLevel property, regardless of handler registration.\nJava: Optional setLevelHandler in McpServerFeatures. The McpServerSession always tracks the level.\n\n\nSending Log Notification (Server):\n\nTS: server.sendLoggingMessage(params).\nPython: ctx.log(level, message, ...) helper in FastMCP. Low-level session.send_log_message(level, data, logger).\nC#: server.SendNotificationAsync(NotificationMethods.LoggingMessageNotification, params). ILogger integration via AsClientLoggerProvider extension.\nJava: exchange.loggingNotification(params) helper. Low-level session.sendNotification(...).\n\n\nReceiving Log Notification (Client):\n\nTS: client.setNotificationHandler(LoggingMessageNotificationSchema, ...).\nPython: logging_callback passed to ClientSession.\nC#: client.RegisterNotificationHandler(NotificationMethods.LoggingMessageNotification, ...).\nJava: .loggingConsumer(...) on client builder.\n\n\n\n\nComparison: All SDKs support the basic flow. C# offers unique integration by providing an ILoggerProvider that automatically routes .NET ILogger messages over MCP. Server-side level handling requires explicit handlers in TS/Python but is implicitly tracked (though optionally handled) in C#/Java.\n\n4. Pagination (cursor/nextCursor)\nHandles large result sets for list operations (Tools, Resources, Prompts, Templates).\n\nSpecification (docs/.../server/utilities/pagination.mdx):\n\nRequests (List*Request) have optional params.cursor (opaque string).\nResponses (List*Result) have optional nextCursor (opaque string).\nServer determines page size. Client iterates by passing the received nextCursor as the cursor in the next request until nextCursor is null/absent.\n\n\nImplementation Insights:\n\nClient-Side: All SDKs typically abstract pagination within their high-level List*Async (C#) or list_* (TS/Python/Java) methods/enumerables. These methods internally handle the loop of sending requests with cursors until nextCursor is null, accumulating or yielding results. Users usually get the full list or an async iterator without needing to manage cursors directly.\nServer-Side: The implementation burden falls entirely on the developer writing the list handler. The handler receives the cursor from the request parameters (via RequestContext/Exchange/Extra). It must:\n\nDecode the cursor (if it contains state like an offset or last ID).\nFetch the appropriate page of data based on the cursor state.\nDetermine if more data exists beyond the current page.\nGenerate the next opaque nextCursor string (encoding the state needed to fetch the subsequent page).\nReturn the List*Result object containing the current page’s items and the nextCursor.\n\n\n\n\nComparison: Client-side usage is generally simple across SDKs. Server-side implementation requires careful state management and cursor encoding/decoding logic, implemented manually by the developer within the handler function/delegate, regardless of the SDK.\n\nConclusion: Building Beyond the Basics\nThe utility features of MCP – Progress, Cancellation, Logging, and Pagination – are essential for creating polished, resilient, and observable applications. While specified consistently, their implementation across the SDKs reveals different approaches to developer experience and integration:\n\nProgress: C# (IProgress&lt;T&gt;) and TS (onprogress callback) offer the most idiomatic client-side handling. Python (Context) provides server-side helpers. Java requires more manual plumbing.\nCancellation: All SDKs integrate well with their platform’s standard cancellation mechanisms (CancellationToken, AbortSignal, etc.) for both sending and receiving cancellations.\nLogging: All SDKs support the basic flow. C# provides unique integration with Microsoft.Extensions.Logging.\nPagination: Clients benefit from automatic handling in list methods across SDKs. Server-side implementation remains a manual task for the handler developer in all ecosystems.\n\nMastering these utilities allows advanced developers to build MCP interactions that are not only functional but also provide crucial feedback during long operations, respond gracefully to interruptions, offer valuable observability, and handle large datasets efficiently.\n"},"3-Official-mcp-spec-tutes/README":{"slug":"3-Official-mcp-spec-tutes/README","filePath":"3 Official mcp spec tutes/README.md","title":"README","links":[],"tags":[],"content":"\nOfficial mcp spec tutes\n"},"3-Official-mcp-spec-tutes/index":{"slug":"3-Official-mcp-spec-tutes/index","filePath":"3 Official mcp spec tutes/index.md","title":"3 Official mcp spec tutes","links":[],"tags":[],"content":""},"4-jlowin-fastmcp-tutes/111_model":{"slug":"4-jlowin-fastmcp-tutes/111_model","filePath":"4 jlowin-fastmcp tutes/111_model.md","title":"111_model","links":[],"tags":[],"content":"Okay, let’s analyze the jlowin-fastmcp repository based on the provided file structure and README.\nProject Overview:\njlowin-fastmcp presents itself as FastMCP v2, positioning itself as “The fast, Pythonic way to build MCP servers and clients.” Critically, it’s explicitly stated (in the README) that FastMCP 1.0 (the original ergonomic, decorator-based server API) is now part of the official Model Context Protocol Python SDK (modelcontextprotocol/python-sdk).\nThis repository, therefore, represents an extension and evolution of that core FastMCP concept. It builds upon the official mcp package (listing it as a dependency in pyproject.toml) by adding advanced features, a more comprehensive client implementation, and potentially alternative abstractions, rather than being a completely separate implementation of the MCP protocol itself.\nPurpose &amp; Value Proposition:\nThe primary goal seems to be enhancing the developer experience (DX) and capabilities beyond the baseline FastMCP module found in the official SDK. It targets developers who want:\n\nMore powerful ways to structure, generate, and manage MCP servers (Proxying, Composition, OpenAPI/FastAPI generation).\nA more feature-complete high-level Python client for interacting with MCP servers.\nAdvanced features like client-side LLM sampling support.\nAn enhanced CLI experience for development and deployment, particularly integrated with uv.\n\nKey Features &amp; Implementation Details:\n\nCore FastMCP Server API (src/fastmcp/server/server.py):\n\nRetains the highly ergonomic decorator-based API (@mcp.tool(), @mcp.resource(), @mcp.prompt()) familiar from the official SDK’s FastMCP module.\nUses type hints and docstrings for automatic schema generation (via utilities/func_metadata.py using Pydantic introspection).\nProvides the Context object for injection into handlers (server/context.py), enabling access to logging, progress reporting, resource reading, and potentially sampling.\n\n\nAdvanced Server Composition &amp; Generation:\n\nProxying (FastMCP.from_client, server/proxy.py): Allows creating a FastMCP server that acts as a frontend/proxy for another MCP endpoint (which could be remote, stdio-based, or even another client connection). Useful for transport bridging or adding middleware logic.\nMounting (FastMCP.mount, server/server.py): Enables composing multiple FastMCP applications together, mounting sub-apps under specific prefixes for tools, resources, and prompts, promoting modularity. Supports both direct (in-memory) and proxy mounting modes.\nOpenAPI/FastAPI Generation (FastMCP.from_openapi, FastMCP.from_fastapi, server/openapi.py, utilities/openapi.py): Automatically generates MCP tools and resources from existing OpenAPI specifications or live FastAPI applications, significantly lowering the barrier to exposing existing web APIs via MCP. Includes logic to map HTTP methods/paths to MCP primitives.\n\n\nEnhanced Client (src/fastmcp/client/client.py):\n\nProvides a high-level Client class that acts as an async context manager (async with Client(...)).\nOffers simplified methods (list_tools, call_tool, etc.) alongside methods returning raw MCP objects (list_tools_mcp, etc.).\nTransport Abstraction (client/transports.py): Defines a ClientTransport base class and provides implementations for Stdio (Python, Node, uvx, npx), SSE, WebSocket, and crucially, an in-memory FastMCPTransport for testing. Automatically infers transport from connection string/object.\nClient Capabilities: Explicitly supports configuring handlers for server-initiated requests like Sampling (client/sampling.py) and Roots (client/roots.py) via callbacks passed to the Client constructor.\n\n\nEnhanced CLI (src/fastmcp/cli/cli.py):\n\nProvides a fastmcp command-line tool built with typer.\nrun: Executes a server file (supporting file:object syntax).\ndev: Runs the server in development mode, automatically launching the MCP Inspector tool (npx @modelcontextprotocol/inspector) alongside it. Manages temporary environments using uv run --with/--with-editable.\ninstall: Installs the server into the Claude Desktop application’s configuration (cli/claude.py), automatically constructing the correct uv run command with necessary dependencies and environment variables. Leverages uv for environment management.\nversion: Displays version information.\n\n\nContrib Modules (src/fastmcp/contrib/):\n\nA dedicated package for community or experimental extensions. Examples include BulkToolCaller (for batching tool calls) and MCPMixin (for registering methods from classes). This encourages extensibility without bloating the core.\n\n\nUtilities (src/fastmcp/utilities/):\n\nfunc_metadata.py: Core logic for function introspection, Pydantic model generation for arguments, and validated function calling.\nopenapi.py: Logic for parsing OpenAPI specs and mapping routes to MCP primitives.\nhttp.py: Helpers potentially for the OpenAPI client integration or web features.\ntypes.py, logging.py: Common type definitions and logging setup.\n\n\nTooling &amp; Ecosystem:\n\nBuild/Dependency: Strongly favors/requires uv for installation and CLI operations. Uses hatchling with uv-dynamic-versioning.\nTesting: Comprehensive suite using pytest and pytest-asyncio. Tests cover CLI, client, server, contrib, utilities, and OpenAPI integration.\nCode Quality: ruff (linting/formatting), pyright (type checking), pre-commit.\nDocumentation: Extensive documentation hosted at gofastmcp.com (source in docs/ using Mintlify).\nTask Runner: justfile.\n\n\n\nRelationship to Official SDK:\n\nCore Dependency: It depends on and uses the official mcp package for low-level protocol types, session management (BaseSession, ClientSession, ServerSession), and potentially low-level server logic.\nExtension Layer: It primarily provides higher-level abstractions (FastMCP, Client, advanced transports) and features (Proxying, OpenAPI, enhanced CLI) on top of the official SDK’s foundation. It essentially is the FastMCP module from the official SDK, but significantly enhanced and evolved as a separate project (v2).\n\nStrengths:\n\nDeveloper Experience: Builds upon the already ergonomic FastMCP v1 API with decorators and type inference, making server creation very intuitive.\nAdvanced Features: Proxying, mounting, and OpenAPI/FastAPI generation are powerful features not found in the official SDKs, significantly aiding integration with existing systems.\nEnhanced Client: Offers a more feature-complete and configurable high-level client compared to basic examples.\nExcellent CLI: The fastmcp CLI with dev (Inspector) and install (Claude Desktop + uv) modes provides a superior local development and deployment workflow.\nModern Tooling: Embraces uv, ruff, pyright.\nExtensibility: The contrib package fosters community extensions.\nGood Documentation &amp; Examples: Appears well-documented with practical examples.\n\nPotential Considerations:\n\nCommunity Fork/Extension: Being a separate repository from the official modelcontextprotocol org means its release cycle and feature alignment might diverge from the official SDKs or spec updates over time. It relies on the official mcp package staying relatively stable.\n“FastMCP-isms”: Advanced features like mounting or OpenAPI generation might introduce patterns specific to this implementation, potentially reducing portability if strict adherence to only core MCP features found across all official SDKs is required.\nHTTP Transport: Like the official Python SDK, it seems to rely on the HTTP+SSE transport model (server/sse.py exists, no obvious Streamable HTTP handler), inheriting its limitations (no built-in resumability).\n\nConclusion:\njlowin-fastmcp is a significant extension and enhancement of the FastMCP concept originally included in the official MCP Python SDK. It leverages the official SDK’s low-level foundation but adds powerful high-level features focused on server generation (from OpenAPI/FastAPI), composition (mounting), proxying, a more feature-rich client, and superior CLI tooling (especially uv and Claude Desktop integration). It represents a compelling option for Python developers seeking maximum developer experience and advanced integration capabilities within the MCP ecosystem, provided they understand its relationship as an extension layer building upon the official core mcp package."},"4-jlowin-fastmcp-tutes/113_model":{"slug":"4-jlowin-fastmcp-tutes/113_model","filePath":"4 jlowin-fastmcp tutes/113_model.md","title":"113_model","links":[],"tags":[],"content":"Okay, here is a 5-part blog series plan for a deep dive into the jlowin-fastmcp (FastMCP v2) codebase, aimed at advanced users and researchers. This plan emphasizes its relationship to the official mcp package and its unique features.\nTarget Audience: Advanced Python developers, AI/Agent developers, researchers using Python, users familiar with MCP basics or the official Python SDK, developers evaluating different MCP implementation approaches.\nOverall Goal: To provide an in-depth technical analysis of FastMCP v2, highlighting its ergonomic abstractions, unique server patterns (proxying, composition, generation), enhanced client features, and developer tooling, while contrasting it with the underlying official mcp library it extends and discussing the practical implications for building sophisticated MCP applications.\n\nBlog Series: FastMCP v2 Deep Dive - Ergonomics, Advanced Patterns, and Ecosystem Tools\nBlog 1: FastMCP v2 - Beyond the Official SDK\n\nCore Focus: Introduce FastMCP v2, clarify its positioning as an enhanced layer on top of the official mcp package (which contains FastMCP v1), and outline its core value proposition.\nKey Code Areas: README.md, pyproject.toml (dependency on mcp), src/fastmcp/__init__.py, high-level view of src/fastmcp/server/server.py (FastMCP class) and src/fastmcp/client/client.py (Client class).\nKey Concepts: MCP Recap (Tools, Resources, Prompts), FastMCP v1 vs. v2 distinction, the “Pythonic” philosophy, core components (Server, Client, CLI, Utilities).\nImplementation Deep Dive: How FastMCP v2 builds upon the mcp base types and sessions. The structure of the FastMCP class vs. the lower-level mcp.server.lowlevel.Server. Initial look at the project structure and dependencies (uv).\nNuanced Take / End-User Angle: Why choose FastMCP v2 over just using the official SDK’s FastMCP module? Focus on advanced patterns, client features, and tooling aimed at improving developer velocity and enabling more complex integrations, ultimately leading to richer end-user applications faster. Discussing the implications of using a community extension vs. sticking strictly to the official library.\n\nBlog 2: The Ergonomic Server - Decorators, Inference, and Context\n\nCore Focus: Deep dive into the high-level FastMCP server API, focusing on how it simplifies Tool, Resource, and Prompt definition compared to lower-level approaches.\nKey Code Areas: src/fastmcp/server/server.py (@tool, @resource, @prompt decorators), src/fastmcp/tools/tool.py (Tool.from_function), src/fastmcp/resources/resource.py/template.py (Resource/Template.from_function), src/fastmcp/prompts/prompt.py (Prompt.from_function), src/fastmcp/utilities/func_metadata.py (func_metadata, ArgModelBase), src/fastmcp/server/context.py (Context class).\nKey Concepts: Decorator pattern for registration, type hint inference for schema generation, automatic result conversion (e.g., dict/list → JSON, Image → ImageContent), context injection.\nImplementation Deep Dive: How does @mcp.tool work? Analyze func_metadata’s role in inspecting signatures and creating dynamic Pydantic models. Trace how arguments are validated (call_fn_with_arg_validation). Explore the Context object implementation and how it gets injected. Examine the automatic result conversion logic in Tool._convert_to_content and similar logic for resources/prompts. Compare this DX to manually defining MCP types and handlers.\nNuanced Take / End-User Angle: The significant reduction in boilerplate allows developers to expose existing Python functions or new logic as MCP primitives extremely quickly. This accelerates the creation of AI-accessible capabilities, allowing users to benefit from more tools and richer context sooner. Discuss trade-offs: “magic” vs. explicit control, potential limitations of type inference for highly complex schemas.\n\nBlog 3: Advanced Server Patterns - Proxying, Mounting, and Generation\n\nCore Focus: Explore the unique server-side features introduced in FastMCP v2 that go beyond basic primitive registration.\nKey Code Areas: src/fastmcp/server/server.py (FastMCP.from_client, FastMCP.mount, FastMCP.from_openapi, FastMCP.from_fastapi), src/fastmcp/server/proxy.py (FastMCPProxy, ProxyTool, ProxyResource, etc.), src/fastmcp/server/openapi.py (FastMCPOpenAPI, RouteMap, etc.), src/fastmcp/utilities/openapi.py (parsing logic).\nKey Concepts: Proxy pattern, Server Composition (Mounting vs. Importing), OpenAPI/FastAPI specification mapping to MCP primitives (Tools, Resources, Templates), Route Mapping rules.\nImplementation Deep Dive: Analyze how FastMCP.from_client discovers capabilities and creates proxy objects. Examine the mount logic and how it delegates requests based on prefixes (direct vs. proxy mode). Trace the from_openapi/from_fastapi flow: parsing the spec/app, applying RouteMap rules, creating OpenAPITool/OpenAPIResource instances that wrap httpx calls.\nNuanced Take / End-User Angle: These patterns enable powerful architectural solutions. Proxying bridges transport gaps (e.g., making a Stdio tool web-accessible). Mounting facilitates modular design for large applications. OpenAPI/FastAPI generation drastically speeds up exposing existing web APIs to LLMs via MCP. How do these architectural choices impact deployment, maintenance, and the types of integrations users can ultimately access?\n\nBlog 4: The Enhanced Client and CLI Workflow\n\nCore Focus: Detail the fastmcp.Client, its transport handling, advanced features (sampling/roots), and the powerful fastmcp CLI tool.\nKey Code Areas: src/fastmcp/client/client.py (Client class, high-level methods, raw *_mcp methods), src/fastmcp/client/transports.py (Transport classes, infer_transport), src/fastmcp/client/sampling.py (create_sampling_callback), src/fastmcp/client/roots.py (create_roots_callback), src/fastmcp/cli/cli.py (typer app, dev, run, install commands), src/fastmcp/cli/claude.py (Claude config logic).\nKey Concepts: Async context manager client, Transport inference, Client-side capabilities implementation (Sampling/Roots handlers), CLI commands, uv integration, MCP Inspector integration, Claude Desktop installation.\nImplementation Deep Dive: Analyze the Client.__aenter__/__aexit__ lifecycle. Examine infer_transport logic. Detail how sampling_handler and roots callbacks are wrapped and used by the underlying mcp.ClientSession. Trace the execution flow of fastmcp dev (launching Inspector + server via uv run) and fastmcp install (finding Claude config, building uv run command, updating JSON).\nNuanced Take / End-User Angle: The high-level Client simplifies programmatic interaction. The CLI tools dramatically improve the developer workflow for testing (dev + Inspector) and local deployment (install + uv). This translates to end-users getting access to working, dependency-managed local tools (like those for Claude Desktop) much more easily and reliably. Compare this integrated CLI experience to the more manual approach needed with other SDKs.\n\nBlog 5: Synthesis - Testing, Extensibility (contrib), and Future Perspective\n\nCore Focus: Summarize FastMCP v2’s advantages, discuss testing strategies, explore the contrib module, and offer perspective on its place in the ecosystem.\nKey Code Areas: tests/ directory structure, tests/conftest.py (if applicable), src/fastmcp/client/transports.py (FastMCPTransport for testing), src/fastmcp/shared/memory.py (underlying mechanism potentially), src/fastmcp/contrib/ modules (BulkToolCaller, MCPMixin).\nKey Concepts: In-memory testing pattern, Unit vs. Integration testing approaches for FastMCP servers, purpose of contrib, potential future directions.\nImplementation Deep Dive: Analyze how the FastMCPTransport enables efficient in-memory testing (tests/client/test_client.py). Discuss how to unit test decorated functions by mocking Context or dependencies. Examine the design of MCPMixin for class-based component registration. Briefly touch on BulkToolCaller’s utility.\nNuanced Take / End-User Angle: FastMCP v2 significantly lowers the friction for Python developers building and testing MCP servers. Features like OpenAPI generation and proxying enable rapid integration. The CLI streamlines local deployment. While being an extension adds a layer, its focus on DX and advanced patterns makes it a compelling choice for many Python use cases, potentially leading to more diverse and powerful MCP tools becoming available to end-users more quickly. Discuss the ongoing relationship between this project and the official SDK.\n\n\nThis plan balances deep dives into specific code areas with broader discussions on design philosophy, developer experience, and end-user impact, specifically tailored to the unique position and features of the jlowin-fastmcp repository."},"4-jlowin-fastmcp-tutes/Blogs/blog-1":{"slug":"4-jlowin-fastmcp-tutes/Blogs/blog-1","filePath":"4 jlowin-fastmcp tutes/Blogs/blog-1.md","title":"Blog 1: FastMCP v2 - Beyond the Official SDK","links":["4-jlowin-fastmcp-tutes/Blogs/link-to-ts-py-series","4-jlowin-fastmcp-tutes/Blogs/link-to-cs-java-series"],"tags":[],"content":"Blog 1: FastMCP v2 - Beyond the Official SDK\nSeries: Deep Dive into the Model Context Protocol SDKs (Advanced Topics)\r\nPost: 1 of 12\nWelcome to this advanced deep-dive series focused on the nuances of the Model Context Protocol (MCP) ecosystem! If you’ve followed our previous explorations of the official Python or Java SDKs, you understand the core goal: bridging the gap between AI language models and application-specific context/tools.\nWhile the official SDKs provide the foundational implementations, the dynamic nature of AI development often spurs community innovation and higher-level abstractions. This series focuses on one such significant contribution: the jlowin-fastmcp repository, which we’ll refer to as FastMCP v2.\nThis isn’t just another MCP implementation; it’s an evolution and enhancement built directly upon the official Python SDK (modelcontextprotocol/python-sdk). Understanding this relationship is key. The original, highly ergonomic FastMCP server API (v1), known for its decorator-based simplicity, proved so effective that it became part of the official mcp package (specifically, mcp.server.fastmcp).\nFastMCP v2 takes that successful foundation and extends it significantly, offering advanced patterns, a more capable client, and powerful developer tooling. This series is for developers who want to move beyond the basics, understand the design choices behind these enhancements, and evaluate their suitability for complex MCP applications.\nWhy FastMCP v2? The Value Proposition\nIf the official SDK already includes FastMCP v1, why consider v2? FastMCP v2 aims to address several advanced needs and improve the developer experience further:\n\nAdvanced Server Patterns: Introduces sophisticated ways to structure and generate MCP servers, including:\n\nProxying: Acting as a frontend for other MCP servers (remote or local).\nComposition (Mounting): Building modular applications by combining multiple FastMCP servers.\nGeneration: Automatically creating MCP servers from OpenAPI specs or FastAPI apps.\n\n\nEnhanced Client: Provides a more feature-complete, high-level Python client (fastmcp.Client) with automatic transport inference and built-in support for handling server-initiated requests (Sampling, Roots).\nSuperior Developer Tooling: Includes a powerful CLI (fastmcp) integrated with modern tooling (uv) for:\n\nInteractive development with the MCP Inspector (dev command).\nSimplified local deployment, especially for Claude Desktop (install command).\nStreamlined server execution (run command).\n\n\nExtensibility: Formalizes community contributions via a contrib package.\nPythonic Ergonomics: Continues the focus on clean, intuitive APIs that feel natural to Python developers.\n\nThe Foundation: Building on the Official mcp Package\nIt’s crucial to understand that FastMCP v2 is not a fork or a replacement for the official modelcontextprotocol/python-sdk. It explicitly depends on the official mcp package (as seen in its pyproject.toml).\n\nCore Types: FastMCP v2 uses the Pydantic models defined in mcp.types for all protocol messages (Requests, Responses, Notifications, Tool, Resource, etc.).\nSession Logic: It likely leverages the underlying mcp.shared.session.BaseSession, mcp.client.session.ClientSession, and potentially mcp.server.session.ServerSession for the core JSON-RPC handling, request/response correlation, and basic state management.\nFocus: FastMCP v2 focuses on providing higher-level abstractions and additional features on top of this stable foundation, rather than reimplementing the base protocol mechanics.\n\nThis layered approach allows FastMCP v2 to benefit from updates to the core mcp package while concentrating on enhancing DX and adding advanced patterns.\nArchitectural Tour: What’s Inside jlowin/fastmcp?\nCompared to the official mcp package, the structure of jlowin/fastmcp reflects its focus on high-level APIs and advanced features:\n\nsrc/fastmcp/server/server.py (FastMCP class): The enhanced server class. It still uses decorators but adds methods like mount, import_server and classmethods like from_client, from_openapi, from_fastapi. It orchestrates internal managers for tools, resources, and prompts.\nsrc/fastmcp/client/client.py (Client class): The high-level client, providing an async with interface, transport inference, and simplified methods, plus access to raw MCP results.\nsrc/fastmcp/client/transports.py: Defines the ClientTransport abstraction and provides concrete implementations (Stdio variants, SSE, WebSocket, and the crucial FastMCPTransport for in-memory testing/embedding).\nsrc/fastmcp/cli/cli.py: The typer-based implementation of the fastmcp command-line tool.\nsrc/fastmcp/cli/claude.py: Specific logic for interacting with the Claude Desktop configuration file.\nsrc/fastmcp/server/proxy.py &amp; openapi.py: Implement the logic for the advanced proxying and OpenAPI/FastAPI generation features.\nsrc/fastmcp/utilities/: Houses core helper modules:\n\nfunc_metadata.py: The engine behind decorator introspection and dynamic Pydantic model generation for argument validation.\nopenapi.py: Utilities for parsing OpenAPI specifications.\n\n\nsrc/fastmcp/contrib/: Namespace for community/experimental extensions like BulkToolCaller and MCPMixin.\nBuild/Tooling: pyproject.toml configured for hatchling and uv-dynamic-versioning. Heavy reliance on uv for dependency management and CLI tasks. justfile for task running. pre-commit with ruff and pyright for code quality.\n\nKey Differentiators (Preview)\nCompared to using only the official mcp package (including its mcp.server.fastmcp module), FastMCP v2 offers:\n\nServer Generation/Composition: from_openapi, from_fastapi, mount.\nProxying: from_client.\nEnhanced Client: fastmcp.Client with transport inference and built-in sampling/roots support.\nAdvanced CLI: fastmcp dev, fastmcp install with uv integration.\nContrib Ecosystem: A dedicated place for extensions.\n\nNuanced Take: Why Choose FastMCP v2?\nFor developers building standard MCP servers or simple clients in Python, the official mcp package (including mcp.server.fastmcp) provides a solid, stable, and officially supported foundation.\nFastMCP v2 (jlowin/fastmcp) becomes compelling when:\n\nMaximizing DX is paramount: The enhanced client, refined server APIs, and especially the CLI tooling significantly streamline development, testing, and local deployment.\nIntegrating Existing APIs: The from_openapi and from_fastapi features offer a massive accelerator for exposing existing web services via MCP.\nBuilding Modular/Bridged Systems: mount and from_client (proxying) enable sophisticated server architectures that are harder to achieve directly with the base SDK.\nLocal Tooling (Claude Desktop): The fastmcp install command, powered by uv, provides the most seamless experience currently available for deploying Python MCP servers to Claude Desktop.\n\nThe Trade-offs:\n\nCommunity Extension: While built on the official SDK, v2 is a community project. Its release cadence and feature set might diverge from the official roadmap. Long-term maintenance depends on its contributors.\nAdded Abstraction: Introducing more features and abstractions inevitably adds complexity compared to the core library.\nPotential “Lock-in”: Relying heavily on v2-specific features (like mounting or OpenAPI generation) might make migrating away from FastMCP v2 slightly harder if strict adherence to only core, cross-SDK patterns becomes necessary later.\n\nConclusion &amp; What’s Next\nFastMCP v2 (jlowin/fastmcp) represents a significant enhancement and opinionated extension built upon the foundation laid by the official Python MCP SDK and the original FastMCP v1 concept. It prioritizes Pythonic ergonomics, advanced server patterns (generation, composition, proxying), and a streamlined developer workflow via its client and CLI tools.\nIt’s an excellent choice for Python developers seeking the path of least resistance to building sophisticated MCP integrations, especially for local development, testing, and exposing existing web APIs. Understanding its relationship to the official mcp package is key to leveraging its strengths effectively.\nIn the next post, we’ll dive deep into the heart of FastMCP v2’s appeal: Blog 2: The Ergonomic Server - Decorators, Inference, and Context, analyzing how it makes defining Tools, Resources, and Prompts so intuitive.\n"},"4-jlowin-fastmcp-tutes/Blogs/blog-2":{"slug":"4-jlowin-fastmcp-tutes/Blogs/blog-2","filePath":"4 jlowin-fastmcp tutes/Blogs/blog-2.md","title":"Blog 2: The Ergonomic Server - FastMCP v2 Decorators, Inference, and Context","links":["4-jlowin-fastmcp-tutes/Blogs/blog-1"],"tags":[],"content":"Blog 2: The Ergonomic Server - FastMCP v2 Decorators, Inference, and Context\nSeries: Deep Dive into the Model Context Protocol SDKs (Advanced Topics)\r\nPost: 2 of 12\nIn our previous post, we introduced jlowin-fastmcp (FastMCP v2) as an enhanced, developer-experience-focused layer built upon the official Python MCP SDK (mcp package). Its core appeal lies in simplifying the process of exposing Python logic as Model Context Protocol (MCP) servers.\nThe heart of this simplicity is the high-level FastMCP server API, which relies heavily on three key pillars:\n\nDecorators: @mcp.tool(), @mcp.resource(), @mcp.prompt() for declarative registration.\nType Hint Inference: Automatically generating MCP schemas (inputSchema, PromptArgument lists) from Python function signatures using Pydantic.\nContext Injection: Providing access to server/request state and MCP utilities via the Context object.\n\nThis post dives deep into these mechanisms, exploring the underlying code (server/server.py, utilities/func_metadata.py, server/context.py, etc.) to understand how FastMCP v2 achieves its ergonomic design and what trade-offs are involved.\n1. Decorators: The Gateway to MCP Primitives\nInstead of manually creating specification objects or registering handlers with complex signatures, FastMCP v2 uses simple decorators.\nfrom fastmcp import FastMCP\n \nmcp = FastMCP(&quot;ErgoServer&quot;)\n \n@mcp.tool() # Registers the function &#039;add&#039; as an MCP Tool named &#039;add&#039;\ndef add(a: int, b: int) -&gt; int:\n    &quot;&quot;&quot;Adds two numbers (this becomes the description).&quot;&quot;&quot;\n    return a + b\n \n@mcp.resource(&quot;config://app/theme&quot;) # Registers &#039;get_theme&#039; as a Resource at the given URI\ndef get_theme() -&gt; str:\n    &quot;&quot;&quot;Returns the current theme (this is the description).&quot;&quot;&quot;\n    return &quot;dark&quot;\n \n@mcp.prompt() # Registers &#039;summarize&#039; as an MCP Prompt named &#039;summarize&#039;\ndef summarize(text_to_summarize: str) -&gt; str: # Argument inferred\n    &quot;&quot;&quot;Creates a summarization request (description from docstring).&quot;&quot;&quot;\n    return f&quot;Please summarize this text: {text_to_summarize}&quot;\nHow it Works (server/server.py, *manager.py):\n\nThe FastMCP instance holds instances of ToolManager, ResourceManager, and PromptManager.\nThe decorators (@mcp.tool, etc.) are methods on the FastMCP instance that call the corresponding manager’s add_*_from_fn method.\nadd_tool_from_fn(fn, name=..., description=...):\n\nCreates a Tool object (from tools/tool.py).\nCrucially, calls Tool.from_function(fn, name, description) which uses utilities.func_metadata.func_metadata(fn) to introspect the function.\nStores the Tool object in the ToolManager’s internal _tools dictionary.\n\n\nadd_resource_fn(fn, uri, name=..., ...) and add_prompt(fn, name=..., ...) follow similar patterns, calling Resource.from_function or Prompt.from_function respectively to perform introspection and create the internal representation.\n\nBenefits: Minimal boilerplate; keeps logic and registration closely coupled; feels very Pythonic.\n2. Type Hint Inference: From Python Signatures to MCP Schemas\nThis is where much of the “magic” happens. FastMCP avoids requiring developers to manually write Zod schemas (like TS) or JSON Schema strings/dicts (like core Java/C# might need).\nKey Component: utilities/func_metadata.py\n\nfunc_metadata(func, skip_names=...):\n\nTakes a Python callable (func).\nUses Python’s inspect.signature() to get parameter names, annotations, and defaults.\nCrucially, dynamically creates a Pydantic BaseModel subclass (ArgModelBase) representing the function’s validatable arguments (excluding skipped names like the Context parameter).\nIt evaluates forward references and complex types (typing.Annotated, Union, Pydantic models, etc.) using eval_type_backport and FieldInfo.from_annotated_attribute.\nStores this generated ArgModelBase type within a FuncMetadata object.\n\n\nSchema Generation:\n\nFor Tools: Tool.from_function calls func_metadata and then uses func_metadata.arg_model.model_json_schema() to generate the standard JSON Schema required for the Tool.inputSchema.\nFor Prompts: Prompt.from_function does the same to generate the list of PromptArgument objects from the signature.\nFor Resource Templates: ResourceTemplate.from_function uses the signature to validate URI template parameters against function parameters.\n\n\nValidation at Runtime:\n\nWhen a tools/call (or prompts/get etc.) request arrives, the FuncMetadata.call_fn_with_arg_validation method is used.\nIt takes the raw arguments dictionary from the MCP request.\nIt calls meta.arg_model.model_validate(arguments) on the dynamically generated Pydantic model. This performs validation, type coercion (e.g., string “5” to int 5), and parsing (e.g., JSON string &quot;[1, 2]&quot; to list[int]).\nIf validation passes, it calls the original handler function (fn) with the validated and coerced arguments (model.model_dump_one_level()).\nIf validation fails, a ValidationError (from fastmcp.exceptions) is raised, typically caught by the server layer and returned as an isError: true result or an InvalidParams MCP error.\n\n\nJSON String Parsing (FuncMetadata.pre_parse_json): Includes a specific pre-processing step to handle cases where clients (like Claude Desktop) send JSON structures as strings instead of actual JSON objects/arrays within the arguments map. It attempts json.loads() on string arguments and validates the result against the expected Pydantic field type before passing it to the main Pydantic validation. This enhances compatibility.\n\nBenefits: DRY (Don’t Repeat Yourself) – types defined once in the signature serve for runtime validation and schema generation. Reduces errors from schema/signature mismatches. Leverages Pydantic’s powerful validation ecosystem.\nNuances &amp; Trade-offs:\n\nRelies heavily on accurate type hints. Missing or incorrect hints lead to weak validation or runtime errors.\nCan feel slightly “magical” compared to explicit schema definition.\nWhile powerful, complex nested generics or highly custom types might occasionally challenge the introspection/generation logic.\nPydantic validation adds some runtime overhead compared to purely static checks or no validation.\n\n3. Context Injection: Accessing Server Capabilities\nMany handlers need to log, report progress, or interact with other MCP features. FastMCP provides the Context object for this.\nKey Component: server/context.py (Context class)\n\nMechanism: When func_metadata introspects a function signature, it identifies parameters annotated with Context (or Context | None, etc. using is_class_member_of_type). It stores the name of this parameter (context_kwarg).\nInjection: During request handling (e.g., in ToolManager.call_tool), before calling the user’s function, the manager creates a Context instance. It populates this Context with references to the current RequestContext (from the low-level mcp server) and the FastMCP server instance itself. This Context object is then passed to the user’s function using the stored context_kwarg name.\nMethods: The Context class provides convenient async methods (.info(), .debug(), .warning(), .error(), .report_progress(), .read_resource(), .sample()) that wrap the underlying calls to the mcp.server.session.ServerSession object (accessed via self.request_context.session).\nProperties: Exposes useful information like request_id, client_id, and provides access to the underlying session, request_context, and fastmcp server instance for advanced use.\n\nBenefits: Clean API for common MCP interactions within handlers. Abstracts away the details of the lower-level mcp session object. Type hinting makes it discoverable and enables IDE support.\nContrast: C# achieves similar context/dependency access primarily through DI parameter injection. Java uses the explicit Exchange object parameter. TypeScript passes the RequestHandlerExtra object. Python’s Context arguably provides the most feature-rich, high-level interface directly tailored for common handler needs within the FastMCP API style.\nConclusion: Pythonic Ergonomics for MCP\nFastMCP v2 demonstrates how a higher-level SDK layer can significantly enhance the developer experience for a protocol like MCP, particularly within the Python ecosystem.\n\nDecorators provide a concise and intuitive way to register MCP primitives.\nType Hint Inference, powered by inspect and dynamic Pydantic model generation, drastically reduces the boilerplate associated with defining and validating input schemas.\nThe Context object offers a clean, unified interface for accessing essential MCP functionalities directly within handler logic.\n\nThese features combine to fulfill the “Fast, Simple, Pythonic” promise, allowing developers to rapidly expose existing code or build new MCP capabilities with minimal friction. While this approach relies on introspection and dynamic generation, which can sometimes feel less explicit than manual schema definition (like in TS/Java), it offers a powerful and productive workflow for many Python developers.\nUnderstanding these core mechanisms – decorator registration calling managers, managers using func_metadata for introspection and validation, and context object injection – provides the foundation for leveraging FastMCP v2 effectively and extending it for more complex scenarios, which we will explore next by looking at Blog 3: Advanced Server Patterns - Proxying, Mounting, and Generation.\n"},"4-jlowin-fastmcp-tutes/Blogs/blog-3":{"slug":"4-jlowin-fastmcp-tutes/Blogs/blog-3","filePath":"4 jlowin-fastmcp tutes/Blogs/blog-3.md","title":"Blog 3: Advanced Server Patterns - Proxying, Mounting, and Generation in FastMCP v2","links":["4-jlowin-fastmcp-tutes/Blogs/blog-2"],"tags":[],"content":"Blog 3: Advanced Server Patterns - Proxying, Mounting, and Generation in FastMCP v2\nSeries: Deep Dive into the Model Context Protocol SDKs (Advanced Topics)\r\nPost: 3 of 12\nIn Blog 2, we explored the core ergonomics of the jlowin-fastmcp server API – its decorators, type inference, and context object that simplify defining standard Model Context Protocol (MCP) Tools, Resources, and Prompts. While this covers many use cases, FastMCP v2 distinguishes itself further by offering powerful advanced server patterns not found in the baseline FastMCP v1 (within the official mcp package) or other official SDKs.\nThese patterns move beyond simply defining individual primitives towards composing, bridging, and even automatically generating entire MCP server functionalities. This post dives into three key advanced patterns provided by FastMCP v2:\n\nProxying (FastMCP.from_client): Creating an MCP server that acts as a frontend for another MCP endpoint.\nMounting (FastMCP.mount): Composing multiple FastMCP servers into a single logical application.\nGeneration (FastMCP.from_openapi, FastMCP.from_fastapi): Automatically creating MCP servers from existing web API definitions.\n\nUnderstanding these patterns is crucial for developers building complex, integrated, or rapidly developed MCP solutions in Python.\n1. Proxying: Bridging Transports and Adding Layers\nThe FastMCP.from_client() class method allows you to create a fully functional FastMCP server instance that transparently forwards requests to another backend MCP endpoint. This backend endpoint is represented by a configured fastmcp.Client instance.\nKey Component: src/fastmcp/server/proxy.py (FastMCPProxy, ProxyTool, ProxyResource, etc.)\nHow FastMCP.from_client(client, ...) Works:\n\nInitialization: An internal FastMCPProxy instance (a subclass of FastMCP) is created.\nDiscovery: It uses the provided client to connect to the backend endpoint and fetches all available Tools, Resources, Resource Templates, and Prompts using standard MCP list_* calls.\nProxy Object Creation: For each discovered primitive on the backend:\n\nIt creates a corresponding “Proxy” object (e.g., ProxyTool, ProxyResource, ProxyTemplate, ProxyPrompt).\nThese proxy objects store the metadata (name, description, schema/uri/arguments) of the original primitive.\nCrucially, their handler logic (run for Tool, read for Resource, render for Prompt) is implemented to simply use the original provided client to forward the request (client.call_tool, client.read_resource, client.get_prompt) to the backend server.\n\n\nRegistration: These proxy objects are registered with the internal managers (_tool_manager, etc.) of the FastMCPProxy instance.\nReturn: The fully populated FastMCPProxy instance is returned, ready to be run like any other FastMCP server.\n\nCode Example (Exposing Stdio server via SSE):\nfrom fastmcp import FastMCP, Client\nfrom fastmcp.client.transports import PythonStdioTransport\n \n# 1. Client configured to talk to the backend Stdio server\nbackend_client = Client(\n    PythonStdioTransport(&quot;path/to/local_tool_server.py&quot;)\n)\n \n# 2. Create the proxy server using the class method\n#    This connects, discovers, and builds the proxy components.\n#    Note: from_client is sync, but uses async internally if needed for discovery.\nproxy_server = FastMCP.from_client(\n    backend_client,\n    name=&quot;LocalToolAsWebService&quot;\n)\n \n# 3. Run the proxy server using the desired *frontend* transport\nif __name__ == &quot;__main__&quot;:\n    # Now, clients connecting via SSE to this proxy_server\n    # will have their requests forwarded via Stdio to the backend.\n    proxy_server.run(transport=&quot;sse&quot;, port=8080)\nUse Cases &amp; Nuances:\n\nTransport Bridging: As shown above, expose a Stdio server over SSE/WebSockets or vice-versa.\nAdding Middleware (Advanced): Subclass FastMCPProxy and override methods like _mcp_call_tool to add logic (logging, caching, auth checks) before/after forwarding to super()._mcp_call_tool(...) which uses the client.\nLimitations: Currently focuses on proxying core primitives. Server-initiated flows like sampling or notifications from the backend might not be fully proxied without custom logic. Error handling relies on the client’s ability to translate backend errors.\n\n2. Mounting: Modular Server Composition\nThe FastMCP.mount(prefix, server, ...) method allows composing applications by attaching one FastMCP server instance (sub-server) onto another (parent server) under a specific prefix.\nKey Component: src/fastmcp/server/server.py (FastMCP.mount, MountedServer class)\nHow mount() Works:\n\nRegistration: The parent FastMCP instance stores the prefix, the sub-server instance, and separator preferences in an internal _mounted_servers dictionary, keyed by the prefix.\nDiscovery (list_* methods): When the parent server handles a list_* request, it first gets its own registered primitives, then iterates through its _mounted_servers:\n\nIt calls the corresponding get_* method on the sub-server (e.g., sub_server.get_tools()).\nIt prefixes the names/URIs of the sub-server’s primitives using the mount prefix and configured separators (e.g., tool_name → {prefix}_{tool_name}, resource_uri → {prefix}+{resource_uri}).\nIt merges these prefixed primitives into the list returned to the client.\n\n\nRequest Routing (call_tool, read_resource, get_prompt): When the parent server receives a request:\n\nIt checks if the requested name or uri starts with any registered mount prefix + separator.\nIf a match is found:\n\nIt strips the prefix and separator from the name/uri.\nIt delegates the call to the corresponding method on the mounted sub-server instance (e.g., mounted_server.server._mcp_call_tool(stripped_name, args)).\n\n\nIf no mount prefix matches, it handles the request using its own primitive managers as usual.\n\n\n\nCode Example (Modular Services):\nfrom fastmcp import FastMCP\n \n# Service A\nservice_a = FastMCP(&quot;ServiceA&quot;)\n@service_a.tool()\ndef process_a(data: str): return f&quot;A processed: {data}&quot;\n@service_a.resource(&quot;a://config&quot;)\ndef config_a(): return {&quot;a_ver&quot;: 1}\n \n# Service B\nservice_b = FastMCP(&quot;ServiceB&quot;)\n@service_b.tool()\ndef process_b(data: int): return f&quot;B processed: {data*2}&quot;\n@service_b.resource(&quot;b://status&quot;)\ndef status_b(): return {&quot;b_ok&quot;: True}\n \n# Main Application\nmain_app = FastMCP(&quot;MainApp&quot;)\n \n# Mount services\nmain_app.mount(&quot;serviceA&quot;, service_a)\nmain_app.mount(&quot;serviceB&quot;, service_b, tool_separator=&quot;-&quot;, resource_separator=&quot;:&quot;)\n \n# Access via main_app (client perspective):\n# Tool: &quot;serviceA_process_a&quot;\n# Tool: &quot;serviceB-process_b&quot;\n# Resource: &quot;serviceA+a://config&quot;\n# Resource: &quot;serviceB:b://status&quot;\nMounting Modes (as_proxy):\n\nDirect (Default, as_proxy=False): Parent directly accesses sub-server’s managers/methods in memory. Faster, simpler. Sub-server’s lifespan function is not run.\nProxy (as_proxy=True): Parent creates an internal FastMCPProxy around the sub-server and interacts via that proxy. Slower, but preserves the sub-server’s full lifecycle including lifespan execution (useful if the sub-server needs initialization). FastMCP automatically uses proxy mode if the sub-server has a non-default lifespan.\n\nUse Cases: Building microservice-like architectures within MCP, organizing large codebases, reusing common utility servers.\n3. Generation: From Web APIs to MCP\nFastMCP v2 can automatically create MCP servers that act as frontends for existing web APIs defined by OpenAPI specifications or live FastAPI applications.\nKey Components: src/fastmcp/server/openapi.py (FastMCPOpenAPI, OpenAPITool, etc.), src/fastmcp/utilities/openapi.py (Parsing &amp; Mapping Logic)\nHow from_openapi(spec, client, ...) / from_fastapi(app, ...) Work:\n\nParse Spec/App: Reads the OpenAPI JSON/YAML (spec) or introspects the FastAPI app object to get its generated OpenAPI schema. Uses openapi-pydantic.\nExtract HTTP Routes: Identifies all paths and HTTP methods defined (utilities.openapi.parse_openapi_to_http_routes).\nApply Route Mapping: For each route, determines whether to map it to an MCP Tool, Resource, or Resource Template using RouteMap rules (defaults: GET → Resource/Template, others → Tool). Custom mappings can be provided.\nCreate MCP Primitives:\n\nFor Tool routes: Creates an OpenAPITool instance. Its metadata (name, description, inputSchema) is derived from the OpenAPI operationId, summary/description, parameters, and request body schema. Its handler logic (_execute_request) uses the provided httpx.AsyncClient to make the corresponding HTTP request to the actual API backend.\nFor Resource routes: Creates an OpenAPIResource. Metadata derived similarly. Handler logic makes a GET request using the httpx client.\nFor ResourceTemplate routes: Creates an OpenAPIResourceTemplate. Metadata derived. The create_resource method generates an OpenAPIResource instance whose handler makes the appropriate GET request with path parameters interpolated into the URL.\n\n\nRegister Primitives: Adds the created OpenAPITool/Resource/Template objects to the managers of a new FastMCPOpenAPI instance (a subclass of FastMCP).\nReturn Server: Returns the populated FastMCPOpenAPI server.\n\nCode Example (FastAPI):\nfrom fastapi import FastAPI\nfrom fastmcp import FastMCP\n \n# Existing FastAPI app\napi = FastAPI()\n@api.get(&quot;/data/{item_id}&quot;)\ndef read_data(item_id: str): return {&quot;id&quot;: item_id, &quot;value&quot;: &quot;some_data&quot;}\n@api.post(&quot;/data&quot;)\ndef create_data(payload: dict): return {&quot;created&quot;: True, **payload}\n \n# Generate MCP server (will need an HTTP client if FastAPI app isn&#039;t running in same process)\n# Here, using ASGITransport for same-process communication\nimport httpx\nmcp_server = FastMCP.from_fastapi(api)\n# Or: mcp_server = FastMCP.from_openapi(api.openapi(), client=httpx.AsyncClient(...))\n \n# MCP perspective:\n# Resource Template: &#039;resource://openapi/read_data_data__item_id__get/{item_id}&#039;\n# Tool: &#039;create_data_data_post&#039;\nUse Cases &amp; Nuances:\n\nRapid API Exposure: Instantly make existing RESTful APIs accessible to LLMs via MCP without writing MCP-specific handlers.\nSchema Accuracy: Relies heavily on the quality and completeness of the OpenAPI specification (descriptions, parameter types, required fields).\nMapping: Default mapping (GET→Resource, others→Tool) works for many REST APIs but might need customization (route_maps) for specific cases (e.g., a GET request that does have side effects should be mapped to a Tool).\nAuthentication: The provided httpx.AsyncClient needs to be configured with any necessary authentication (API keys, tokens) required by the backend API. MCP-level authentication would need to be handled separately by the FastMCP server itself (e.g., by wrapping the generated server).\n\nConclusion: Architectural Flexibility with FastMCP v2\nFastMCP v2 significantly elevates the possibilities for structuring and creating MCP servers in Python. Beyond the ergonomic decorators, its advanced patterns offer powerful solutions:\n\nProxying elegantly bridges transport gaps and enables adding middleware layers.\nMounting facilitates modular design and code reuse for complex applications.\nOpenAPI/FastAPI Generation provides an unparalleled accelerator for exposing existing web APIs through the MCP standard.\n\nThese features, combined with the core ergonomic API, make FastMCP v2 a compelling choice for advanced developers looking to rapidly build, integrate, and scale sophisticated MCP solutions within the Python ecosystem. Understanding how these patterns are implemented internally – through client delegation for proxies, prefixed routing for mounts, and schema parsing/HTTP wrapping for generation – allows developers to leverage them effectively and troubleshoot potential issues.\nOur next post will shift focus to the enhanced FastMCP v2 Client and the powerful CLI workflow, exploring how they simplify interaction and deployment.\n"},"4-jlowin-fastmcp-tutes/Blogs/blog-4":{"slug":"4-jlowin-fastmcp-tutes/Blogs/blog-4","filePath":"4 jlowin-fastmcp tutes/Blogs/blog-4.md","title":"Blog 4: The Enhanced Client and CLI Workflow in FastMCP v2","links":["4-jlowin-fastmcp-tutes/Blogs/blog-1.md1","4-jlowin-fastmcp-tutes/Blogs/blog-1.md2","4-jlowin-fastmcp-tutes/Blogs/blog-6"],"tags":[],"content":"Blog 4: The Enhanced Client and CLI Workflow in FastMCP v2\nSeries: Deep Dive into the Model Context Protocol SDKs (Advanced Topics)\r\nPost: 4 of 12\nWhile much of the focus in Model Context Protocol (MCP) development often lies on the server-side implementation (Tools, Resources, Prompts), a capable and ergonomic client is essential for testing, programmatic interaction, and building applications that consume MCP services. Furthermore, a smooth development and deployment workflow is critical for developer productivity.\njlowin-fastmcp (FastMCP v2) significantly enhances both the client library and the command-line tooling compared to the baseline offerings in the official mcp package. This post dives into:\n\nThe fastmcp.Client: Its async context manager design, transport inference, simplified methods, raw result access, and support for client-side capabilities (Sampling/Roots).\nClient Transports: A closer look at the provided implementations (Stdio, SSE, WS, FastMCPTransport, uvx, npx).\nThe fastmcp CLI: Analyzing the dev, install, and run commands, their integration with uv, MCP Inspector, and Claude Desktop.\n\n1. The fastmcp.Client: High-Level Interaction\nFastMCP v2 introduces fastmcp.Client (src/fastmcp/client/client.py), a dedicated high-level client class designed for ease of use.\nKey Features:\n\nAsync Context Manager (async with Client(...)): Enforces proper connection management. The connection is established upon entering the async with block and automatically closed (transport disconnection, process termination for Stdio) upon exiting, even if errors occur.\nTransport Inference (infer_transport): The Client constructor cleverly infers the correct ClientTransport based on the input:\n\nFastMCP instance → FastMCPTransport (in-memory)\n.py file path → PythonStdioTransport\n.js file path → NodeStdioTransport\nhttp:// or https:// URL → SSETransport\nws:// or wss:// URL → WSTransport\nExplicit ClientTransport instance → Uses it directly.\r\nThis simplifies common connection scenarios.\n\n\nSimplified Methods: Provides intuitive async methods (list_tools, call_tool, read_resource, get_prompt, ping, etc.) that directly return the relevant data (e.g., list[Tool], list[Content]) or raise ClientError on tool execution errors (isError: true).\nRaw MCP Result Access: For advanced use or debugging, corresponding *_mcp methods (list_tools_mcp, call_tool_mcp, etc.) return the full MCP result object (e.g., ListToolsResult, CallToolResult), including metadata like nextCursor or the isError flag, without raising ClientError on tool failures.\nClient Capability Handlers: Directly accepts callbacks (sampling_handler, roots handler/list, log_handler, message_handler) in its constructor, simplifying the setup for handling server-initiated requests compared to the lower-level mcp.ClientSession. Uses helper functions (create_sampling_callback, create_roots_callback) internally.\nTimeout Configuration: read_timeout_seconds can be passed to the constructor.\n\nImplementation Insight (client/client.py):\nThe Client acts as a wrapper around an underlying mcp.ClientSession and a ClientTransport. The __aenter__ method uses the transport’s connect_session(**self._session_kwargs) context manager to get the streams and create/initialize the mcp.ClientSession. The high-level methods (call_tool, etc.) simply call the corresponding *_mcp method and then process the result (extracting data or raising ClientError).\n# Example Client Usage\nfrom fastmcp import Client\nfrom fastmcp.client.sampling import SamplingHandler # Import handler types\n \nasync def my_sampling_handler(...) -&gt; str: ...\nasync def my_log_handler(...) -&gt; None: ...\n \nasync def interact_with_server(server_ref):\n    client = Client(\n        server_ref, # Can be FastMCP obj, path, URL\n        sampling_handler=my_sampling_handler,\n        log_handler=my_log_handler,\n        read_timeout_seconds=datetime.timedelta(seconds=15)\n    )\n    async with client:\n        # Simplified methods\n        tools = await client.list_tools()\n        if &quot;add&quot; in [t.name for t in tools]:\n            try:\n                result_content = await client.call_tool(&quot;add&quot;, {&quot;a&quot;: 1, &quot;b&quot;: 2})\n                print(f&quot;Add result: {result_content[0].text}&quot;)\n            except ClientError as e:\n                print(f&quot;Tool call failed: {e}&quot;)\n \n        # Raw method\n        raw_result = await client.call_tool_mcp(&quot;add&quot;, {&quot;a&quot;: 5, &quot;b&quot;: 5})\n        if raw_result.isError:\n            print(&quot;Tool reported an error:&quot;, raw_result.content)\n        else:\n            print(&quot;Raw add result:&quot;, raw_result.content[0].text)\nComparison: This Client provides a significantly more user-friendly and robust interface than using the base mcp.ClientSession directly, especially regarding transport management, error handling for tools, and setting up client capabilities.\n2. Client Transports: Connecting the Dots\nFastMCP v2 provides a richer set of explicit ClientTransport implementations (client/transports.py) beyond the basic Stdio/SSE/WS/Memory found in the core mcp package.\n\nPythonStdioTransport / NodeStdioTransport: Explicit classes for running Python/JS scripts via Stdio. Allow specifying the exact interpreter path (python_cmd, node_cmd), args, env vars, and CWD.\nUvxStdioTransport / NpxStdioTransport (Experimental): Allow running MCP servers packaged as Python tools (via uvx) or NPM packages (via npx) without prior installation. This is powerful for quickly using community servers or tools in CI/CD. Relies on uv/npx being available in the environment.\nSSETransport / WSTransport: Standard HTTP/WebSocket transports. Allow passing custom headers (e.g., for authentication).\nFastMCPTransport: Key for testing. Connects directly to an in-memory FastMCP server instance, bypassing process/network layers for fast, reliable tests.\n\nImplementation Insight: These transports implement the ClientTransport abstract base class, primarily the connect_session async context manager. Stdio transports use mcp.client.stdio.stdio_client internally. Network transports use mcp.client.sse.sse_client or mcp.client.websocket.websocket_client. The FastMCPTransport uses the special mcp.shared.memory.create_connected_server_and_client_session function.\n3. The fastmcp CLI: Streamlining Development &amp; Deployment\nPerhaps the most impactful DX improvement is the fastmcp CLI tool (cli/cli.py).\n\n\nfastmcp run &lt;file_spec&gt; [--transport ...]:\n\nPurpose: Executes a FastMCP server defined in a Python file. Supports file:object syntax to specify the server instance if not named mcp, server, or app. Allows overriding transport, host, port, log level via CLI options.\nMechanism: Parses the file spec, imports the server object dynamically using importlib, and calls the server’s .run() method with specified transport options.\nUse Case: Directly running servers for simple deployments or when embedding in other scripts. Note: Does not manage dependencies automatically.\n\n\n\nfastmcp dev &lt;file_spec&gt; [--with ...] [--with-editable ...]:\n\nPurpose: Runs the server in a development environment alongside the MCP Inspector web UI.\nMechanism:\n\nImports the server to discover its declared dependencies.\nConstructs a uv run command.\nAdds --with fastmcp and any server dependencies (--with &lt;dep&gt;) or local editable paths (--with-editable &lt;path&gt;) to the uv run command.\nConstructs the npx @modelcontextprotocol/inspector [...] command, passing the entire uv run ... fastmcp run &lt;file_spec&gt; command as arguments to npx. Optionally passes --ui-port / --server-port via environment variables.\nExecutes the npx command, which starts the Inspector UI and the proxy server, which in turn uses uv run to execute the user’s server in an isolated, dependency-managed environment.\n\n\nUse Case: The recommended way to test and debug servers during development. Provides immediate visual feedback via the Inspector and handles dependencies automatically.\n\n\n\nfastmcp install &lt;file_spec&gt; [--name ...] [--with ...] [-v KEY=VAL] [-f .env]:\n\nPurpose: Registers the MCP server with the Claude Desktop application for persistent use.\nMechanism:\n\nLocates the claude_desktop_config.json file (cli/claude.py).\nImports the server (if possible) to get its name and dependencies.\nConstructs the exact uv run --with ... fastmcp run &lt;file_spec&gt; command needed to execute the server, including all discovered and explicitly provided dependencies (--with/--with-editable). Uses resolved absolute path for the file spec.\nLoads environment variables from -v flags and/or --env-file.\nUpdates the mcpServers section in claude_desktop_config.json, adding or replacing the entry for server_name. Stores the full uv run command and any specified environment variables.\n\n\nUse Case: The primary way to deploy local Python MCP servers for use with Claude Desktop. Automates the complex task of ensuring the server runs with the correct dependencies in an isolated environment managed by uv.\n\n\n\nComparison &amp; Nuances:\n\nThis CLI workflow is far more sophisticated than the basic cli.ts in the TS SDK or the standard dotnet run/java -jar used for C#/Java.\nThe integration with uv for dependency management (dev, install) is a major advantage, avoiding pollution of the global or project environment.\nThe dev command’s automatic Inspector integration significantly speeds up debugging.\nThe install command makes deploying to Claude Desktop almost trivial for Python servers.\nRequires uv and potentially npx (for dev) to be installed and available on the PATH.\n\nConclusion: A Holistic Developer Experience\nFastMCP v2 significantly enhances the MCP client and developer workflow compared to the official mcp baseline. The high-level Client simplifies programmatic interactions with its transport inference, context management, and clear method structure. The expanded set of ClientTransport implementations, including the experimental uvx/npx runners, offers flexibility.\nHowever, the standout feature is the fastmcp CLI. The dev command provides an integrated test environment with the Inspector, while the install command, leveraging uv, offers a robust and user-friendly solution for deploying local Python servers, particularly targeting Claude Desktop. This focus on the complete development lifecycle – from coding to testing to deployment – makes FastMCP v2 a highly productive toolkit for advanced Python developers building within the MCP ecosystem.\nOur final post will synthesize the entire series, looking back at the comparisons across all four SDKs and contemplating the future of MCP and its tooling.\n"},"4-jlowin-fastmcp-tutes/Blogs/blog-5":{"slug":"4-jlowin-fastmcp-tutes/Blogs/blog-5","filePath":"4 jlowin-fastmcp tutes/Blogs/blog-5.md","title":"Blog 5: Synthesis - Testing, Extensibility (`contrib`), and Future Perspective for FastMCP v2","links":["4-jlowin-fastmcp-tutes/Blogs/blog-1","4-jlowin-fastmcp-tutes/Blogs/blog-2","4-jlowin-fastmcp-tutes/Blogs/blog-3","4-jlowin-fastmcp-tutes/Blogs/blog-4"],"tags":[],"content":"Blog 5: Synthesis - Testing, Extensibility (contrib), and Future Perspective for FastMCP v2\nSeries: Deep Dive into the Model Context Protocol SDKs (Advanced Topics)\r\nPost: 5 of 5 (FastMCP v2 Deep Dive)\nOur focused exploration of jlowin-fastmcp (FastMCP v2) is drawing to a close. We’ve seen how it positions itself as an enhanced layer over the official mcp package, how its ergonomic server API simplifies development with decorators and type inference, how it enables advanced server patterns like proxying and generation, and how its enhanced client and CLI streamline interaction and deployment.\nIn this concluding post, we synthesize these findings, focusing on crucial aspects for advanced development and adoption:\n\nTesting Strategies: Leveraging FastMCP v2’s features for effective testing.\nExtensibility: Understanding the contrib package and customization potential.\nFastMCP v2’s Niche: Where does it fit in the broader MCP ecosystem?\nFuture Perspective: Potential evolution and the relationship with the official SDK.\n\n1. Effective Testing with FastMCP v2\nTesting MCP servers can be complex due to their interactive and often stateful nature. FastMCP v2 provides specific features that greatly simplify this process:\n\n\nIn-Memory Testing (FastMCPTransport): This is the cornerstone of efficient testing. By passing the FastMCP server instance directly to the fastmcp.Client constructor, the client automatically uses the FastMCPTransport.\n\nMechanism: Uses mcp.shared.memory.create_connected_server_and_client_session internally. This bypasses all transport layers (Stdio, network), process management, and serialization. Client method calls effectively become direct calls to the server’s handling logic via in-memory queues/streams managed by the underlying mcp session objects.\nBenefits: Extremely fast execution, no port conflicts, no process cleanup needed, easy debugging within a single process. Ideal for unit and integration tests of server logic (Tools, Resources, Prompts).\nExample (tests/client/test_client.py): Most tests in the repository leverage this pattern, using pytest fixtures to create the server instance and passing it to the client.\n\n# Simplified pytest example\nimport pytest\nfrom fastmcp import FastMCP, Client\n \n@pytest.fixture\ndef mcp_server() -&gt; FastMCP:\n    mcp = FastMCP()\n    @mcp.tool()\n    def echo(msg: str) -&gt; str: return msg\n    return mcp\n \n@pytest.mark.asyncio\nasync def test_echo_tool(mcp_server: FastMCP):\n    # Pass server instance directly to client -&gt; FastMCPTransport used\n    async with Client(mcp_server) as client:\n        result = await client.call_tool(&quot;echo&quot;, {&quot;msg&quot;: &quot;test&quot;})\n        assert result[0].text == &quot;test&quot;\n\n\nUnit Testing Handlers:\n\nDecorated functions can often be tested directly by importing them.\nIf the handler uses the Context object, create a mock context (unittest.mock.Mock or pytest-mock) or instantiate a basic Context (though its methods might fail outside a real request cycle unless mocked). Mock external dependencies as usual.\n\n\n\nEnd-to-End Testing (CLI):\n\nUse fastmcp run or fastmcp dev within test scripts (using subprocess) to test the server via its actual intended transport (Stdio or SSE) and interact using a separately launched fastmcp.Client configured with the appropriate transport (PythonStdioTransport, SSETransport). This validates the full stack but is slower and more complex to manage. Testcontainers could also be used if deploying the server via Docker.\n\n\n\nComparison: The built-in FastMCPTransport offers a significant DX advantage for testing compared to manually setting up mock transports or in-memory channels required by some other SDKs (like C# or Java’s core testing utilities, though they do provide helpers).\n2. Extensibility: The contrib Package and Beyond\nFastMCP v2 encourages community contributions and specialized extensions through its src/fastmcp/contrib/ directory.\n\nPurpose: Houses modules providing functionality beyond the core MCP spec or core FastMCP abstractions, often addressing specific patterns or integrations. Maintained with potentially different stability guarantees than the core library.\nCurrent Examples:\n\nbulk_tool_caller: Adds tools (call_tools_bulk, call_tool_bulk) to an existing FastMCP server allowing clients to invoke multiple underlying tool calls with a single MCP request, potentially reducing network latency overhead. It uses the FastMCPTransport internally to call back into the server it’s attached to.\nmcp_mixin: Provides an MCPMixin base class and decorators (@mcp_tool, @mcp_resource, @mcp_prompt) allowing developers to define MCP components as methods within a class and then register them en masse from an instance of that class onto a FastMCP server, optionally with prefixes. Useful for organizing larger applications.\n\n\nCustomization:\n\nCustom Serializers: Pass a tool_serializer function to the FastMCP constructor to control how non-standard tool results are converted to string content (Blog 3).\nCustom Route Maps (OpenAPI/FastAPI): Provide custom RouteMap lists to from_openapi/from_fastapi to override default HTTP method → MCP primitive mapping.\nSubclassing FastMCP: Possible for deep customization, but requires understanding the internal managers and interaction with the underlying mcp server.\nCustom Transports: While the Client accepts ClientTransport instances, adding custom server-side transports currently requires more significant integration, likely at the level of the underlying mcp library or by adapting the ASGI application structure used by FastMCP.run(transport=&quot;sse&quot;).\n\n\n\nComparison: The contrib model provides a clear pathway for extending FastMCP without bloating the core library, similar in spirit to Django’s contrib apps or Flask extensions. The mixin pattern (MCPMixin) offers an alternative object-oriented registration style compared to the primary decorator approach.\n3. FastMCP v2’s Niche in the Ecosystem\nGiven that FastMCP v1 is part of the official mcp package, where does FastMCP v2 fit?\n\nThe Ergonomic Power User Tool: It’s designed for Python developers who prioritize rapid development, clean APIs (decorators, context), powerful integration features (OpenAPI/FastAPI generation, proxying, mounting), and a smooth local development/deployment experience (CLI + uv + Inspector/Claude Desktop).\nBridging and Integration Hub: Its proxying and generation capabilities make it uniquely suited for bringing existing systems (Stdio tools, Web APIs) into the MCP ecosystem quickly. Mounting allows building complex applications from smaller, reusable MCP services.\nPrototyping and Research: The speed of defining tools/resources via decorators combined with the integrated testing (FastMCPTransport, dev command) makes it excellent for experimentation.\nPython-Centric Environments: It’s the most feature-rich Python-native option for building complex MCP servers and clients currently available.\n\nIt complements the official mcp package by providing a more opinionated, feature-packed layer on top. It’s less about implementing the bare spec and more about providing a productive framework for building MCP applications in Python.\n4. Future Perspective: Collaboration and Convergence?\nFastMCP v2’s existence as a separate project raises interesting questions:\n\nRelationship with Official SDK: Will popular features from v2 (like OpenAPI generation, enhanced CLI, improved client) eventually be merged back into the official modelcontextprotocol/python-sdk? Or will they remain separate, offering users a choice between a core implementation and an extended framework? Close collaboration seems likely given the shared history.\nTransport Evolution: Will FastMCP v2 adopt Streamable HTTP (like TS/C#) to gain resumability, or will it continue leveraging the official mcp package’s focus on HTTP+SSE for web transport? Adding Streamable HTTP would significantly enhance its web capabilities.\nFeature Gaps: Will features like built-in OAuth server support or dynamic capability handles (from the TS SDK) be added? Or will the philosophy remain focused on leveraging the broader Python ecosystem (e.g., FastAPI/Starlette middleware for auth)?\nCommunity Growth: The contrib package and the project’s clear extension points offer fertile ground for community contributions to flourish.\n\nFastMCP v2 currently occupies a sweet spot for Python developers wanting cutting-edge features and maximum DX for MCP development. Its future likely involves continued innovation, close observation of the evolving MCP specification, and ongoing dialogue with the maintainers of the official SDKs.\nFinal Synthesis\njlowin-fastmcp (FastMCP v2) is a powerful and highly ergonomic framework built upon the official Python MCP SDK. It excels in simplifying server definition through decorators and type inference, provides advanced architectural patterns like proxying, mounting, and OpenAPI/FastAPI generation, and significantly enhances the developer workflow with its feature-rich client and integrated CLI tooling (especially uv, Inspector, and Claude Desktop support).\nIts in-memory testing capabilities (FastMCPTransport) are a major boon for building reliable applications. While it inherits the HTTP+SSE transport focus from its underlying dependency and lacks some advanced features present in the TypeScript SDK, it represents the state-of-the-art for productive, Pythonic MCP development today. For advanced Python users building complex integrations or prioritizing rapid development and seamless local deployment, FastMCP v2 offers a compelling and feature-packed solution.\n\nThank you for following this advanced deep dive into the MCP SDKs! We hope this series provided valuable technical insights into the specification and its cross-language implementations."},"4-jlowin-fastmcp-tutes/README":{"slug":"4-jlowin-fastmcp-tutes/README","filePath":"4 jlowin-fastmcp tutes/README.md","title":"README","links":[],"tags":[],"content":"\njlowin-fastmcp tutes\n"},"4-jlowin-fastmcp-tutes/index":{"slug":"4-jlowin-fastmcp-tutes/index","filePath":"4 jlowin-fastmcp tutes/index.md","title":"4 jlowin-fastmcp tutes","links":[],"tags":[],"content":""},"5-punkpeye-fastmcp-tutes/125_model":{"slug":"5-punkpeye-fastmcp-tutes/125_model","filePath":"5 punkpeye-fastmcp tutes/125_model.md","title":"125_model","links":[],"tags":[],"content":"Okay, let’s break down the punkpeye-fastmcp TypeScript repository.\nProject Overview:\nThis repository provides a TypeScript framework for building Model Context Protocol (MCP) servers. Crucially, it is inspired by the Python jlowin/fastmcp project and explicitly positions itself as a higher-level abstraction built on top of the official @modelcontextprotocol/sdk (TypeScript). It aims to provide a more ergonomic and feature-rich experience for defining MCP servers in TypeScript, particularly focusing on simplifying the definition of Tools, Resources, and Prompts, and adding features like session management and easier transport handling.\nPurpose &amp; Value Proposition:\nThe main goal is to enhance the developer experience (DX) for building MCP servers in TypeScript by:\n\nSimplifying Primitive Definition: Offering addTool, addResource, addPrompt methods instead of requiring direct use of the official SDK’s lower-level Server.setRequestHandler.\nFlexible Schema Input: Supporting popular validation libraries (Zod, ArkType, Valibot) adhering to the “Standard Schema” concept for defining tool parameters, automatically converting them to JSON Schema internally.\nErgonomic Handlers: Providing a simpler handler signature (execute/load functions) that receives parsed arguments and a dedicated Context object.\nSession Management: Explicitly modeling and managing client sessions (FastMCPSession).\nBuilt-in Helpers: Providing utility functions like imageContent and audioContent.\nSimplified Server Startup: Offering a straightforward server.start() method to configure and run underlying transports (Stdio, SSE).\nDeveloper Tooling: Integrating with external CLI/Inspector tools via its own basic fastmcp CLI wrapper.\n\nKey Features &amp; Implementation Details:\n\nCore Server Class (src/FastMCP.ts):\n\nThe central FastMCP class orchestrates server definition and execution.\nConstructor takes ServerOptions (name, version, instructions, importantly, an authenticate function).\nUses addTool, addResource, addResourceTemplate, addPrompt methods for registering primitives.\nUnderlying SDK: Internally, it likely creates and manages an instance of the official @modelcontextprotocol/sdk’s Server. The add* methods configure the necessary low-level request handlers on this internal server instance.\nSchema Conversion: Accepts Zod/ArkType/Valibot schemas via the parameters property in addTool (or inferred for prompts/templates). Uses libraries like xsschema or zod-to-json-schema internally to convert these into the JSON Schema format required by MCP’s listTools response or for internal validation.\nHandler Execution: Wraps the user-provided execute (for tools) or load (for resources/prompts) functions. Before calling the user’s function, it likely uses the underlying official SDK’s Zod-based validation (if Zod was provided) or performs validation based on the generated JSON Schema. It then injects the parsed args and the Context object.\nContext Object: Provides handlers with simplified access to logging (log.info, etc.), progress reporting (reportProgress), and session data (session).\nSession Management: Tracks connected clients via FastMCPSession instances, likely mapping transport connections to sessions. Exposes sessions via the sessions property and emits connect/disconnect events.\nEvent Emitter: Uses Node.js EventEmitter for server (connect, disconnect) and session (error, rootsChanged) events.\n\n\nSchema Flexibility:\n\nLeverages the “Standard Schema” concept, allowing developers to use Zod, ArkType, or Valibot for defining tool parameters, abstracting the conversion to JSON Schema.\n\n\nContent Helpers (src/FastMCP.ts):\n\nProvides imageContent and audioContent async helper functions that accept URLs, paths, or Buffers and return correctly formatted ImageContent or AudioContent objects (handling MIME type detection and base64 encoding).\n\n\nAuthentication Hook (ServerOptions.authenticate):\n\nProvides a simple hook for custom authentication logic. The function receives the raw incoming HTTP request (presumably for SSE) and should return session data (of generic type T) on success or throw/return an HTTP Response (like new Response(null, { status: 401 })) on failure. The returned session data is made available as context.session.\nNote: This is simpler than the full OAuth framework in the official TS SDK but more flexible than having no hook at all.\n\n\nTransport Management (FastMCP.start()):\n\nSimplifies starting the server on a specific transport.\ntransportType: &#039;stdio&#039;: Creates and connects the underlying official SDK Server to an StdioServerTransport.\ntransportType: &#039;sse&#039;: Uses the external mcp-proxy library’s startSSEServer function (likely a helper around Node http and the official SDK’s SSEServerTransport) to launch an HTTP server handling the legacy SSE dual-endpoint protocol.\nNote: No explicit mention or option for Streamable HTTP server transport. It appears to rely on the legacy SSE transport provided by the official SDK via mcp-proxy.\n\n\nCLI Tool (src/bin/fastmcp.ts):\n\nA simple wrapper CLI built with yargs.\ndev: Uses execa to run npx @wong2/mcp-cli (a separate community CLI tool) against the user’s server file.\ninspect: Uses execa to run npx @modelcontextprotocol/inspector (the official Inspector) against the user’s server file (using tsx to run TS directly).\nNote: This CLI acts primarily as a launcher for external tools, unlike the Python FastMCP v2 CLI which has significant built-in functionality.\n\n\nTooling &amp; Ecosystem:\n\nBuild: Uses tsup for building JavaScript output from TypeScript source.\nTesting: Uses vitest. Includes unit tests (FastMCP.test.ts).\nLinting/Formatting: ESLint and Prettier.\nPublishing: Configured for semantic-release and publishing to both NPM and JSR.\nDependencies: @modelcontextprotocol/sdk (core dependency), Zod (primary schema lib), @standard-schema/spec, xsschema, zod-to-json-schema (schema handling), execa, yargs (CLI), mcp-proxy (SSE server helper), file-type, undici (fetch), uri-templates, etc.\n\n\n\nRelationship to Official SDK &amp; Python FastMCP:\n\nOfficial TS SDK: Acts as a higher-level abstraction layer over the official SDK’s Server. It uses the official SDK’s core types, protocol handling, and transport implementations internally but provides a more opinionated and arguably more ergonomic API for defining the server logic. It hides some of the lower-level details like setRequestHandler.\nPython FastMCP v2: This project is clearly inspired by jlowin/fastmcp, adopting the FastMCP naming and the focus on ergonomic server definition. However, the implementations differ significantly due to language differences (e.g., decorators vs. add* methods, Pydantic vs. Zod/StandardSchema, anyio vs. Node async). Python’s v2 has more advanced features like proxying, mounting, and OpenAPI generation, and a much more powerful CLI. This TS version seems focused primarily on the ergonomic server definition aspect and session management.\n\nStrengths:\n\nErgonomic Server Definition: Simplifies registering Tools, Resources, Prompts compared to the official SDK’s low-level handlers.\nSchema Flexibility: Support for Zod, ArkType, Valibot via Standard Schema is a nice abstraction.\nBuilt-in Helpers: imageContent/audioContent helpers are convenient.\nSession Management: Explicitly surfaces session concepts.\nSimplified Startup: server.start() abstracts transport setup.\nEvent Emitter: Provides familiar Node.js event patterns for lifecycle events.\nJSR Support: Publishing to JSR broadens accessibility (Deno users).\n\nPotential Considerations / Weaknesses:\n\nAbstraction Layer: Adds another layer on top of the official SDK, which could potentially introduce its own bugs or lag behind official SDK updates.\nTransport Limitation: Appears to only support Stdio and the legacy HTTP+SSE transport via mcp-proxy. Crucially, it lacks built-in support for the modern Streamable HTTP transport, missing out on its efficiency and resumability features present in the official TS SDK itself.\nLimited Advanced Features: Doesn’t include the proxying, mounting, or generation features of Python’s FastMCP v2. Lacks the official TS SDK’s built-in OAuth server framework.\nCLI Simplicity: The CLI is just a launcher for external tools, lacking the dependency/environment management of its Python counterpart.\nMaturity/Adoption: As a community project, its maintenance and adoption level compared to the official SDKs might be a factor for some users.\n\nConclusion:\npunkpeye-fastmcp is a valuable TypeScript framework for developers who want a more ergonomic and simplified experience for building MCP servers compared to using the official @modelcontextprotocol/sdk directly. It successfully abstracts away much of the handler registration boilerplate, offers flexibility in schema definition, provides useful helpers, and introduces explicit session management. Its primary strength lies in this enhanced developer experience for defining server primitives.\nHowever, advanced users should be aware that it acts as a layer over the official SDK and currently appears limited to the older HTTP+SSE transport model for web communication, lacking the benefits of Streamable HTTP. It also doesn’t replicate the more advanced server patterns (proxying, mounting, generation) or the sophisticated CLI found in the Python FastMCP v2 project it draws inspiration from. It’s best suited for developers prioritizing ease of server definition in TypeScript over access to the absolute latest transport features or built-in OAuth capabilities found in the core official SDK."},"5-punkpeye-fastmcp-tutes/127_model":{"slug":"5-punkpeye-fastmcp-tutes/127_model","filePath":"5 punkpeye-fastmcp tutes/127_model.md","title":"127_model","links":[],"tags":[],"content":"Okay, here is a 5-part blog series plan for a deep dive into the punkpeye-fastmcp TypeScript codebase. This plan targets advanced users, focusing on its internal workings, design choices, relationship to the official SDK, and end-user implications.\nTarget Audience: Experienced TypeScript/Node.js developers, developers familiar with MCP concepts (possibly from other SDKs), those evaluating higher-level MCP frameworks in TS.\nOverall Goal: To provide a technically deep analysis of the punkpeye-fastmcp framework, dissecting its abstractions, implementation details, and trade-offs compared to using the official @modelcontextprotocol/sdk directly, and evaluating its suitability for building advanced, ergonomic MCP servers in TypeScript.\n\nBlog Series: Dissecting punkpeye-fastmcp - An Ergonomic TypeScript MCP Framework\nBlog 1: Introduction - Positioning punkpeye-fastmcp in the TypeScript Ecosystem\n\nCore Focus: Introduce punkpeye-fastmcp, clarify its purpose as a higher-level framework built upon the official @modelcontextprotocol/sdk, outline its key value proposition (developer experience, schema flexibility), and set the stage for the deep dive. Contrast with the official SDK’s lower-level approach.\nKey Code Areas: README.md, package.json (dependencies like @modelcontextprotocol/sdk, zod, xsschema, mcp-proxy), src/FastMCP.ts (main class signature), jsr.json.\nKey Concepts: Recap MCP basics (Tool, Resource, Prompt). Explain the “framework vs. SDK core” distinction. Introduce the “Standard Schema” concept for input validation flexibility. Highlight inspiration from Python’s FastMCP.\nImplementation Deep Dive: Examine the core dependencies. Discuss the high-level structure of the FastMCP class and its role as an orchestrator wrapping the official Server internally (conceptual). Outline the build process (tsup).\nNuanced Take / End-User Angle: Why might a developer choose this framework over the official SDK? Focus on the trade-offs: potentially faster development and schema flexibility vs. an added layer of abstraction, reliance on specific (potentially legacy) transport wrappers (mcp-proxy for SSE), and potential lag behind official SDK features. How does this choice impact the eventual features and reliability users experience?\n\nBlog 2: Simplified Primitives - addTool, addResource, addPrompt Internals\n\nCore Focus: Analyze how punkpeye-fastmcp simplifies the definition and registration of MCP Tools, Resources, and Prompts compared to the official SDK’s Server.setRequestHandler.\nKey Code Areas: src/FastMCP.ts (implementation of addTool, addResource, addResourceTemplate, addPrompt methods), usage examples (src/examples/addition.ts). Examine dependency usage (zod-to-json-schema, xsschema).\nKey Concepts: Abstraction over handler registration, Standard Schema usage (Zod, ArkType, Valibot input), automatic JSON Schema generation, simplified handler signatures (execute/load), content helper functions (imageContent, audioContent).\nImplementation Deep Dive: Trace how addTool likely works internally:\n\nAccepts user schema (Zod, etc.).\nUses xsschema/zod-to-json-schema to convert it to standard JSON Schema (for tools/list).\nCreates a wrapper function around the user’s execute function.\nThis wrapper likely receives the raw JsonRpcRequest and RequestHandlerExtra from the underlying official Server.\nIt uses the original user schema (e.g., Zod) to parse and validate request.params.arguments.\nIt creates the simplified Context object.\nIt calls the user’s execute function with parsed args and context.\nIt converts the handler’s return value (string, object, Content array) into the required CallToolResult format.\nIt registers this wrapper function with the underlying official Server using server.setRequestHandler(CallToolRequestSchema, wrapper).\nAnalyze similar flows for addResource/addPrompt. Examine the imageContent/audioContent helpers (fetching, encoding, MIME type detection).\n\n\nNuanced Take / End-User Angle: Evaluate the DX win: How much boilerplate is removed? What are the performance implications of runtime schema conversion and handler wrapping? Does the flexibility of supporting multiple schema libraries add significant value or complexity? How do content helpers impact the ease of returning rich media to users?\n\nBlog 3: Sessions, Context, and Lifecycle Management\n\nCore Focus: Explore how punkpeye-fastmcp manages client connections, provides contextual information to handlers, and handles the server lifecycle.\nKey Code Areas: src/FastMCP.ts (FastMCP class constructor, start/stop methods, sessions property, authenticate option, Context type definition, FastMCPSession class, event emitter usage).\nKey Concepts: Session tracking, Authentication hook, Context object pattern, server events (connect/disconnect), session events (error/rootsChanged).\nImplementation Deep Dive: Analyze how sessions (FastMCPSession) are created and stored when a client connects (likely tied to the onConnect/onClose callbacks from the transport/mcp-proxy). How does the authenticate function integrate with session creation? How is the Context object instantiated and populated for each handler call (access to session auth data, logging, progress reporting methods)? Examine the implementation of context.log.* and context.reportProgress – how do they map to underlying official SDK sendNotification calls? Trace the start and stop logic and how it manages the underlying transport and session cleanup. How does FastMCPSession handle roots/list requests and roots/list_changed notifications?\nNuanced Take / End-User Angle: Does the explicit session object provide tangible benefits over managing state implicitly? How robust is the simple authenticate hook compared to a full OAuth implementation (like in the official TS SDK)? What are the scalability implications of storing session instances in the main FastMCP object’s memory? How do server/session events help build monitoring or dynamic features?\n\nBlog 4: Transports and Tooling - Under the Wrapper\n\nCore Focus: Investigate the specific transport implementations supported (stdio, legacy sse) and the functionality of the provided CLI wrapper.\nKey Code Areas: src/FastMCP.ts (start method logic for ‘stdio’ and ‘sse’), package.json (dependency on mcp-proxy), src/bin/fastmcp.ts (CLI implementation using yargs and execa).\nKey Concepts: Stdio transport, HTTP+SSE transport (legacy dual-endpoint), reliance on external libraries/tools (mcp-proxy, @wong2/mcp-cli, @modelcontextprotocol/inspector).\nImplementation Deep Dive:\n\nStdio: How does start({ transportType: &#039;stdio&#039; }) instantiate and connect the official StdioServerTransport to the internal Server?\nSSE: Analyze the use of mcp-proxy’s startSSEServer. What does this function likely do? (Probably creates an http.Server, sets up /sse and /message handlers, and uses the official SSEServerTransport internally, managing session mapping). Crucially, confirm the lack of Streamable HTTP server support. Discuss the implications.\nCLI: Examine the bin/fastmcp.ts script. How does it use yargs to parse arguments? How does it use execa to launch mcp-cli or inspector with the user’s server file (and tsx for direct TypeScript execution)? Evaluate its role – is it essential, or just a convenience launcher?\n\n\nNuanced Take / End-User Angle: The biggest point here is the transport limitation. Relying on legacy SSE via mcp-proxy means servers built with this framework won’t support Streamable HTTP features like resumability when accessed over the web. How does this impact users of long-running tools? Compare the developer convenience of server.start() vs. manually setting up transports with the official SDK. Is the CLI wrapper a significant DX improvement over direct npx commands?\n\nBlog 5: Synthesis - DX Trade-offs, Use Cases, and Ecosystem Fit\n\nCore Focus: Summarize the key findings, evaluate the strengths and weaknesses of punkpeye-fastmcp for advanced users, identify ideal use cases, and discuss its position relative to the official SDK and other implementations (like Python’s FastMCP v2).\nKey Topics: Recap: Ergonomic API (add* methods, Context), schema flexibility, content helpers, session management, simplified startup, basic CLI. Limitations: Legacy SSE only, no Streamable HTTP server, no built-in OAuth server, no advanced patterns (proxy/mount/gen), added abstraction layer.\nComparison:\n\nvs. Official TS SDK: Easier primitive definition, schema flexibility, built-in helpers vs. More direct control, Streamable HTTP, built-in OAuth server, dynamic handles.\nvs. Python FastMCP v2: Similar ergonomic goals but Python has more advanced patterns (proxy/mount/gen) and a vastly superior CLI. TS version has stronger typing guarantees via Zod integration within handlers.\n\n\nIdeal Use Cases: Rapid prototyping of MCP servers in TS, projects where legacy SSE transport is acceptable, developers prioritizing simplified server definition over access to the very latest transport features or built-in OAuth, teams comfortable using multiple schema validation libraries.\nNuanced Take / End-User Angle: punkpeye-fastmcp demonstrably speeds up the initial development of MCP server features in TypeScript by reducing boilerplate. This can lead to faster feature delivery for users. However, the reliance on legacy SSE for web transport might negatively impact the reliability of long-running operations for web users compared to servers built directly with the official SDK using Streamable HTTP. The lack of a built-in OAuth server means developers still need significant effort to secure web-facing servers properly. Is the DX gain worth the potential transport limitations and feature lag compared to the official SDK? Discuss the project’s maintenance status and future alignment with the core MCP spec and official SDK.\n\n\nThis 5-part plan provides a critical, in-depth look at punkpeye-fastmcp, evaluating its technical implementation, comparing it explicitly to the official SDK it wraps, and analyzing the practical consequences for advanced developers and the end-users of the applications they build."},"5-punkpeye-fastmcp-tutes/Blogs/blog-1":{"slug":"5-punkpeye-fastmcp-tutes/Blogs/blog-1","filePath":"5 punkpeye-fastmcp tutes/Blogs/blog-1.md","title":"Blog 1: Introduction - Positioning `punkpeye-fastmcp` in the TypeScript Ecosystem","links":[],"tags":[],"content":"Blog 1: Introduction - Positioning punkpeye-fastmcp in the TypeScript Ecosystem\nSeries: Deep Dive into the Model Context Protocol SDKs (Advanced Topics)\r\nPost: 1 of 12\nWelcome to this advanced technical dive into the expanding ecosystem surrounding the Model Context Protocol (MCP). For those following the evolution of AI integration, MCP (spec) presents a compelling standard for enabling rich, contextual communication between Large Language Models (LLMs) and diverse applications. The official SDKs provide the foundational building blocks, but as with many protocols, higher-level frameworks often emerge to enhance developer experience (DX) and tackle specific patterns.\nThis series focuses on one such framework in the TypeScript world: punkpeye-fastmcp. Inspired by the ergonomic design of its Python counterpart (jlowin/fastmcp), this library aims to be “A TypeScript framework for building MCP servers,” offering a more abstract and potentially simpler interface than the official @modelcontextprotocol/sdk.\nThis series is tailored for experienced TypeScript developers, SDK implementers, and researchers already familiar with MCP basics. We will dissect punkpeye-fastmcp’s internal mechanisms, compare its design choices against the official SDK, evaluate its strengths and weaknesses for advanced use cases, and consider its place within the broader TypeScript MCP landscape.\nWhat is punkpeye-fastmcp? A Framework, Not Just an SDK\nIt’s crucial to understand that punkpeye-fastmcp is positioned as a framework layer built on top of the official @modelcontextprotocol/sdk. It doesn’t reimplement the core MCP logic or transport mechanisms from scratch. Instead, it aims to provide a more opinionated and streamlined API for common server development tasks.\nCore Value Proposition:\n\nErgonomic Primitive Definition: Simplifies registering Tools, Resources, and Prompts via addTool, addResource, addPrompt methods instead of lower-level handler registrations.\nSchema Flexibility: Adopts the “Standard Schema” concept, allowing developers to define tool parameters using popular libraries like Zod, ArkType, or Valibot, handling the conversion to JSON Schema internally.\nSimplified Handler Signature: Provides a Context object to handler functions (execute/load), abstracting away some details of the official SDK’s RequestHandlerExtra.\nIntegrated Session Management: Explicitly models and tracks client sessions (FastMCPSession).\nConvenience Helpers: Includes utilities like imageContent and audioContent for easier media handling.\nSimplified Startup: Offers a basic server.start() method to initialize common transports (Stdio, legacy SSE).\n\nRelationship to the Official @modelcontextprotocol/sdk\nThis is the most critical point for advanced users: punkpeye-fastmcp depends directly on @modelcontextprotocol/sdk. You’ll find it listed in the package.json:\n// package.json (simplified)\n&quot;dependencies&quot;: {\n    &quot;@modelcontextprotocol/sdk&quot;: &quot;^1.10.2&quot;,\n    // ... other dependencies ...\n}\nThis means:\n\nCore Protocol Logic: The underlying JSON-RPC handling, request/response correlation, timeout management, and core session state are likely handled by the official SDK’s internal Protocol and McpSession classes.\nCore Types: It uses the types.ts definitions (e.g., CallToolResult, ReadResourceResult, JSONRPCMessage) from the official SDK.\nTransport Implementations: When server.start() is called, it likely instantiates and uses the official SDK’s StdioServerTransport or SSEServerTransport (potentially via the mcp-proxy helper for SSE).\nWrapper/Facade: punkpeye-fastmcp essentially acts as a facade or abstraction layer, providing its simplified API by translating calls into the necessary configurations and interactions with the underlying official Server instance it manages internally.\n\nInspiration: Python’s jlowin/fastmcp\nThis project explicitly draws inspiration from the Python jlowin/fastmcp (FastMCP v2). While sharing the name and the goal of improved DX, the implementations differ significantly due to language paradigms:\n\nPython: Uses decorators (@mcp.tool) and heavy runtime introspection/Pydantic model generation. Has advanced proxy/mount/generation features and a powerful CLI.\nTypeScript: Uses explicit methods (addTool), leverages compile-time typing and Zod/Standard Schema integration, has a simpler CLI wrapper, and currently lacks the proxy/mount/generation features.\n\nA Quick Look Inside the Codebase\n\nsrc/FastMCP.ts: The heart of the framework, defining the main FastMCP class, the FastMCPSession class, the Context type, and the add* methods. This is where the abstraction logic resides.\nsrc/bin/fastmcp.ts: Implements the simple CLI wrapper using yargs and execa to launch external tools like @wong2/mcp-cli or the official inspector.\nDependencies: Key external dependencies include @modelcontextprotocol/sdk (core), zod (default schema), xsschema/zod-to-json-schema (for schema conversion), mcp-proxy (likely for SSE server setup), execa/yargs (CLI).\nBuild: Standard TypeScript setup using tsc for type checking and tsup for building distributable JavaScript. Configuration in tsconfig.json and package.json.\n\nNuanced Take: The Advanced Developer’s Perspective\nFor experienced developers evaluating punkpeye-fastmcp, several trade-offs emerge compared to using the official @modelcontextprotocol/sdk directly:\nPotential Advantages:\n\nReduced Boilerplate: The add* methods and automatic schema handling significantly simplify the registration of standard Tools, Resources, and Prompts. This can accelerate development, especially for servers with many primitives.\nSchema Library Choice: Supporting multiple validation libraries (Zod, ArkType, Valibot) via Standard Schema offers flexibility if a team has a preference or existing investment.\nSimplified Context: The injected Context object might feel more straightforward for common tasks (logging, progress) than the official SDK’s RequestHandlerExtra.\nSession Abstraction: Explicitly modeling FastMCPSession could simplify building session-aware features or monitoring.\n\nPotential Drawbacks &amp; Considerations:\n\nAbstraction Overhead: Introducing a framework layer adds complexity. Debugging issues might require tracing calls through both punkpeye-fastmcp and the underlying official SDK. Performance overhead, while likely small, exists due to wrapping and schema conversion.\nTransport Limitations: The biggest concern is the apparent reliance on the legacy HTTP+SSE transport (via mcp-proxy) for web communication. It lacks built-in support for the modern Streamable HTTP transport defined in the latest MCP specs and implemented in the official TS/C# SDKs. This means missing out on:\n\nSingle Endpoint Efficiency: Streamable HTTP uses one primary endpoint instead of SSE’s dual GET/POST.\nResumability: No built-in way to leverage EventStore for recovering from dropped connections during long operations.\n\n\nFeature Lag: Being a community project built on the official SDK, it may lag behind in adopting new features or specification changes introduced in @modelcontextprotocol/sdk (e.g., refined capabilities, potential future transport enhancements).\nLimited Advanced Features: It currently lacks the sophisticated server patterns (proxying, mounting, OpenAPI generation) found in jlowin/fastmcp, and the built-in OAuth server framework from the official TS SDK. Authentication relies on a simpler custom hook.\nMaintenance &amp; Community: Relies on the maintainer (punkpeye) and community for updates and bug fixes, which may have a different cadence than the official Anthropic-maintained SDKs.\n\nEnd-User Angle: Speed vs. Sophistication\nHow does the choice between punkpeye-fastmcp and the official SDK impact the end user?\n\nFaster Feature Development (Potentially): The ergonomic API might allow developers to implement and iterate on MCP features more quickly, getting them to users sooner.\nWeb Reliability (Potentially Lower): The lack of Streamable HTTP and resumability means web-based interactions involving long-running tools are more susceptible to irrecoverable failures due to network interruptions, leading to a potentially frustrating user experience in those scenarios.\nSecurity (Different Approach): The simple authenticate hook requires careful implementation by the developer. It lacks the standardized robustness (and complexity) of the full OAuth framework available in the official SDK.\n\nConclusion &amp; What’s Next\npunkpeye-fastmcp presents an interesting alternative for TypeScript developers seeking a higher-level, more ergonomic API for defining MCP servers than offered by the raw @modelcontextprotocol/sdk. Its strengths lie in simplified primitive registration, flexible schema definitions, and convenient helpers.\nHowever, advanced users must weigh this improved DX against the current reliance on the legacy SSE transport for web communication (missing Streamable HTTP’s benefits) and the absence of certain advanced features found in other SDKs (like built-in OAuth or Python’s server patterns). It’s a trade-off between immediate development speed for common tasks and access to the full feature set and potentially greater resilience offered by building directly on the official SDK.\nIn the next post, we will dive into the core of punkpeye-fastmcp’s appeal: Blog 2: Simplified Primitives - addTool, addResource, addPrompt Internals, examining exactly how these methods abstract the underlying official SDK mechanisms.\n"},"5-punkpeye-fastmcp-tutes/Blogs/blog-2":{"slug":"5-punkpeye-fastmcp-tutes/Blogs/blog-2","filePath":"5 punkpeye-fastmcp tutes/Blogs/blog-2.md","title":"Blog 2: Simplified Primitives - Inside `punkpeye-fastmcp`'s `addTool`, `addResource`, `addPrompt`","links":["5-punkpeye-fastmcp-tutes/Blogs/blog-1"],"tags":[],"content":"Blog 2: Simplified Primitives - Inside punkpeye-fastmcp’s addTool, addResource, addPrompt\nSeries: Deep Dive into the Model Context Protocol SDKs (Advanced Topics)\r\nPost: 2 of 12\nIn Blog 1, we introduced punkpeye-fastmcp as a TypeScript framework layered atop the official @modelcontextprotocol/sdk, primarily aimed at enhancing developer experience (DX). Its core promise lies in simplifying the definition of Model Context Protocol (MCP) server primitives: Tools, Resources, and Prompts.\nInstead of directly using the official SDK’s somewhat lower-level server.setRequestHandler for each MCP method (tools/list, tools/call, resources/read, etc.), punkpeye-fastmcp provides convenient addTool, addResource, addResourceTemplate, and addPrompt methods on its main FastMCP class.\nThis post dives into the internals of these add* methods. How do they work? What abstractions do they provide? And what are the implications for advanced developers? We’ll analyze their likely implementation based on the project’s structure, dependencies, and stated goals.\nThe Official SDK Way (Recap)\nTo appreciate the simplification, let’s recall how you’d register a Tool using only the official @modelcontextprotocol/sdk:\nimport { Server } from &quot;@modelcontextprotocol/sdk/server/index.js&quot;;\nimport { z } from &quot;zod&quot;;\nimport { CallToolRequestSchema, ListToolsRequestSchema, /* other types */ } from &quot;@modelcontextprotocol/sdk/types.js&quot;;\nimport { McpJsonUtilities } from &quot;@modelcontextprotocol/sdk/utils/json&quot;; // Assuming helper exists\n \nconst lowLevelServer = new Server(/* serverInfo, serverOptions */);\n \n// 1. Define Zod Schema for Arguments\nconst addArgsSchema = z.object({ a: z.number(), b: z.number() });\n \n// 2. Define JSON Schema for listing\nconst addJsonSchema = { // Manually create or generate from Zod\n    type: &quot;object&quot;,\n    properties: { a: { type: &quot;number&quot; }, b: { type: &quot;number&quot; } },\n    required: [&quot;a&quot;, &quot;b&quot;],\n};\n \n// 3. Register handler for tools/list\nlowLevelServer.setRequestHandler(ListToolsRequestSchema, async (req, extra) =&gt; {\n    // Logic to return list including &#039;add&#039; tool metadata\n    return {\n        tools: [\n            { name: &quot;add&quot;, description: &quot;Adds two numbers&quot;, inputSchema: addJsonSchema }\n            // ... other tools\n        ]\n    };\n});\n \n// 4. Register handler for tools/call\nlowLevelServer.setRequestHandler(CallToolRequestSchema, async (req, extra) =&gt; {\n    if (req.params.name === &quot;add&quot;) {\n        // 5. Manually validate args against Zod schema\n        const validationResult = addArgsSchema.safeParse(req.params.arguments);\n        if (!validationResult.success) {\n            throw new McpError(ErrorCode.InvalidParams, /* format error */);\n        }\n        const validatedArgs = validationResult.data;\n \n        // 6. Execute actual logic\n        const sum = validatedArgs.a + validatedArgs.b;\n \n        // 7. Format result\n        return { content: [{ type: &quot;text&quot;, text: String(sum) }] };\n    }\n    // ... handle other tools or throw MethodNotFound ...\n});\nThis involves manually:\n\nDefining Zod and JSON schemas.\nImplementing tools/list handler to return metadata.\nImplementing tools/call handler.\nInside tools/call: Routing based on name, validating arguments, executing logic, formatting results.\nSimilar manual setup required for Resources (resources/list, resources/templates/list, resources/read) and Prompts (prompts/list, prompts/get).\n\npunkpeye-fastmcp: The Abstraction Layer\npunkpeye-fastmcp aims to handle steps 2, 3, 4, 5, and 7 automatically via its add* methods.\n1. server.addTool(toolDefinition)\n\nInput (Tool type defined in FastMCP.ts): An object containing name, description?, parameters? (a Zod/ArkType/Valibot schema object adhering to Standard Schema), annotations?, and execute (the handler function).\nInternal Mechanism (Conceptual):\n\nStore Definition: Stores the provided toolDefinition (name, description, user schema, handler function, annotations) internally, likely in a collection within the FastMCP instance (e.g., this.#tools.push(toolDefinition)).\nGenerate JSON Schema: If not already done, uses zod-to-json-schema (if Zod provided) or xsschema (if ArkType/Valibot provided) to convert the toolDefinition.parameters into a standard JSON Schema object. Caches this.\nRegister tools/list Handler (Implicitly): The framework likely registers one central tools/list handler with the underlying official Server instance when the first tool is added (or overwrites any existing one). This central handler iterates through the internal this.#tools collection, extracts the stored metadata (name, description, annotations, generated JSON schema) for each tool, and formats the ListToolsResult.\nRegister tools/call Handler (Implicitly): Similarly, it likely registers one central tools/call handler with the underlying official Server. This handler:\n\nReceives the raw CallToolRequest and RequestHandlerExtra.\nUses request.params.name to look up the corresponding toolDefinition in this.#tools.\nThrows MethodNotFound if not found.\nRetrieves the stored user schema (Zod/etc.) from the definition.\nValidates request.params.arguments using the user schema’s .parse() or .validate() method. Catches validation errors and throws an McpError (ErrorCode.InvalidParams).\nCreates the simplified Context object, populating it with log, reportProgress helpers (which wrap extra.sendNotification) and session data (if authentication is used).\nCalls the user’s toolDefinition.execute(validatedArgs, context).\nCatches Errors: Wraps the execute call in a try...catch. If an exception occurs:\n\nIf it’s a UserError, formats it into CallToolResult { isError: true, content: [{ text: error.message }] }.\nIf it’s another error, logs it and returns a generic isError: true result or potentially rethrows as an InternalError.\n\n\nConverts Result: Takes the return value from execute (string, Content object, { content: [...] }) and ensures it’s formatted correctly as a CallToolResult. The helpers imageContent/audioContent likely return the { type: &#039;image&#039;/&#039;audio&#039;, data: &#039;base64&#039;, mimeType: &#039;...&#039; } structure expected here.\nReturns the final CallToolResult to the underlying Server, which sends the JsonRpcResponse.\n\n\n\n\n\n2. server.addResource(resourceDefinition) &amp; server.addResourceTemplate(templateDefinition)\n\nInput (Resource/ResourceTemplate types): Objects defining uri/uriTemplate, name, description?, mimeType?, arguments? (for template), and the load handler function. Templates also accept complete functions for arguments.\nInternal Mechanism (Conceptual):\n\nStore Definition: Stores the definition internally (e.g., in this.#resources and this.#resourceTemplates). Pre-parses uriTemplate using the uri-templates library if it’s a template.\nRegister resources/list / resources/templates/list Handlers: Similar to tools/list, central handlers are likely registered with the underlying Server. They iterate through the stored definitions and format the ListResourcesResult / ListResourceTemplatesResult.\nRegister resources/read Handler: Registers one central handler. This handler:\n\nReceives the ReadResourceRequest (uri).\nMatches URI: Iterates through stored static Resource definitions first. If uri matches, finds the definition.\nIf no static match, iterates through stored ResourceTemplate definitions. Uses the parsed template object (e.g., uriTemplate.fromUri(requestedUri)) to check for a match and extract parameters.\nThrows MethodNotFound if no match.\nCreates the Context object.\nCalls the corresponding resourceDefinition.load(parsedArgs, context).\nConverts Result: Takes the { text: ... } or { blob: ... } returned by load and constructs the ReadResourceResult { contents: [ ... ] }. Handles potential arrays returned by load. Manually constructing Text/BlobResourceContents might be needed internally based on the result shape. Base64 encoding for blobs must happen here if load returns raw Buffers/bytes.\nReturns the ReadResourceResult.\n\n\nRegister completion/complete Handler (If Needed): If any resource template or prompt defines complete functions for arguments, a central handler for completion/complete is registered. It uses the request.params.ref (uri or name) and request.params.argument.name to find the correct registered complete function, calls it with request.params.argument.value, and formats the CompleteResult.\n\n\n\n3. server.addPrompt(promptDefinition)\n\nInput (Prompt type): Object defining name, description?, arguments? (including optional complete or enum), and the load handler.\nInternal Mechanism (Conceptual): Very similar to addTool:\n\nStore Definition: Stores definition in this.#prompts. Extracts argument metadata (name, description, required, enum) for listing. Stores completers.\nGenerate Argument Schema (Implicit): May internally create a Zod/JSON schema from promptDefinition.arguments for validation if not directly using the argument list for checks.\nRegister prompts/list Handler: Central handler iterates this.#prompts and formats ListPromptsResult.\nRegister prompts/get Handler: Central handler finds prompt by name, validates arguments against definition (checking required, potentially using generated schema), creates Context, calls promptDefinition.load(args, context), converts the returned string into GetPromptResult { messages: [{ role: &#039;user&#039;, content: { type: &#039;text&#039;, text: result } }] }, and returns it.\nRegister completion/complete Handler (If Needed): As described under resources. Handles completions defined via argument.complete or derived from argument.enum.\n\n\n\nBenefits and Trade-offs of the Abstraction\n\nPros:\n\nReduced Boilerplate: Significantly less code required compared to manually registering handlers for list_*, call_*, read_*, get_* methods.\nFocus on Logic: Developers focus on the execute/load function and schema definition.\nSchema Flexibility: Support for multiple validation libraries is convenient.\nSimplified Context: The Context object provides easier access to common utilities.\nAutomatic Error Handling: Basic exception-to-error-result conversion for tools.\n\n\nCons:\n\nAbstraction Leakage/Complexity: Debugging requires understanding both the framework’s layer and the underlying official SDK’s behavior. Errors might originate in either layer.\nPerformance Overhead: Runtime schema conversion (if not Zod), handler wrapping, and context object creation add some overhead per request compared to direct low-level handlers. Likely negligible for most use cases but could matter at extreme scale.\nLess Control (Potentially): Less direct control over the exact JSON-RPC response format or low-level transport interactions compared to using the official Server directly. Error handling for resources/prompts seems less nuanced than for tools (less explicit isError handling shown).\nReliance on Underlying SDK: Tied to the features and limitations of the @modelcontextprotocol/sdk version it depends on (e.g., transport options).\n\n\n\nConclusion: Ergonomics through Encapsulation\npunkpeye-fastmcp achieves its ergonomic API by encapsulating the repetitive logic of MCP primitive registration and handling. The addTool, addResource, and addPrompt methods act as factories and registrars, internally managing the setup of low-level handlers on the official SDK’s Server. They leverage schema introspection/conversion and wrap user-provided logic within standardized execution flows that include validation, context injection, and basic result/error formatting.\nThis abstraction significantly simplifies the development process for common MCP server patterns in TypeScript. However, advanced users should be aware of the underlying mechanisms, particularly regarding schema conversion, validation scope, result formatting rules, and the limitations inherited from the specific transports being wrapped (primarily legacy SSE for web). Understanding this internal translation layer is key to effectively utilizing and debugging applications built with punkpeye-fastmcp.\nOur next post will explore Blog 3: Sessions, Context, and Lifecycle Management, diving into how client connections are tracked and how state is managed within this framework.\n"},"5-punkpeye-fastmcp-tutes/Blogs/blog-3":{"slug":"5-punkpeye-fastmcp-tutes/Blogs/blog-3","filePath":"5 punkpeye-fastmcp tutes/Blogs/blog-3.md","title":"Blog 3: Sessions, Context, and Lifecycle Management in `punkpeye-fastmcp`","links":["5-punkpeye-fastmcp-tutes/Blogs/blog-2"],"tags":[],"content":"Blog 3: Sessions, Context, and Lifecycle Management in punkpeye-fastmcp\nSeries: Deep Dive into the Model Context Protocol SDKs (Advanced Topics)\r\nPost: 3 of 12\nHaving explored how punkpeye-fastmcp simplifies defining MCP primitives (Tools, Resources, Prompts) using its add* methods, we now shift our focus to the runtime aspects: how does the framework manage client connections (sessions), provide contextual information to your handler logic, and handle the overall server lifecycle?\nUnlike purely stateless APIs, MCP often involves maintaining state per connection (e.g., for logging levels, resource subscriptions, or potentially complex tool interactions) and providing handlers with relevant session or request information. This post dives into the implementation details within punkpeye-fastmcp:\n\nSession Management (FastMCPSession): How individual client connections are represented and tracked.\nThe Context Object: How handlers access session data, authentication info, logging, and progress reporting.\nAuthentication Hook: Integrating custom authentication logic.\nServer Lifecycle &amp; Events: The start/stop methods and the connect/disconnect events.\n\n1. Session Management: Tracking Connections\nWhile the underlying @modelcontextprotocol/sdk’s Server and internal McpSession handle the core protocol state for a connection, punkpeye-fastmcp introduces its own explicit FastMCPSession class (src/FastMCP.ts) to manage and expose session-specific details and lifecycle events at the framework level.\nKey Aspects:\n\nCreation: A new FastMCPSession instance appears to be created for each client connection.\n\nStdio: A single session is created when server.start({ transportType: &#039;stdio&#039; }) connects the internal official Server to the StdioServerTransport.\nSSE: The startSSEServer helper (from mcp-proxy, likely wrapping the official SSEServerTransport) is configured with a createServer callback. This callback is invoked per connecting SSE client and likely returns a new FastMCPSession instance associated with that specific SSE connection/transport instance.\n\n\nTracking (FastMCP.sessions): The main FastMCP instance maintains an array (#sessions) holding all currently active FastMCPSession instances.\nSession State: Each FastMCPSession instance likely holds:\n\nA reference back to the main FastMCP server instance.\nThe underlying official SDK Server instance specific to that session’s transport connection. (This implies multiple internal Server instances might exist when using SSE, one per client, managed by the mcp-proxy/transport layer).\nThe negotiated ClientCapabilities.\nThe client-set LoggingLevel.\nThe list of client Roots.\nThe result of the authenticate function (if provided), stored in #auth.\n\n\nLifecycle Events:\n\nFastMCP emits &quot;connect&quot; with the new FastMCPSession instance when a client successfully connects and initializes.\nFastMCP emits &quot;disconnect&quot; with the FastMCPSession instance when a client disconnects (SSE stream closes or Stdio transport ends). The session is removed from the #sessions array.\nFastMCPSession itself emits &quot;error&quot; and &quot;rootsChanged&quot;.\n\n\n\nImplementation Insights:\n\nThe framework abstracts the underlying transport’s connection mechanism. For SSE, it relies on mcp-proxy (or similar logic) to map individual HTTP connections/SSE streams to distinct FastMCPSession instances, likely using unique session IDs generated by the transport.\nStoring session instances directly in the main FastMCP object’s array implies session state is primarily in-memory. This works well for single-process deployments but doesn’t scale horizontally without external state management or sticky sessions at a load balancer level (a common limitation noted for stateful MCP servers).\n\n2. The Context Object: Empowering Handlers\nDirectly interacting with the underlying official Server or transport objects within every Tool/Resource/Prompt handler would be cumbersome. punkpeye-fastmcp provides a simplified Context object (type alias Context&lt;T&gt; in FastMCP.ts) passed to the execute and load functions.\nHow it’s Created and Populated:\n\nWhen the central framework handler (registered via the underlying Server.setRequestHandler) is invoked for a specific request (tools/call, resources/read, etc.), it identifies the corresponding FastMCPSession for that connection.\nIt creates the Context object for that specific request invocation.\nIt populates the Context with:\n\nsession: The authenticated session data (the result of the authenticate function, type T).\nlog: An object with methods (debug, info, warn, error) that internally call the underlying session.#server.sendLoggingMessage() but only if the message level meets the client-set session.loggingLevel.\nreportProgress: An async function that wraps the underlying session.#server.sendNotification({ method: &#039;notifications/progress&#039;, ... }) call, using the progressToken from the incoming request’s _meta data.\n\n\n\nUsage in Handlers:\nserver.addTool({\n  name: &quot;process_data&quot;,\n  parameters: z.object({ dataId: z.string() }),\n  execute: async (args, context) =&gt; { // Context object passed as second arg\n    // Access authenticated session data (if authenticate was used)\n    const userId = context.session // Assuming authenticate returned { userId: ... }\n    if (!userId) { throw new UserError(&quot;Authentication required&quot;); }\n \n    // Use simplified logging\n    context.log.info(`User ${userId} processing data ${args.dataId}`);\n \n    // Report progress (only sends if client included progressToken)\n    await context.reportProgress({ progress: 50, total: 100 });\n \n    // ... perform work ...\n \n    context.log.debug(&quot;Processing complete&quot;);\n    return &quot;Success&quot;;\n  }\n});\nComparison: This Context object provides a cleaner, more focused interface for common handler needs compared to the official SDK’s RequestHandlerExtra (which exposes more, lower-level details like the AbortSignal and sendRequest). Python’s FastMCP Context is very similar in purpose and methods provided. C#‘s RequestContext combined with DI parameter injection offers a different but also powerful way to access context and dependencies. Java’s Exchange object serves a similar role.\n3. Authentication Hook (ServerOptions.authenticate)\nSecurity is crucial. punkpeye-fastmcp provides a simple, synchronous hook for custom authentication logic.\n\nMechanism: The authenticate function provided in FastMCP constructor options is called early in the connection process (likely by the createServer callback passed to startSSEServer or equivalent Stdio logic).\nInput: It receives the raw incoming request object (e.g., Node.js http.IncomingMessage for SSE). This allows inspecting headers (Authorization: Bearer ..., X-API-Key, cookies, etc.).\nOutput:\n\nSuccess: Return an object (T) containing the authenticated user/session data. This object is stored and made available later via context.session.\nFailure: Throw an Error or, more appropriately for HTTP, throw a Response object (new Response(null, { status: 401 })). Throwing a Response allows controlling the exact HTTP status code and headers sent back to the unauthorized client.\n\n\nSimplicity vs. Robustness: This provides a basic, flexible hook. However, it lacks the structure, standard compliance, and features (token types, grant flows, revocation, discovery) of a full OAuth 2.1 implementation like the one provided by the official TS SDK’s mcpAuthRouter. Developers using this hook need to implement all token validation, scope checking, etc., manually.\n\n4. Server Lifecycle (start/stop) and Events\n\nserver.start(options):\n\nThe primary method to begin listening for connections.\nTakes transport options (stdio or sse).\nFor stdio, it creates an StdioServerTransport, creates a single FastMCPSession, connects it via the internal Server, emits &quot;connect&quot;, and waits for the transport to close (usually when stdin closes), then emits &quot;disconnect&quot;.\nFor sse, it calls startSSEServer (from mcp-proxy), providing the createServer callback which instantiates FastMCPSession for each new connection and hooks up the onConnect/onClose events to emit &quot;connect&quot;/&quot;disconnect&quot;. Stores the underlying HTTP server handle.\n\n\nserver.stop():\n\nFor stdio, it likely cancels the underlying session’s processing loop and disposes the transport.\nFor sse, it calls close() on the underlying HTTP server returned by startSSEServer.\n\n\nEvents (connect, disconnect): Allow application code to react to clients joining or leaving, useful for tracking active users, resource cleanup, or metrics.\n\nImplementation Nuances:\n\nThe reliance on mcp-proxy for SSE startup abstracts away the direct use of the official SDK’s SSEServerTransport. While convenient, it means the server is tied to that library’s implementation and the legacy SSE transport model.\nError handling during start (e.g., port already in use) depends on the underlying http.Server or StdioServerTransport behavior.\n\nConclusion: Abstraction with In-Memory State\npunkpeye-fastmcp provides useful abstractions for managing the MCP server lifecycle and interacting with session context. The FastMCPSession class offers a tangible representation of connected clients, and the Context object simplifies common tasks like logging and progress reporting within handlers. The authenticate hook provides a basic mechanism for securing the server.\nHowever, advanced developers must recognize the implications of these abstractions:\n\nSession State: State is primarily in-memory, tied to FastMCPSession instances. Scaling beyond a single process requires externalizing state.\nTransport Abstraction: The simplification provided by server.start() currently hides the use of the legacy SSE transport for web communication, foregoing the benefits of Streamable HTTP available in the underlying official SDK.\nAuthentication: The basic hook requires significant custom implementation for robust, standard-based authentication like OAuth 2.1.\n\nThis framework excels at providing ergonomic wrappers for common patterns but requires developers to understand the underlying mechanisms (and their limitations) when building complex, scalable, or highly secure applications.\nNext, we examine the transport layer in more detail, specifically how Stdio and the legacy SSE model are implemented via the underlying SDK and helpers like mcp-proxy, in Blog 4: Transports and Tooling - Under the Wrapper.\n"},"5-punkpeye-fastmcp-tutes/Blogs/blog-4":{"slug":"5-punkpeye-fastmcp-tutes/Blogs/blog-4","filePath":"5 punkpeye-fastmcp tutes/Blogs/blog-4.md","title":"Blog 4: Transports and Tooling - Under the Wrapper in `punkpeye-fastmcp`","links":["5-punkpeye-fastmcp-tutes/Blogs/blog-2","5-punkpeye-fastmcp-tutes/Blogs/blog-3"],"tags":[],"content":"Blog 4: Transports and Tooling - Under the Wrapper in punkpeye-fastmcp\nSeries: Deep Dive into the Model Context Protocol SDKs (Advanced Topics)\r\nPost: 4 of 12\nHaving explored how punkpeye-fastmcp simplifies defining primitives and managing sessions and context, we now peel back another layer to examine how it handles the fundamental Transport Layer and its associated Developer Tooling.\nAs a framework built upon the official @modelcontextprotocol/sdk, punkpeye-fastmcp doesn’t reinvent the wheel for basic communication protocols like Stdio or HTTP+SSE. Instead, it acts as a wrapper and orchestrator, simplifying the setup and usage of the official SDK’s transport implementations and integrating with external helper tools.\nThis post investigates:\n\nStdio Transport: How server.start({ transportType: &#039;stdio&#039; }) configures and uses the official SDK’s StdioServerTransport.\nSSE Transport: Analyzing the reliance on mcp-proxy (startSSEServer) and its implications (legacy HTTP+SSE model).\nStreamable HTTP Absence: Confirming the lack of support for the modern web transport.\nThe fastmcp CLI Wrapper: Deconstructing the dev and inspect commands and their use of external CLIs (@wong2/mcp-cli, @modelcontextprotocol/inspector).\n\n1. Stdio Transport: A Direct Pass-Through\nFor local inter-process communication, punkpeye-fastmcp provides a straightforward wrapper around the official SDK’s Stdio capabilities.\nserver.start({ transportType: &#039;stdio&#039; }) Internals (Conceptual):\n\nInstantiate Official Transport: Creates an instance of @modelcontextprotocol/sdk/server/stdio.StdioServerTransport. This class handles reading from process.stdin and writing to process.stdout using the newline-delimited JSON format defined in shared/stdio.ts.\nInstantiate Official Server: Creates an instance of the low-level @modelcontextprotocol/sdk/server/index.Server, configured with the server info, capabilities, and the central request/notification handlers set up by punkpeye-fastmcp’s add* methods (Blog 2).\nCreate Session: Creates the punkpeye-fastmcp FastMCPSession object, linking it to the underlying official Server instance.\nConnect: Calls the internal session.connect(stdioTransport) method (likely inherited or adapted from the official SDK’s internal McpEndpoint logic). This starts the message processing loop within the official SDK’s McpSession which reads from the transport’s channel.\nEmit Event: Emits the &quot;connect&quot; event with the FastMCPSession.\nLifecycle: Waits for the underlying transport/session to complete (typically when stdin is closed by the parent process), then emits &quot;disconnect&quot; and cleans up.\n\nKey Takeaway: For Stdio, punkpeye-fastmcp primarily acts as a configuration and lifecycle management wrapper around the standard, official Stdio transport implementation. It adds the FastMCPSession layer for its own eventing and context management but relies on the official SDK for the core communication.\n2. SSE Transport: Relying on mcp-proxy and Legacy SSE\nWeb-based communication in punkpeye-fastmcp takes a different approach, relying on an external helper library.\nserver.start({ transportType: &#039;sse&#039;, sse: { port, endpoint } }) Internals (Conceptual):\n\nImport startSSEServer: Uses the startSSEServer function imported from the mcp-proxy package. (Note: mcp-proxy seems to be a separate utility, potentially also by punkpeye, designed specifically to simplify hosting the official SDK’s legacy SSEServerTransport).\nDefine createServer Callback: Passes a callback function to startSSEServer. This callback is the crucial link. It will be invoked by startSSEServer for each new incoming SSE connection.\nInside createServer Callback:\n\nReceives the underlying connection details (likely request/response objects) from startSSEServer.\nIf an authenticate function was provided to FastMCP, it’s called here with the request object. Authentication failures would typically result in throwing an HTTP Response (e.g., 401).\nCreates a new instance of the official SDK’s low-level Server.\nCreates a new FastMCPSession instance, associating it with the new Server instance and the authenticated session data (if any).\nStores this session in the main FastMCP’s #sessions array.\nReturns the FastMCPSession instance back to startSSEServer.\n\n\nstartSSEServer Logic (Hypothesized based on its purpose):\n\nCreates a standard Node.js http.Server.\nListens on the specified port.\nSets up route handlers for GET {endpoint} (e.g., /sse) and POST /message (the hardcoded path for legacy SSE).\nOn GET /sse:\n\nCalls the provided createServer callback to get a FastMCPSession and its associated internal official Server.\nCreates an instance of the official SDK’s SSEServerTransport for this specific connection.\nConnects the Server instance to this SSEServerTransport.\nManages the SSE response stream, sending the endpoint event with a unique sessionId (e.g., http://host:port/message?sessionId=UUID).\nWires up outgoing messages from the session’s Server to be sent over this SSE stream.\n\n\nOn POST /message?sessionId=...:\n\nExtracts the sessionId.\nFinds the correct active Server instance associated with that sessionId (maintained by startSSEServer or looked up via the FastMCP sessions list?).\nParses the JSON-RPC message from the POST body.\nForwards the message to the appropriate Server instance’s message handling input (likely simulating a message arriving via its transport channel).\nReturns 202 Accepted.\n\n\nHandles connection closure, calling onClose which emits the disconnect event on the main FastMCP instance and removes the session.\n\n\nFastMCP.start: Stores the handle to the http.Server created by startSSEServer so it can be closed by server.stop().\n\nKey Takeaways &amp; Implications:\n\nLegacy Protocol: This approach uses the HTTP+SSE dual-endpoint model from the older (2024-11-05) MCP specification, as implemented by the official SDK’s SSEServerTransport.\nExternal Dependency: Relies on the mcp-proxy package to abstract the complexities of setting up the legacy SSE server using the official SDK components.\nMultiple Server Instances: Critically, this model likely creates a separate instance of the official SDK’s low-level Server for each connected client. While the punkpeye-fastmcp FastMCP object is a singleton, the underlying protocol handling might be session-specific. This impacts how shared state needs to be managed (it must live outside the handler context or be accessed via shared services if DI were used more deeply).\nNo Streamable HTTP: This setup does not support the modern, single-endpoint Streamable HTTP transport.\n\n3. The Streamable HTTP Question\nBased on the code structure (start method options) and the reliance on mcp-proxy (which appears focused on simplifying the legacy SSE setup), punkpeye-fastmcp does not seem to offer built-in support for hosting via the Streamable HTTP transport.\nImplications for Advanced Users:\n\nResumability: Servers built with punkpeye-fastmcp cannot leverage the built-in resumability features of Streamable HTTP when hosted over the web. Long-running tools will be susceptible to failures on connection drops.\nEfficiency: Uses the less efficient dual-endpoint SSE model compared to Streamable HTTP’s potential single-connection approach (especially with HTTP/2).\nSpecification Alignment: Primarily aligns with the older 2024-11-05 web transport spec, not the 2025-03-26 version favored by the official TS and C# SDKs.\n\nDevelopers needing Streamable HTTP would have to bypass punkpeye-fastmcp’s start method and manually configure the official SDK’s StreamableHTTPServerTransport, likely losing some of the framework’s abstractions in the process or needing to adapt the FastMCPSession logic significantly.\n4. The CLI Wrapper: Launching External Tools\nThe fastmcp command provided by this package (src/bin/fastmcp.ts) acts as a simple launcher.\n\nfastmcp dev &lt;file&gt;:\n\nMechanism: Uses execa (a library for running child processes) to execute npx @wong2/mcp-cli &lt;args...&gt;. @wong2/mcp-cli is a separate, community-developed CLI tool for interacting with MCP servers via Stdio. tsx is likely used by mcp-cli internally or passed along to run the TypeScript server file directly.\nPurpose: Provides a convenient alias to run a server alongside an interactive terminal-based MCP client for basic testing.\n\n\nfastmcp inspect &lt;file&gt;:\n\nMechanism: Uses execa to execute npx @modelcontextprotocol/inspector &lt;args...&gt;. The inspector is the official web-based UI tool. Again, tsx is likely passed to run the server file.\nPurpose: Simplifies launching the server simultaneously with the official Inspector UI for visual debugging and interaction.\n\n\n\nComparison: Unlike Python’s fastmcp CLI (which uses uv for environment/dependency management and directly integrates with Claude Desktop), this TypeScript CLI is purely a process launcher for other tools. It doesn’t manage dependencies or provide deep integrations. It’s a convenience wrapper around existing npx commands.\nConclusion: Convenience Layer with Transport Trade-offs\npunkpeye-fastmcp succeeds in abstracting the transport setup for Stdio and legacy HTTP+SSE behind a simple server.start() method. It leverages the official SDK’s transports but hides their direct configuration. The CLI provides convenient shortcuts for common development workflows using external testing tools.\nHowever, advanced users must understand the implications:\n\nThe Stdio implementation is a standard wrapper.\nThe SSE implementation relies on the legacy dual-endpoint protocol via mcp-proxy, lacking the features of Streamable HTTP (like resumability). This is the most significant technical trade-off for web-hosted servers.\nThe CLI is a simple launcher, not an integrated development/deployment tool like its Python namesake.\n\nThis design prioritizes ease-of-use for getting started with Stdio or basic SSE servers but might limit developers needing the performance, resilience, or spec-compliance of modern Streamable HTTP for web deployments.\nOur final post will synthesize the entire framework, evaluating the DX trade-offs, identifying ideal use cases, and considering its overall position within the TypeScript MCP ecosystem.\n"},"5-punkpeye-fastmcp-tutes/Blogs/blog-5":{"slug":"5-punkpeye-fastmcp-tutes/Blogs/blog-5","filePath":"5 punkpeye-fastmcp tutes/Blogs/blog-5.md","title":"Blog 5: Synthesis - DX Trade-offs, Use Cases, and Ecosystem Fit for `punkpeye-fastmcp`","links":["5-punkpeye-fastmcp-tutes/Blogs/blog-1","5-punkpeye-fastmcp-tutes/Blogs/blog-2","5-punkpeye-fastmcp-tutes/Blogs/blog-3","5-punkpeye-fastmcp-tutes/Blogs/blog-4"],"tags":[],"content":"Blog 5: Synthesis - DX Trade-offs, Use Cases, and Ecosystem Fit for punkpeye-fastmcp\nSeries: Deep Dive into the Model Context Protocol SDKs (Advanced Topics)\r\nPost: 5 of 5 (punkpeye-fastmcp Deep Dive)\nOur deep dive into punkpeye-fastmcp has taken us from its positioning as a framework above the official @modelcontextprotocol/sdk, through its ergonomic primitive definition APIs (addTool, etc.), its approach to sessions and context, and its wrapping of underlying transports and tooling.\nNow, we synthesize these findings to provide a nuanced perspective for advanced TypeScript developers evaluating this framework. We’ll weigh the developer experience (DX) benefits against the technical trade-offs, identify ideal use cases, and consider its overall fit within the rapidly evolving TypeScript MCP ecosystem.\nRecapping punkpeye-fastmcp: The Core Proposition\npunkpeye-fastmcp aims to be the “Fast” and “Simple” way to build MCP servers in TypeScript. It achieves this primarily through:\n\nAbstraction: Hiding the lower-level Server.setRequestHandler calls behind addTool, addResource, addPrompt methods.\nSchema Flexibility: Supporting Zod, ArkType, and Valibot via the “Standard Schema” concept for tool parameters, handling JSON Schema conversion internally.\nSimplified Handlers: Providing a Context object and handling basic result/error formatting.\nSession Management: Explicitly tracking client sessions (FastMCPSession) and providing lifecycle events.\nSimplified Startup: Offering server.start() for Stdio and legacy SSE.\nConvenience: imageContent/audioContent helpers, basic auth hook, CLI wrappers.\n\nIt undeniably lowers the initial barrier to defining MCP server logic compared to using the official SDK directly for common tasks.\nThe Developer Experience (DX) Trade-offs\nAdvantages:\n\nReduced Boilerplate: Significantly less code needed for registering standard primitives, especially compared to manually implementing list_* and action (call_*, read_*, get_*) handlers.\nFocus on Logic: Developers concentrate on the execute/load function, schema, and description.\nSchema Choice: Freedom to use preferred validation libraries (Zod being the most natural fit in TS).\nReadability: The add* methods can make the server’s overall structure clearer at a glance.\nGentle Learning Curve (for Basics): Easier to get a simple server running quickly than learning the official SDK’s lower-level details immediately.\n\nDisadvantages/Considerations for Advanced Users:\n\nAbstraction Layer: Debugging can be harder, requiring understanding both the framework and the underlying official SDK it calls. Performance overhead exists (though likely minor).\n“Magic” Factor: Automatic schema conversion and handler wrapping can obscure underlying MCP mechanics. Less direct control over JSON-RPC message structure or error formatting.\nTransport Limitation (Web): The most significant trade-off. Relying on the legacy HTTP+SSE transport (via mcp-proxy) means no built-in support for modern Streamable HTTP. This sacrifices:\n\nPotential efficiency gains (single endpoint).\nCrucially, Resumability: No easy way to leverage EventStore for reliable long-running web operations.\n\n\nFeature Lag: May not expose all features or configuration options of the underlying official SDK (e.g., detailed timeout settings within RequestOptions, enforceStrictCapabilities). Updates depend on the punkpeye-fastmcp maintainer syncing with official SDK releases.\nLimited Advanced Features: Lacks built-in OAuth server (unlike official TS SDK), proxying/mounting/generation (unlike Python FastMCP v2), sophisticated CLI tooling (unlike Python FastMCP v2).\n\nIdeal Use Cases for punkpeye-fastmcp\nGiven the trade-offs, this framework shines in specific scenarios:\n\nRapid Prototyping: Quickly building and iterating on MCP server ideas in TypeScript where DX and speed of development are prioritized over ultimate transport features or scalability nuances.\nStdio-Based Servers: For local tools or integrations (e.g., VS Code extensions, custom desktop agents) where Stdio is the primary transport, the framework provides a clean API without the web transport limitations being relevant.\nSimple Web Services (Internal/Trusted): Hosting basic Tools/Resources over HTTP where the limitations of legacy SSE (no resumability) are acceptable and robust OAuth isn’t immediately required (using the basic auth hook or relying on external API gateway security).\nTeaching/Learning MCP Concepts: The simplified API can be a good starting point for understanding MCP primitives before diving into the official SDK’s lower levels.\nTeams Standardizing on Zod/ArkType/Valibot: The schema flexibility is a direct benefit if a team strongly prefers one of these over defining handlers directly with Zod schemas as required by the official SDK’s setRequestHandler.\n\nWhere It Might Fall Short (Advanced Needs)\n\nProduction Web Services with Long-Running Tools: The lack of Streamable HTTP and resumability is a significant drawback for reliability over potentially unstable web connections. Building directly on the official @modelcontextprotocol/sdk is likely preferable here.\nPublic-Facing Servers Requiring Standard OAuth: The basic authenticate hook is insufficient. Integrating a proper OAuth 2.1 flow would likely require bypassing the hook and adding standard Express middleware, diminishing the framework’s abstraction benefits. Using the official TS SDK’s mcpAuthRouter is much more direct.\nHighly Performance-Sensitive Applications: The extra layers of abstraction and runtime schema conversion might introduce measurable overhead compared to a finely tuned server built directly on the official SDK’s core components.\nComplex Server Architectures: Lacks the built-in support for proxying or mounting multiple server instances found in Python’s FastMCP v2.\n\nEcosystem Fit and Future Perspective\npunkpeye-fastmcp occupies an interesting space. It’s a community-driven effort to bring the ergonomic philosophy of Python’s FastMCP to TypeScript, layering convenience on top of the official foundation.\n\nComplement, Not Replacement: It serves as a higher-level alternative for specific use cases, particularly rapid development and simpler server definitions. It doesn’t aim to replace the official SDK, which remains essential for core protocol logic, transport implementations, and accessing the full feature set (like Streamable HTTP).\nMaintenance &amp; Alignment: Its long-term value depends on continued maintenance and alignment with the evolving MCP specification and the official TypeScript SDK. Potential divergence, especially regarding transport support, is a key factor to monitor.\nCommunity Adoption: Wider adoption could lead to more contributions, potentially bridging feature gaps (e.g., adding Streamable HTTP support, more sophisticated context features), but it currently appears less widely used than the official SDK or its Python inspiration.\n\nFinal Synthesis: A Useful Tool with Caveats\npunkpeye-fastmcp successfully delivers on its promise of a more ergonomic, simplified API for defining basic MCP server primitives in TypeScript. Its add* methods, flexible schema support, and convenient context object significantly reduce boilerplate for common tasks, accelerating development. The included CLI wrappers are helpful conveniences.\nHowever, for advanced users building robust, scalable, secure, and feature-rich web-facing applications, the current limitations are significant. The reliance on legacy HTTP+SSE and the lack of built-in Streamable HTTP support (with its associated resumability) is a major technical trade-off compared to using the official @modelcontextprotocol/sdk directly. Similarly, the basic authentication hook falls short of the official SDK’s comprehensive OAuth framework.\nRecommendation: punkpeye-fastmcp is a valuable tool for rapid prototyping, Stdio-based local servers, and simpler web services where legacy SSE limitations are acceptable. For production web applications requiring maximum reliability, resilience, standard security patterns, and alignment with the latest MCP specifications, developers should strongly consider building directly upon the official @modelcontextprotocol/sdk, despite its slightly steeper initial learning curve for handler registration. Understanding both libraries allows developers to choose the right tool for the specific demands of their TypeScript MCP project.\n\nThis concludes the 5-part deep dive into punkpeye-fastmcp. We hope this analysis has provided a clear technical picture of the framework’s strengths, weaknesses, and its place within the TypeScript MCP landscape."},"5-punkpeye-fastmcp-tutes/README":{"slug":"5-punkpeye-fastmcp-tutes/README","filePath":"5 punkpeye-fastmcp tutes/README.md","title":"README","links":[],"tags":[],"content":"\npunkpeye-fastmcp tutes\n"},"5-punkpeye-fastmcp-tutes/index":{"slug":"5-punkpeye-fastmcp-tutes/index","filePath":"5 punkpeye-fastmcp tutes/index.md","title":"5 punkpeye-fastmcp tutes","links":[],"tags":[],"content":""},"6-Remaining/099_breakdown-of-the-CS-SDK-files":{"slug":"6-Remaining/099_breakdown-of-the-CS-SDK-files","filePath":"6 Remaining/099_breakdown of the CS SDK files.md","title":"099_breakdown of the CS SDK files","links":[],"tags":[],"content":"Okay, classifying files strictly by dependency level in a complex project can be nuanced, as dependencies aren’t always strictly hierarchical. However, we can group them based on a general flow from foundational, self-contained code to more complex, integrated components that rely on many other parts of the SDK.\nHere’s a breakdown of the C# SDK files, ordered approximately from least to most dependent on other files within this specific SDK repository, along with their purposes:\nLevel 0: Foundational Utilities &amp; Polyfills (Minimal internal dependencies)\n\nCommon/Polyfills/**/*.cs: Provides implementations of newer .NET features for older target frameworks (like netstandard2.0). They depend only on base .NET libraries and enable the rest of the SDK to use modern APIs consistently.\n\nPurpose: Ensure compatibility across different .NET versions.\n\n\nCommon/Utils/Throw.cs: Contains static helper methods for throwing common exceptions (e.g., ArgumentNullException). Likely used widely but self-contained.\n\nPurpose: Reduce boilerplate exception throwing code.\n\n\nCommon/Utils/SemaphoreSlimExtensions.cs: Provides extension methods for SemaphoreSlim (like LockAsync). Self-contained utility.\n\nPurpose: Simplify asynchronous locking patterns.\n\n\nModelContextProtocol/McpErrorCode.cs: Defines an enum for standard MCP error codes. Self-contained definition.\n\nPurpose: Standardize error reporting codes.\n\n\nModelContextProtocol/McpException.cs: Defines the custom exception type for MCP errors. Depends only on base Exception and McpErrorCode.\n\nPurpose: Provide a specific exception type for protocol-level errors.\n\n\n\nLevel 1: Core JSON/Protocol Definitions &amp; Basic Utils\n\nCommon/Utils/Json/*.cs: Utilities for JSON handling, like custom converters (JsonRpcMessageConverter, CustomizableJsonStringEnumConverter). Depend on System.Text.Json and base MCP message types, but are fundamental building blocks for serialization.\n\nPurpose: Handle custom JSON serialization/deserialization needs of MCP.\n\n\nCommon/Utils/ProcessHelper.cs: Helpers for interacting with external processes (like KillTree). May depend on System.Diagnostics.Process.\n\nPurpose: Provide robust process management, especially for Stdio transport cleanup.\n\n\nModelContextProtocol/Protocol/Messages/RequestId.cs, ModelContextProtocol/Protocol/Messages/ProgressToken.cs: Structs representing JSON-RPC IDs/tokens, handling string/number duality via custom converters. Depend only on base types.\n\nPurpose: Represent the union types for IDs used in the protocol.\n\n\nModelContextProtocol/Protocol/Messages/JsonRpcMessage.cs: Abstract base class for all JSON-RPC messages. Defines the jsonrpc property.\n\nPurpose: Base type for JSON-RPC message hierarchy.\n\n\nModelContextProtocol/Protocol/Messages/JsonRpcMessageWithId.cs: Abstract base class for messages having an ID (Requests, Responses, Errors). Inherits JsonRpcMessage, adds Id.\n\nPurpose: Base type for messages requiring request/response correlation.\n\n\nModelContextProtocol/Protocol/Messages/JsonRpcNotification.cs: Concrete class for notifications. Inherits JsonRpcMessage, adds Method, Params.\n\nPurpose: Represent JSON-RPC Notifications.\n\n\nModelContextProtocol/Protocol/Messages/JsonRpcRequest.cs: Concrete class for requests. Inherits JsonRpcMessageWithId, adds Method, Params.\n\nPurpose: Represent JSON-RPC Requests.\n\n\nModelContextProtocol/Protocol/Messages/JsonRpcErrorDetail.cs: Record defining the error object structure (code, message, data).\n\nPurpose: Structure for JSON-RPC error details.\n\n\nModelContextProtocol/Protocol/Messages/JsonRpcError.cs: Concrete class for error responses. Inherits JsonRpcMessageWithId, adds Error property of type JsonRpcErrorDetail.\n\nPurpose: Represent JSON-RPC Error Responses.\n\n\nModelContextProtocol/Protocol/Messages/JsonRpcResponse.cs: Concrete class for success responses. Inherits JsonRpcMessageWithId, adds Result.\n\nPurpose: Represent JSON-RPC Success Responses.\n\n\nModelContextProtocol/Protocol/Messages/NotificationMethods.cs, ModelContextProtocol/Protocol/Messages/RequestMethods.cs: Static classes containing constants for standard MCP method names.\n\nPurpose: Provide strongly-typed constants for method strings, reducing typos.\n\n\nModelContextProtocol/Protocol/Types/Role.cs, ModelContextProtocol/Protocol/Types/LoggingLevel.cs, ModelContextProtocol/Protocol/Types/ContextInclusion.cs: Enums defining specific protocol values.\n\nPurpose: Define constrained sets of values used in the protocol.\n\n\nModelContextProtocol/Protocol/Types/Implementation.cs: Simple class defining client/server name and version.\n\nPurpose: Identify communicating parties.\n\n\nModelContextProtocol/Protocol/Types/Annotations.cs: Defines optional metadata (audience, priority).\n\nPurpose: Allow annotating primitives for client interpretation.\n\n\n\nLevel 2: Core MCP Payload Types\n\nModelContextProtocol/Protocol/Messages/PaginatedResult.cs: Base class for results supporting pagination (NextCursor).\nModelContextProtocol/Protocol/Types/RequestParams.cs: Base class for request parameters, defining optional _meta.\nModelContextProtocol/Protocol/Types/RequestParamsMetadata.cs: Defines the structure of the _meta field (e.g., ProgressToken).\nModelContextProtocol/Protocol/Types/Content.cs: Core class representing message content (text, image, audio, resource). Depends on Annotations.\nModelContextProtocol/Protocol/Types/ResourceContents.cs, TextResourceContents.cs, BlobResourceContents.cs: Base and concrete types for resource data. EmbeddedResource (in PromptMessage.cs) uses these.\nModelContextProtocol/Protocol/Types/PromptMessage.cs: Defines the structure of messages within a prompt result. Uses Role, Content, EmbeddedResource.\nModelContextProtocol/Protocol/Types/SamplingMessage.cs: Defines messages for sampling requests. Uses Role, Content.\nModelContextProtocol/Protocol/Types/Resource.cs, ResourceTemplate.cs, Tool.cs, Prompt.cs, Root.cs: Define the metadata structures for the core MCP primitives. Depend on Annotations. Tool depends on ToolAnnotations.\nModelContextProtocol/Protocol/Types/ToolAnnotations.cs: Defines optional hints about tool behavior.\nModelContextProtocol/Protocol/Types/PromptArgument.cs: Defines arguments for prompts.\nModelContextProtocol/Protocol/Types/ModelHint.cs, ModelContextProtocol/Protocol/Types/ModelPreferences.cs: Define structures for sampling model selection.\nModelContextProtocol/Protocol/Types/Reference.cs, Argument.cs, Completion.cs: Define structures for the completion feature.\nModelContextProtocol/Protocol/Types/Capabilities.cs (ClientCapabilities, ServerCapabilities, *Capability): Define the capability structures exchanged during initialization. These often aggregate other types or define handler signatures (Func&lt;&gt;) in [JsonIgnore] properties (though the handlers themselves are defined elsewhere).\n\nLevel 3: Foundational Interfaces and Shared Logic\n\nModelContextProtocol/IMcpEndpoint.cs: Core interface defining basic send/receive/notify operations for any MCP endpoint.\nModelContextProtocol/Protocol/Transport/ITransport.cs: Interface defining the contract for a communication channel session (reading/sending messages).\nModelContextProtocol/Protocol/Transport/IClientTransport.cs: Interface defining the contract for establishing a client connection.\nModelContextProtocol/Shared/NotificationHandlers.cs, ModelContextProtocol/Shared/RequestHandlers.cs: Classes managing collections of notification/request handlers.\nModelContextProtocol/Shared/McpEndpoint.cs: Abstract base class implementing much of IMcpEndpoint, likely using McpSession. Depends on IMcpEndpoint, McpSession, logging.\nModelContextProtocol/Shared/McpSession.cs: Core internal class managing a single session’s state, request/response correlation, message dispatching. Depends on ITransport, message types, handlers, logging.\nModelContextProtocol/Protocol/Transport/TransportBase.cs: Abstract base providing common functionality for ITransport implementations (channel management, logging). Depends on ITransport, JsonRpcMessage, logging.\nModelContextProtocol/Diagnostics.cs: Internal helper for OpenTelemetry Activity/Metric creation. Depends on JsonRpcMessage types.\nModelContextProtocol/NopProgress.cs, ModelContextProtocol/ProgressNotificationValue.cs, ModelContextProtocol/TokenProgress.cs: Types related to progress reporting. TokenProgress depends on IMcpEndpoint.\n\nLevel 4: Concrete Transport Implementations\n\nModelContextProtocol/Protocol/Transport/StreamServerTransport.cs, StreamClientSessionTransport.cs: Base implementations for stream-based communication (used by Stdio). Depend on TransportBase, ITransport, .NET Streams.\nModelContextProtocol/Protocol/Transport/StdioServerTransport.cs, StdioClientTransport.cs, StdioClientSessionTransport.cs, StdioClientTransportOptions.cs: Stdio implementation. Depend on Stream transports, Process, IClientTransport, logging.\nModelContextProtocol/Protocol/Transport/SseWriter.cs, SseClientSessionTransport.cs, SseClientTransport.cs, SseClientTransportOptions.cs: SSE client implementation. Depend on TransportBase, ITransport, IClientTransport, System.Net.ServerSentEvents, HttpClient, logging. Can operate in legacy SSE or Streamable HTTP mode.\nModelContextProtocol/Protocol/Transport/StreamableHttp*Transport.cs: Core logic for Streamable HTTP. StreamableHttpClientSessionTransport uses HTTP/SSE. StreamableHttpServerTransport uses SSE/JSON responses and IDuplexPipe. StreamableHttpPostTransport handles POST request/response pairing. Depend on TransportBase, ITransport, HttpClient, SseWriter, IDuplexPipe.\nModelContextProtocol/Protocol/Transport/StreamClientTransport.cs: Client transport wrapping existing streams. Depends on IClientTransport, StreamClientSessionTransport.\n\nLevel 5: Core Client/Server Implementations &amp; Options\n\nModelContextProtocol/Client/IMcpClient.cs: Interface defining client-specific operations and properties. Inherits IMcpEndpoint.\nModelContextProtocol/Server/IMcpServer.cs: Interface defining server-specific operations and properties. Inherits IMcpEndpoint.\nModelContextProtocol/Client/McpClientOptions.cs: Configuration for clients (Capabilities, ClientInfo, timeouts).\nModelContextProtocol/Server/McpServerOptions.cs: Configuration for servers (Capabilities, ServerInfo, timeouts, instructions, ScopeRequests).\nModelContextProtocol/Client/McpClient.cs: Concrete client implementation. Inherits McpEndpoint, implements IMcpClient. Depends heavily on IClientTransport, McpSession, McpClientOptions, Types, Messages, logging.\nModelContextProtocol/Server/McpServer.cs: Concrete server implementation. Inherits McpEndpoint, implements IMcpServer. Depends heavily on ITransport, McpSession, McpServerOptions, Types, Messages, logging, potentially IServiceProvider.\nModelContextProtocol/Server/RequestContext.cs: Context object passed to server handlers. Depends on IMcpServer, TParams.\nModelContextProtocol/Server/IMcpServerPrimitive.cs, McpServerPrimitiveCollection.cs: Base interface and collection for server-side Tools/Prompts.\n\nLevel 6: Factories, Extensions, and Primitive Wrappers\n\nModelContextProtocol/Client/McpClientFactory.cs: Creates and initializes IMcpClient. Depends on IMcpClient, McpClient, IClientTransport, McpClientOptions.\nModelContextProtocol/Server/McpServerFactory.cs: Creates IMcpServer. Depends on IMcpServer, McpServer, ITransport, McpServerOptions.\nModelContextProtocol/AIContentExtensions.cs: Converts between MCP types and Microsoft.Extensions.AI types. Depends on Microsoft.Extensions.AI and MCP Types.\nModelContextProtocol/McpEndpointExtensions.cs: Extension methods for IMcpEndpoint (strongly-typed send/receive). Depend on IMcpEndpoint, Messages, Types, System.Text.Json.\nModelContextProtocol/Client/McpClientExtensions.cs: Extension methods for IMcpClient (e.g., ListToolsAsync, CallToolAsync). Depend on IMcpClient, Types, Messages, McpClientTool, McpClientPrompt.\nModelContextProtocol/Server/McpServerExtensions.cs: Extension methods for IMcpServer (e.g., RequestSamplingAsync, AsSamplingChatClient). Depend on IMcpServer, Types, Messages, Microsoft.Extensions.AI.\nModelContextProtocol/Client/McpClientTool.cs, McpClientPrompt.cs: Client-side wrappers for discovered Tools/Prompts. Depend on IMcpClient, Tool, Prompt. McpClientTool depends on AIFunction.\nModelContextProtocol/Server/McpServerTool.cs, McpServerPrompt.cs: Server-side abstractions for Tools/Prompts, including factory Create methods. Depend on IMcpServerPrimitive, AIFunction, Tool, Prompt, RequestContext.\nModelContextProtocol/Server/AIFunctionMcpServerTool.cs, AIFunctionMcpServerPrompt.cs: Implementations using AIFunction. Depend on McpServerTool/Prompt, AIFunction, RequestContext.\nModelContextProtocol/Server/DelegatingMcpServerTool.cs, DelegatingMcpServerPrompt.cs: Base classes for wrapping/decorating tools/prompts. Depend on McpServerTool/Prompt.\nModelContextProtocol/Server/*Attribute.cs: Attributes ([McpServerTool], [McpServerToolType], etc.) used for discovery. Self-contained metadata.\nModelContextProtocol/Server/McpServerToolCreateOptions.cs, McpServerPromptCreateOptions.cs: Options classes for programmatic creation of Tools/Prompts.\n\nLevel 7: Dependency Injection &amp; Hosting Configuration\n\nModelContextProtocol/Configuration/IMcpServerBuilder.cs: Interface for the DI builder pattern.\nModelContextProtocol/Configuration/DefaultMcpServerBuilder.cs: Concrete implementation of the builder. Depends on IMcpServerBuilder, IServiceCollection.\nModelContextProtocol/Server/McpServerHandlers.cs: Container class holding handler delegates configured via DI. Depends on RequestContext and various MCP message types.\nModelContextProtocol/Configuration/McpServerOptionsSetup.cs: IConfigureOptions implementation that applies handlers and registered primitives (Tools/Prompts) from DI to McpServerOptions. Depends on IOptions&lt;McpServerHandlers&gt;, IEnumerable&lt;McpServerTool/Prompt&gt;.\nModelContextProtocol/Configuration/McpServerBuilderExtensions.cs: The core DI extension methods (AddMcpServer, WithTools, WithPrompts, With*Handler, With*Transport). Depends on IMcpServerBuilder, IServiceCollection, McpServerHandlers, McpServerOptions, ITransport, Tool/Prompt types.\nModelContextProtocol/Hosting/SingleSessionMcpServerHostedService.cs: IHostedService for running single-session servers (like Stdio). Depends on IHostedService, IMcpServer.\n\nLevel 8: ASP.NET Core Integration\n\nModelContextProtocol.AspNetCore/*: Classes specifically for ASP.NET Core integration.\n\nHttpServerTransportOptions.cs: Options specific to the HTTP server transport (idle timeout, etc.).\nHttpMcpSession.cs: Internal class to manage state for an HTTP session (transport, user, activity). Depends on ITransport, IMcpServer.\nIdleTrackingBackgroundService.cs: Hosted service to clean up idle HTTP sessions. Depends on HttpMcpSession, IHostedService, options.\nStreamableHttpHandler.cs, SseHandler.cs: Core ASP.NET Core request delegates handling incoming HTTP requests for Streamable HTTP and legacy SSE respectively. Depend heavily on HttpContext, McpServerFactory, HttpMcpSession, options, logging.\nHttpMcpServerBuilderExtensions.cs: DI extension (WithHttpTransport) to register ASP.NET Core specific services. Depends on IMcpServerBuilder.\nMcpEndpointRouteBuilderExtensions.cs: Extension (MapMcp) to register endpoints in ASP.NET Core routing. Depends on IEndpointRouteBuilder, handlers.\n\n\n\nThis breakdown shows a progression from fundamental utilities and type definitions, through core protocol logic and transport implementations, up to the client/server APIs, DI configuration, and finally framework-specific integration like ASP.NET Core."},"6-Remaining/101_breakdown-of-the-Python-MCP-SDK-files":{"slug":"6-Remaining/101_breakdown-of-the-Python-MCP-SDK-files","filePath":"6 Remaining/101_breakdown of the Python MCP SDK files.md","title":"101_breakdown of the Python MCP SDK files","links":[],"tags":[],"content":"Okay, here is the breakdown of the Python MCP SDK files, ordered approximately from least dependent on other repository files to most dependent, along with their purposes.\nLevel 0: Foundational &amp; Configuration\n\nsrc/mcp/py.typed:\n\nPurpose: Marker file indicating to type checkers (like MyPy, Pyright) that the mcp package provides type hints according to PEP 561. No code dependencies.\n\n\nsrc/mcp/types.py:\n\nPurpose: Defines the core MCP message structures (Requests, Responses, Notifications, Tools, Resources, Prompts, Capabilities, Content types, etc.) using Pydantic V2 models. This is the foundational data contract based on the MCP specification. Depends only on Pydantic and standard Python typing.\n\n\nsrc/mcp/shared/exceptions.py:\n\nPurpose: Defines the custom McpError exception class used for protocol-level errors. Depends only on base Python exceptions and potentially mcp.types.ErrorData.\n\n\nsrc/mcp/shared/version.py:\n\nPurpose: Holds constants related to supported MCP protocol versions (e.g., LATEST_PROTOCOL_VERSION, SUPPORTED_PROTOCOL_VERSIONS). No code dependencies.\n\n\nsrc/mcp/server/fastmcp/exceptions.py:\n\nPurpose: Defines exception subclasses specific to the FastMCP high-level server API (e.g., ValidationError, ResourceError). Depends on shared/exceptions.py.\n\n\n\nLevel 1: Core Shared Logic &amp; Base Session\n\nsrc/mcp/shared/session.py:\n\nPurpose: Implements BaseSession, the core class managing the JSON-RPC protocol logic over abstract read/write streams. Handles request/response correlation, timeouts, message dispatching loops, and basic state management. Depends heavily on mcp.types, shared/exceptions, anyio, and standard Python libraries. It’s the foundation for both ClientSession and ServerSession. Also defines RequestResponder.\n\n\nsrc/mcp/shared/context.py:\n\nPurpose: Defines RequestContext (and LifespanContextT), a simple data structure used to pass request-specific metadata (like ID, session, lifespan state) to handlers. Depends on shared/session (for BaseSession generic constraint) and types.\n\n\nsrc/mcp/shared/progress.py:\n\nPurpose: Defines ProgressContext and related types/helpers for handling MCP progress notifications. Depends on shared/session, shared/context, and types.\n\n\n\nLevel 2: Server Low-Level Components &amp; Core Session\n\nsrc/mcp/server/lowlevel/helper_types.py:\n\nPurpose: Defines simple helper data classes like ReadResourceContents used by the low-level server resource handlers. Depends only on base types.\n\n\nsrc/mcp/server/models.py:\n\nPurpose: Defines Pydantic models specifically for server configuration, like InitializationOptions. Depends on mcp.types.\n\n\nsrc/mcp/server/session.py:\n\nPurpose: Defines ServerSession, which extends BaseSession with server-specific logic. Handles the server side of the initialization handshake (initialize request, initialized notification) and manages server state (_initialization_state, _client_params). Provides server-specific methods like send_log_message, create_message, list_roots. Depends on shared/session, server/models, types.\n\n\nsrc/mcp/server/lowlevel/server.py:\n\nPurpose: Implements the low-level Server class. Provides decorators (@server.call_tool, @server.list_resources, etc.) for registering specific handler functions. Manages the overall server run loop, connecting to transports, creating ServerSession instances, and dispatching messages to registered handlers. Depends on server/session, server/models, shared/context, types.\n\n\n\nLevel 3: Client Core Session &amp; Specific Implementations\n\nsrc/mcp/client/session.py:\n\nPurpose: Defines ClientSession, which extends BaseSession with client-specific logic. Handles the client side of the initialization handshake (sending initialize/initialized). Provides high-level methods for interacting with servers (list_tools, call_tool, read_resource, etc.). Takes callbacks for handling server-initiated requests (sampling, roots). Depends on shared/session, shared/context, types.\n\n\n\nLevel 4: Transport Implementations\n(These depend on core sessions, types, and specific I/O libraries)\n\nsrc/mcp/client/stdio/win32.py:\n\nPurpose: Contains Windows-specific helper functions for finding executables and creating/terminating processes correctly, used by the Stdio client transport. Depends on standard sys, shutil, subprocess, anyio.\n\n\nsrc/mcp/client/stdio/__init__.py:\n\nPurpose: Implements the stdio_client async context manager. Uses anyio.open_process (and win32 helpers) to spawn the server process and connects its stdin/stdout to memory streams yielded to the ClientSession. Depends on anyio, types, shared/session, client/stdio/win32.py.\n\n\nsrc/mcp/server/stdio.py:\n\nPurpose: Implements the stdio_server async context manager for servers launched via Stdio. Wraps sys.stdin/stdout using anyio for async reading/writing and yields memory streams to the low-level Server.run method. Depends on anyio, types.\n\n\nsrc/mcp/client/sse.py:\n\nPurpose: Implements the sse_client async context manager for connecting to HTTP+SSE servers. Uses httpx-sse library. Handles the GET /sse connection, receives the endpoint event, listens for message events, and manages a background task to POST outgoing messages. Depends on anyio, httpx, httpx-sse, types, shared/session.\n\n\nsrc/mcp/server/sse.py:\n\nPurpose: Implements the SseServerTransport class providing ASGI applications (connect_sse, handle_post_message) for HTTP+SSE servers. Integrates with frameworks like Starlette. Uses sse-starlette. Manages sessions via session IDs in POST URLs. Depends on anyio, starlette, sse-starlette, types, shared/session.\n\n\nsrc/mcp/client/websocket.py:\n\nPurpose: Implements the websocket_client async context manager. Uses the websockets library to connect to a WebSocket server supporting the mcp subprotocol. Depends on anyio, websockets, types, shared/session.\n\n\nsrc/mcp/server/websocket.py:\n\nPurpose: Implements the websocket_server ASGI application for hosting MCP over WebSockets. Uses the websockets library via Starlette’s WebSocket class. Depends on anyio, starlette, websockets, types, shared/session.\n\n\n\nLevel 5: FastMCP High-Level Server Components\n(These build upon low-level server components and provide ergonomic APIs)\n\nsrc/mcp/server/fastmcp/utilities/logging.py:\n\nPurpose: Simple logging configuration helper, potentially using rich. Depends on standard logging.\n\n\nsrc/mcp/server/fastmcp/utilities/types.py:\n\nPurpose: Defines helper types like Image for convenient handling of specific data within FastMCP. Depends on standard libraries, mcp.types.\n\n\nsrc/mcp/server/fastmcp/utilities/func_metadata.py:\n\nPurpose: Crucial utility for FastMCP. Uses Python’s inspect module to analyze function signatures, generate Pydantic models dynamically for arguments, and handle calling functions with validated/parsed arguments (including basic JSON string parsing). Depends on inspect, pydantic, fastmcp/exceptions.\n\n\nsrc/mcp/server/fastmcp/tools/base.py:\n\nPurpose: Defines the internal Tool Pydantic model used by FastMCP to store metadata and the handler function. Depends on pydantic, fastmcp/utilities/func_metadata, fastmcp/server (for Context type hint).\n\n\nsrc/mcp/server/fastmcp/resources/base.py:\n\nPurpose: Defines the abstract base class Resource. Depends on pydantic, abc.\n\n\nsrc/mcp/server/fastmcp/prompts/base.py:\n\nPurpose: Defines Prompt, Message (User/Assistant), and PromptArgument models for FastMCP. Depends on pydantic, mcp.types.\n\n\nsrc/mcp/server/fastmcp/tools/tool_manager.py:\n\nPurpose: Manages the registration (add_tool) and execution (call_tool) of tools within FastMCP. Uses Tool.from_function to create internal representations. Depends on tools/base, fastmcp/server (for Context), fastmcp/exceptions.\n\n\nsrc/mcp/server/fastmcp/resources/types.py:\n\nPurpose: Defines concrete Resource implementations (TextResource, BinaryResource, FunctionResource, FileResource, etc.). Depend on resources/base, standard libraries (pathlib), anyio, httpx.\n\n\nsrc/mcp/server/fastmcp/resources/templates.py:\n\nPurpose: Defines the ResourceTemplate class, responsible for matching URI patterns and creating dynamic resource instances from functions. Depends on resources/base, resources/types, pydantic, inspect, re.\n\n\nsrc/mcp/server/fastmcp/resources/resource_manager.py:\n\nPurpose: Manages registration (add_resource, add_template) and retrieval (get_resource) of both static resources and templates within FastMCP. Depends on resources/base, resources/templates, resources/types.\n\n\nsrc/mcp/server/fastmcp/prompts/manager.py (and prompt_manager.py - likely duplication):\n\nPurpose: Manages registration (add_prompt) and rendering (render_prompt) of prompts within FastMCP. Depends on prompts/base.\n\n\nsrc/mcp/server/fastmcp/server.py:\n\nPurpose: Defines the high-level FastMCP server class. This is the main user-facing API for building servers easily. Provides decorators (@mcp.tool, etc.). It orchestrates the managers (ToolManager, etc.) and wraps the low-level Server (mcp.server.lowlevel.server.Server) to handle actual protocol communication. Defines the Context object. High dependency on almost all other fastmcp components, server/lowlevel/server, types, shared/context.\n\n\n\nLevel 6: CLI and Testing Utilities\n\nsrc/mcp/cli/claude.py:\n\nPurpose: Contains logic specific to integrating with Claude Desktop by finding and modifying its configuration file. Depends on standard libraries (json, os, sys, pathlib), potentially subprocess.\n\n\nsrc/mcp/cli/cli.py:\n\nPurpose: Implements the mcp command-line interface using typer. Provides commands like dev, run, install. Imports server objects to run them, uses cli/claude.py for installation. Depends on typer, importlib, subprocess, dotenv, cli/claude.py, server/fastmcp.\n\n\nsrc/mcp/shared/memory.py:\n\nPurpose: Provides the create_client_server_memory_streams async context manager for testing. Creates linked in-memory streams to connect a client and server directly without real transport. Depends on anyio, client/session, server/lowlevel/server, types.\n\n\n\nLevel 7: Entry Points &amp; Initialization Files\n\nsrc/mcp/client/__main__.py:\n\nPurpose: Example command-line runner for the client. Demonstrates using ClientSession and different transports. High dependency on client components.\n\n\nsrc/mcp/server/__main__.py:\n\nPurpose: Example command-line runner for the server (using ServerSession directly, lower-level than FastMCP). High dependency on server components.\n\n\nsrc/mcp/__init__.py, src/mcp/cli/__init__.py, src/mcp/client/__init__.py, src/mcp/server/__init__.py, src/mcp/server/fastmcp/__init__.py, etc.:\n\nPurpose: Standard Python package initialization files. They often import symbols from deeper modules to make them available at a higher level (e.g., from .client.session import ClientSession in src/mcp/__init__.py). They depend on the modules they import from.\n\n\n\nThis ordering reflects a general flow from basic definitions → core shared logic → specific client/server session logic → transport implementations → high-level abstractions (FastMCP) → CLI tools → testing utilities."},"6-Remaining/103_breakdown-of-the-TypeScript-SDK-files":{"slug":"6-Remaining/103_breakdown-of-the-TypeScript-SDK-files","filePath":"6 Remaining/103_breakdown of the TypeScript SDK files.md","title":"103_breakdown of the TypeScript SDK files","links":[],"tags":[],"content":"Okay, here’s a breakdown of the TypeScript SDK files, ordered approximately from least dependent on other files within this specific SDK repository to most dependent, along with their purposes.\nLevel 0: Foundational Definitions &amp; Self-Contained Utilities\n\nsrc/types.ts:\n\nPurpose: THE foundational definitions. Defines all MCP message structures (Requests, Responses, Notifications, Primitives like Tool, Resource, Prompt, Content types, Capabilities, etc.) using Zod schemas. Derives corresponding TypeScript types using z.infer. Defines protocol constants (LATEST_PROTOCOL_VERSION, JSONRPC_VERSION) and error codes (ErrorCode).\nDependencies: Zod (external). Minimal internal dependencies, potentially simple enums/types from itself.\n\n\nsrc/shared/transport.ts:\n\nPurpose: Defines the abstract Transport interface contract (methods start, send, close, callbacks onmessage, onclose, onerror) and TransportSendOptions.\nDependencies: types.ts (for JSONRPCMessage, RequestId, AuthInfo). Minimal implementation.\n\n\nsrc/shared/stdio.ts:\n\nPurpose: Provides utilities specific to newline-delimited JSON framing for the Stdio transport (ReadBuffer, serializeMessage, deserializeMessage).\nDependencies: types.ts (for JSONRPCMessage, JSONRPCMessageSchema).\n\n\nsrc/shared/uriTemplate.ts:\n\nPurpose: Implements RFC 6570 URI Template parsing and expansion. Used for dynamic resources.\nDependencies: None internal (standard JS/TS APIs).\n\n\nsrc/server/auth/types.ts:\n\nPurpose: Defines the AuthInfo interface used to represent validated authentication context passed to handlers.\nDependencies: None internal.\n\n\nsrc/shared/auth.ts:\n\nPurpose: Defines shared Zod schemas for standard OAuth 2.1 data structures (Tokens, Metadata, Client Info, Errors) used by both client and server auth components.\nDependencies: Zod (external).\n\n\nsrc/server/auth/errors.ts:\n\nPurpose: Defines custom Error subclasses for specific OAuth errors (e.g., InvalidRequestError, InvalidClientError), inheriting from a base OAuthError.\nDependencies: Base Error.\n\n\n\nLevel 1: Core Protocol Logic\n\nsrc/shared/protocol.ts:\n\nPurpose: Implements the abstract Protocol base class. Contains the core JSON-RPC message handling logic: request/response correlation, ID management, notification dispatch, timeout handling (DEFAULT_REQUEST_TIMEOUT_MSEC, RequestOptions), cancellation, progress notification processing. Defines RequestHandlerExtra.\nDependencies: types.ts, shared/transport.ts, server/auth/types.ts.\n\n\n\nLevel 2: Base Client/Server Implementations\n\nsrc/client/index.ts:\n\nPurpose: Defines the primary Client class. Extends Protocol. Implements the client-side initialization handshake, capability checking against server capabilities, and provides high-level methods (ping, listTools, callTool, readResource, getPrompt, setLoggingLevel, etc.) which wrap protocol.request. Defines ClientOptions.\nDependencies: shared/protocol.ts, types.ts, shared/transport.ts.\n\n\nsrc/server/index.ts:\n\nPurpose: Defines the low-level Server class. Extends Protocol. Implements the server-side initialization handshake response, capability checking against client capabilities, and provides setRequestHandler/setNotificationHandler for registering logic for specific MCP methods using Zod schemas. Defines ServerOptions.\nDependencies: shared/protocol.ts, types.ts, shared/transport.ts.\n\n\n\nLevel 3: Concrete Transport Implementations\n\nsrc/inMemory.ts:\n\nPurpose: Implements the Transport interface for testing client/server interactions entirely within memory using shared queues. Includes createLinkedPair.\nDependencies: shared/transport.ts, types.ts, server/auth/types.ts.\n\n\nsrc/client/stdio.ts:\n\nPurpose: Implements Transport for the client side of Stdio communication. Manages spawning and communicating with a child process using cross-spawn. Includes StdioClientTransportOptions and getDefaultEnvironment.\nDependencies: shared/transport.ts, shared/stdio.ts, types.ts, cross-spawn (external).\n\n\nsrc/server/stdio.ts:\n\nPurpose: Implements Transport for the server side of Stdio communication. Reads from process.stdin and writes to process.stdout.\nDependencies: shared/transport.ts, shared/stdio.ts, types.ts.\n\n\nsrc/client/websocket.ts:\n\nPurpose: Implements Transport for client-side WebSocket communication. Uses the ws library.\nDependencies: shared/transport.ts, types.ts, ws (external).\n\n\nsrc/client/auth.ts:\n\nPurpose: Provides client-side helper functions for initiating OAuth 2.1 flows (discovery, start auth, exchange code, refresh token, register client). Uses fetch and pkce-challenge.\nDependencies: shared/auth.ts, types.ts (for LATEST_PROTOCOL_VERSION), pkce-challenge (external/mocked).\n\n\nsrc/client/sse.ts:\n\nPurpose: Implements Transport for the legacy HTTP+SSE client (dual endpoint: GET /sse, POST /message). Includes optional OAuth handling via authProvider option.\nDependencies: shared/transport.ts, types.ts, client/auth.ts, eventsource (external).\n\n\nsrc/server/sse.ts:\n\nPurpose: Implements Transport for the legacy HTTP+SSE server. Handles the GET /sse stream (using Node http.ServerResponse) and POST /message requests (parsing body, using sessionId query param).\nDependencies: shared/transport.ts, types.ts, server/auth/types.ts, Node http, crypto, url, content-type, raw-body (external).\n\n\nsrc/client/streamableHttp.ts:\n\nPurpose: Implements Transport for the modern Streamable HTTP client (single endpoint GET/POST). Handles SSE/JSON responses, header-based sessions, Last-Event-ID for resumability, reconnection logic. Includes optional OAuth handling via authProvider.\nDependencies: shared/transport.ts, types.ts, client/auth.ts, eventsource-parser/stream (external).\n\n\nsrc/server/streamableHttp.ts:\n\nPurpose: Implements Transport for the modern Streamable HTTP server. Handles GET/POST/DELETE on a single endpoint, manages sessions via Mcp-Session-Id header, supports SSE/JSON response modes, implements resumability via the EventStore interface.\nDependencies: shared/transport.ts, types.ts, server/auth/types.ts, Node http, crypto, content-type, raw-body (external). Defines EventStore, StreamableHTTPServerTransportOptions.\n\n\n\nLevel 4: High-Level Server Abstractions &amp; OAuth Implementation\n\nsrc/server/completable.ts:\n\nPurpose: Defines the Completable Zod schema wrapper and related types used to add autocompletion logic to tool/prompt arguments.\nDependencies: Zod (external).\n\n\nsrc/server/mcp.ts:\n\nPurpose: Defines the high-level McpServer class. Provides ergonomic .tool(), .resource(), .prompt() methods for registering primitives. Wraps the low-level Server, automatically setting up handlers and generating schemas (zod-to-json-schema). Returns handles (RegisteredTool, etc.) for dynamic management. Defines ResourceTemplate.\nDependencies: server/index.ts, types.ts, Zod, zod-to-json-schema (external), server/completable.ts, shared/uriTemplate.ts.\n\n\nsrc/server/auth/clients.ts:\n\nPurpose: Defines the OAuthRegisteredClientsStore interface contract for storing/retrieving OAuth client registrations.\nDependencies: shared/auth.ts.\n\n\nsrc/server/auth/provider.ts:\n\nPurpose: Defines the OAuthServerProvider interface contract, outlining the methods needed to implement the core OAuth logic (authorize, exchange tokens, verify tokens, revoke).\nDependencies: Express types (external), server/auth/clients.ts, shared/auth.ts, server/auth/types.ts.\n\n\nsrc/server/auth/middleware/allowedMethods.ts:\n\nPurpose: Express middleware to reject requests using disallowed HTTP methods for an endpoint.\nDependencies: Express types (external), server/auth/errors.ts.\n\n\nsrc/server/auth/middleware/clientAuth.ts:\n\nPurpose: Express middleware to authenticate an OAuth client based on client_id and client_secret in the request body (for /token, /revoke endpoints). Attaches req.client.\nDependencies: Express types (external), Zod, server/auth/clients.ts, shared/auth.ts, server/auth/errors.ts.\n\n\nsrc/server/auth/middleware/bearerAuth.ts:\n\nPurpose: Express middleware to authenticate requests using a Bearer token in the Authorization header. Validates the token using the OAuthServerProvider and attaches req.auth. Used to protect MCP endpoints.\nDependencies: Express types (external), server/auth/provider.ts, server/auth/errors.ts, server/auth/types.ts.\n\n\nsrc/server/auth/handlers/*.ts (authorize, metadata, register, revoke, token):\n\nPurpose: Implement the request handling logic for each standard OAuth endpoint (/authorize, /.well-known/..., /register, /revoke, /token). They parse requests, apply middleware (like authenticateClient), call the appropriate OAuthServerProvider methods, and format responses.\nDependencies: Express types (external), server/auth/provider.ts, middleware, errors, shared types, Zod.\n\n\nsrc/server/auth/providers/proxyProvider.ts:\n\nPurpose: Provides a concrete implementation of OAuthServerProvider that proxies requests to an upstream OAuth server.\nDependencies: server/auth/provider.ts, server/auth/clients.ts, shared/auth.ts, server/auth/errors.ts, fetch (likely via Node or polyfill).\n\n\n\nLevel 5: Top-Level Integration &amp; Examples\n\nsrc/server/auth/router.ts:\n\nPurpose: Provides the mcpAuthRouter function, which conveniently creates and configures an Express router with all the standard OAuth endpoint handlers and middleware, wired to a given OAuthServerProvider.\nDependencies: Express (external), all files in server/auth/handlers/ and server/auth/middleware/, server/auth/provider.ts.\n\n\nsrc/cli.ts:\n\nPurpose: A simple command-line interface for running basic client/server examples, primarily using Stdio but also demonstrating SSE/WebSocket client connection.\nDependencies: client/index.ts, server/index.ts, various transport implementations, types.ts, ws (external).\n\n\nsrc/examples/**/*.ts:\n\nPurpose: Practical examples demonstrating how to build clients and servers using the SDK, showcasing features like different transports, state management, resumability, and parallel operations.\nDependencies: Various core client/server classes (Client, McpServer), transports, types.\n\n\nsrc/integration-tests/**/*.ts:\n\nPurpose: Tests designed to verify the interaction between client and server components, often involving real (but controlled) transports or specific feature interactions like resumability.\nDependencies: Core client/server classes, transports, types, testing framework (Jest).\n\n\nsrc/**/*.test.ts (Unit Tests):\n\nPurpose: Test individual classes or functions in isolation.\nDependencies: The specific unit under test, mocking libraries (Jest), potentially inMemory.ts.\n\n\n\nThis ordering flows from foundational type definitions and utilities → core protocol logic → client/server base classes → specific communication transports → high-level abstractions → complex features like OAuth → top-level entry points, examples, and tests."},"6-Remaining/105_recreated-breakdown-of-the-Python-MCP-SDK-files":{"slug":"6-Remaining/105_recreated-breakdown-of-the-Python-MCP-SDK-files","filePath":"6 Remaining/105_recreated breakdown of the Python MCP SDK files.md","title":"105_recreated breakdown of the Python MCP SDK files","links":[],"tags":[],"content":"Okay, here is a detailed breakdown of the Python MCP SDK files, ordered approximately from least dependent on other internal SDK files to most dependent.\nDependency Level refers to reliance on other modules within this SDK repository. External dependencies like anyio, pydantic, httpx, etc., are assumed present at all relevant levels.\n\nLevel 0: Foundational Definitions &amp; Markers\n\n\nsrc/mcp/py.typed:\n\nPurpose: Marker file adhering to PEP 561. Signals to type checkers (MyPy, Pyright) that the mcp package includes inline type hints and supports type checking.\nInternal Dependencies: None.\n\n\n\nsrc/mcp/types.py:\n\nPurpose: Defines the core data structures and message types of the Model Context Protocol using Pydantic V2 models. This includes Requests, Responses, Notifications, Primitives (Tool, Resource, Prompt, Content types), Capabilities, etc. It serves as the foundational data contract derived from the MCP specification schema. Defines constants like LATEST_PROTOCOL_VERSION.\nInternal Dependencies: None (relies on external Pydantic, standard Python typing). This is the bedrock upon which most other modules depend.\n\n\n\nsrc/mcp/client/stdio/win32.py:\n\nPurpose: Contains Windows-specific helper functions for finding executable paths (get_windows_executable_command) and creating/terminating processes (create_windows_process, terminate_windows_process) to handle platform nuances, primarily used by the Stdio client transport.\nInternal Dependencies: None (relies on standard Python os, sys, shutil, subprocess, pathlib, typing, external anyio).\n\n\n\nLevel 1: Basic Utilities, Exceptions, and Base Models\n\n\nsrc/mcp/shared/version.py:\n\nPurpose: Holds constants defining the supported MCP protocol versions (e.g., SUPPORTED_PROTOCOL_VERSIONS).\nInternal Dependencies: types.py (for LATEST_PROTOCOL_VERSION).\n\n\n\nsrc/mcp/shared/exceptions.py:\n\nPurpose: Defines the base McpError custom exception class, wrapping the ErrorData structure for protocol-level errors.\nInternal Dependencies: types.py (for ErrorData).\n\n\n\nsrc/mcp/server/lowlevel/helper_types.py:\n\nPurpose: Defines simple helper data structures, specifically ReadResourceContents, used for return values in low-level resource handlers.\nInternal Dependencies: Standard libraries (dataclasses).\n\n\n\nsrc/mcp/server/models.py:\n\nPurpose: Defines Pydantic models used specifically for server configuration, primarily InitializationOptions which bundles server info and capabilities needed for the initialize response.\nInternal Dependencies: types.py.\n\n\n\nsrc/mcp/server/fastmcp/utilities/logging.py:\n\nPurpose: Provides a helper (get_logger) to get a standard Python logger instance configured under the FastMCP namespace and potentially configures basic logging using rich if available.\nInternal Dependencies: Standard logging, potentially external rich.\n\n\n\nsrc/mcp/server/fastmcp/resources/base.py:\n\nPurpose: Defines the abstract base class Resource for use within the FastMCP framework, establishing common fields (uri, name, description, mime_type) and the abstract read method.\nInternal Dependencies: abc, typing, pydantic.\n\n\n\nsrc/mcp/server/fastmcp/prompts/base.py:\n\nPurpose: Defines base Pydantic models for prompts used by FastMCP: Prompt, Message (and subclasses UserMessage, AssistantMessage), PromptArgument. Also handles basic content type conversion within Message.\nInternal Dependencies: inspect, json, typing, pydantic, pydantic_core, types.py (for TextContent, ImageContent, etc.).\n\n\n\nsrc/mcp/server/fastmcp/utilities/types.py:\n\nPurpose: Defines utility classes for FastMCP, currently Image, which simplifies handling image data (from paths or bytes) and converting it to ImageContent.\nInternal Dependencies: base64, pathlib, types.py (for ImageContent).\n\n\n\nLevel 2: Core Session Logic &amp; FastMCP Primitives\n\n\nsrc/mcp/shared/session.py:\n\nPurpose: Implements the fundamental BaseSession class. This is the core engine handling JSON-RPC framing, request/response ID correlation, message dispatching based on type (request/response/notification), basic timeout handling, and managing communication over abstract read/write streams provided by transports. Defines RequestResponder.\nInternal Dependencies: logging, typing, datetime, anyio, pydantic, types.py, shared/exceptions.py.\n\n\n\nsrc/mcp/server/fastmcp/exceptions.py:\n\nPurpose: Defines exceptions specific to the FastMCP layer (FastMCPError, ValidationError, ResourceError, ToolError, InvalidSignature).\nInternal Dependencies: shared/exceptions.py.\n\n\n\nsrc/mcp/server/fastmcp/utilities/func_metadata.py:\n\nPurpose: A critical utility for FastMCP. Introspects Python function signatures using inspect, dynamically generates Pydantic models (ArgModelBase) for validating arguments, and provides logic (call_fn_with_arg_validation) to call functions with validated/parsed arguments (including parsing JSON within strings).\nInternal Dependencies: inspect, json, typing, pydantic, pydantic_core, fastmcp/exceptions.py, fastmcp/utilities/logging.py.\n\n\n\nsrc/mcp/server/fastmcp/resources/types.py:\n\nPurpose: Defines concrete Resource subclasses for FastMCP (TextResource, BinaryResource, FunctionResource, FileResource, HttpResource, DirectoryResource), implementing the read method for each type.\nInternal Dependencies: inspect, json, typing, pathlib, anyio, httpx, pydantic, pydantic_core, fastmcp/resources/base.py.\n\n\n\nLevel 3: Client/Server Session Implementations &amp; FastMCP Templates\n\n\nsrc/mcp/shared/context.py:\n\nPurpose: Defines the RequestContext dataclass, a container for passing request-specific data (ID, session, lifespan state) to handlers.\nInternal Dependencies: dataclasses, typing, shared/session.py (for BaseSession generic), types.py.\n\n\n\nsrc/mcp/client/session.py:\n\nPurpose: Implements ClientSession, extending BaseSession. Handles the client-side initialization handshake (initialize). Provides high-level, user-friendly methods (list_tools, call_tool, read_resource, etc.) that wrap send_request. Manages callbacks for server-initiated requests (sampling_callback, list_roots_callback).\nInternal Dependencies: datetime, typing, anyio, pydantic, types.py, shared/context.py, shared/session.py, shared/version.py.\n\n\n\nsrc/mcp/server/session.py:\n\nPurpose: Implements ServerSession, extending BaseSession. Handles the server-side initialization handshake (_received_request for initialize, _received_notification for initialized). Manages server state regarding initialization and client capabilities. Provides server-specific methods (send_log_message, create_message, etc.).\nInternal Dependencies: enum, typing, anyio, types.py, server/models.py, shared/session.py.\n\n\n\nsrc/mcp/server/fastmcp/tools/base.py:\n\nPurpose: Defines the internal Tool Pydantic model used by FastMCP to store metadata (derived using func_metadata) and the actual handler function. Includes the run method for execution.\nInternal Dependencies: inspect, typing, pydantic, fastmcp/exceptions.py, fastmcp/utilities/func_metadata.py, fastmcp/server.py (for Context type hint), server/session.py (for ServerSessionT).\n\n\n\nsrc/mcp/server/fastmcp/resources/templates.py:\n\nPurpose: Defines the ResourceTemplate class for FastMCP. Handles matching URI templates against requested URIs and dynamically creating FunctionResource instances by calling the underlying handler function with extracted parameters.\nInternal Dependencies: inspect, re, typing, pydantic, fastmcp/resources/types.py.\n\n\n\nLevel 4: Transport Implementations &amp; FastMCP Managers\n\n\nsrc/mcp/server/stdio.py:\n\nPurpose: Implements the stdio_server async context manager. Wraps sys.stdin/stdout for use with anyio. Yields memory streams to the consuming server logic (Server.run).\nInternal Dependencies: sys, io, anyio, types.py.\n\n\n\nsrc/mcp/client/sse.py:\n\nPurpose: Implements the sse_client async context manager. Uses httpx and httpx-sse for HTTP+SSE communication. Handles connection, endpoint discovery, message sending (POST), and event listening (GET). Yields memory streams.\nInternal Dependencies: logging, contextlib, typing, urllib.parse, anyio, httpx, httpx_sse, types.py.\n\n\n\nsrc/mcp/server/sse.py:\n\nPurpose: Implements the SseServerTransport class providing ASGI applications (connect_sse, handle_post_message) for HTTP+SSE servers. Integrates with ASGI frameworks (Starlette). Manages sessions via UUIDs and internal dictionaries mapping IDs to streams.\nInternal Dependencies: logging, contextlib, typing, urllib.parse, uuid, anyio, pydantic, sse_starlette, starlette, types.py.\n\n\n\nsrc/mcp/client/websocket.py:\n\nPurpose: Implements websocket_client async context manager using the websockets library. Handles connection and message framing. Yields memory streams.\nInternal Dependencies: json, logging, collections.abc, contextlib, anyio, pydantic, websockets, types.py.\n\n\n\nsrc/mcp/server/websocket.py:\n\nPurpose: Implements the websocket_server ASGI application for WebSocket transport using starlette.websockets. Yields memory streams.\nInternal Dependencies: logging, contextlib, anyio, pydantic, starlette, types.py.\n\n\n\nsrc/mcp/server/fastmcp/tools/tool_manager.py:\n\nPurpose: Manages tool registration (add_tool) and execution (call_tool) for FastMCP.\nInternal Dependencies: typing, fastmcp/exceptions.py, fastmcp/tools/base.py, fastmcp/server.py (for Context), shared/context.py.\n\n\n\nsrc/mcp/server/fastmcp/resources/resource_manager.py:\n\nPurpose: Manages resource and template registration (add_resource, add_template) and retrieval (get_resource) for FastMCP.\nInternal Dependencies: typing, pydantic, fastmcp/resources/base.py, fastmcp/resources/templates.py, fastmcp/utilities/logging.py.\n\n\n\nsrc/mcp/server/fastmcp/prompts/manager.py (and prompt_manager.py):\n\nPurpose: Manages prompt registration (add_prompt) and rendering (render_prompt) for FastMCP.\nInternal Dependencies: typing, fastmcp/prompts/base.py, fastmcp/utilities/logging.py.\n\n\n\nLevel 5: High-Level Server API &amp; Testing Transport\n\n\nsrc/mcp/server/fastmcp/server.py:\n\nPurpose: Defines the primary high-level FastMCP class and the Context object. Orchestrates the various managers (Tool, Resource, Prompt). Provides the user-friendly decorator API (@mcp.tool, etc.). Wraps and configures the low-level Server to handle actual protocol communication. Defines run() method and sse_app() for ASGI integration.\nInternal Dependencies: inspect, json, contextlib, typing, anyio, pydantic, pydantic_settings, starlette, fastmcp/exceptions.py, fastmcp/prompts/, fastmcp/resources/, fastmcp/tools/, fastmcp/utilities/, server/lowlevel/server.py, server/session.py, server/sse.py, server/stdio.py, shared/context.py, types.py. (Highest internal dependency count).\n\n\n\nsrc/mcp/shared/memory.py:\n\nPurpose: Provides create_client_server_memory_streams utility for testing. Creates linked anyio memory streams to connect client and server instances without real I/O.\nInternal Dependencies: typing, contextlib, datetime, anyio, types.py, client/session.py, server/lowlevel/server.py.\n\n\n\nLevel 6: CLI &amp; Application Logic\n\n\nsrc/mcp/cli/claude.py:\n\nPurpose: Logic for finding and updating the Claude Desktop application’s configuration file (claude_desktop_config.json) to register MCP servers.\nInternal Dependencies: json, os, sys, pathlib, typing, subprocess, server/fastmcp/utilities/logging.py.\n\n\n\nsrc/mcp/cli/cli.py:\n\nPurpose: Defines the mcp command-line interface (dev, run, install) using typer. It imports server objects dynamically based on file paths, constructs uv commands, and interacts with cli/claude.py.\nInternal Dependencies: importlib, os, subprocess, sys, pathlib, typing, typer, dotenv, cli/claude.py, server/fastmcp/utilities/logging.py, potentially server/fastmcp/server.py (for importing server objects).\n\n\n\nLevel 7: Package Entry Points\n\n\nsrc/mcp/client/__main__.py:\n\nPurpose: Example CLI runner demonstrating how to use ClientSession with various transports.\nInternal Dependencies: argparse, logging, sys, functools, urllib.parse, anyio, types.py, client/session.py, client/sse.py, client/stdio/.\n\n\n\nsrc/mcp/server/__main__.py:\n\nPurpose: Example CLI runner demonstrating the low-level server using ServerSession directly (not FastMCP).\nInternal Dependencies: importlib.metadata, logging, sys, anyio, server/models.py, server/session.py, server/stdio.py, types.py.\n\n\n\nsrc/mcp/__init__.py, src/mcp/cli/__init__.py, etc. (__init__.py files):\n\nPurpose: Standard Python package/module initializers. Often used to expose key classes/functions from submodules at a higher level (e.g., from mcp.client.session import ClientSession).\nInternal Dependencies: The specific modules they import from.\n\n\n\nThis detailed breakdown flows from basic definitions → core logic → session implementations → transports → high-level APIs → CLI → entry points, showing the increasing complexity and inter-module dependencies."},"6-Remaining/107_recreated-break-down-of-TypeScript-SDK-files":{"slug":"6-Remaining/107_recreated-break-down-of-TypeScript-SDK-files","filePath":"6 Remaining/107_recreated break down of TypeScript SDK files.md","title":"107_recreated break down of TypeScript SDK files","links":[],"tags":[],"content":"Okay, let’s break down the TypeScript SDK files, ordering them from the most foundational and least dependent on other internal SDK files, up to the most complex and highly dependent components like examples and tests.\n\nLevel 0: Foundational Definitions &amp; Self-Contained Utilities\nThese files define core types or provide basic utilities with minimal reliance on other SDK modules, mostly depending on external libraries (like Zod) or built-in language features.\n\n\nsrc/types.ts:\n\nPurpose: The absolute core. Defines all Model Context Protocol message structures (Requests, Responses, Notifications), data types (Tool, Resource, Prompt, Content variants), capability flags, error codes, and protocol constants using Zod schemas. It derives the corresponding TypeScript types using z.infer. This file is the foundational contract for the entire SDK.\nDependencies: Zod (external).\n\n\n\nsrc/shared/transport.ts:\n\nPurpose: Defines the essential Transport interface contract. Specifies the methods (start, send, close) and callbacks (onmessage, onclose, onerror) that any communication mechanism must implement to be used by the core protocol logic. Also defines TransportSendOptions.\nDependencies: types.ts (for JSONRPCMessage, RequestId, AuthInfo).\n\n\n\nsrc/shared/stdio.ts:\n\nPurpose: Provides utility functions (serializeMessage, deserializeMessage) and the ReadBuffer class specifically for handling the newline-delimited JSON framing required by the Stdio transport.\nDependencies: types.ts (for JSONRPCMessage, JSONRPCMessageSchema).\n\n\n\nsrc/shared/uriTemplate.ts:\n\nPurpose: Implements URI Template (RFC 6570) parsing and expansion logic. Essential for handling dynamic resource URIs (e.g., items://{category}/{id}).\nDependencies: None internal (uses standard TS/JS APIs).\n\n\n\nsrc/server/auth/types.ts:\n\nPurpose: Defines the AuthInfo interface, which represents the validated authentication context (token, client ID, scopes) passed to request handlers when using bearer authentication.\nDependencies: None internal.\n\n\n\nsrc/shared/auth.ts:\n\nPurpose: Defines shared Zod schemas for standard OAuth 2.1 data structures (like OAuthTokens, OAuthMetadata, OAuthClientInformation, OAuthErrorResponse) used by both client-side helpers and server-side implementation.\nDependencies: Zod (external).\n\n\n\nsrc/server/auth/errors.ts:\n\nPurpose: Defines specific Error subclasses (e.g., InvalidRequestError, InvalidClientError, InvalidTokenError) extending a base OAuthError for representing standard OAuth 2.1 error conditions. Includes logic to format these into OAuth error responses.\nDependencies: Base Error.\n\n\n\nLevel 1: Core Protocol Logic\n\nsrc/shared/protocol.ts:\n\nPurpose: Implements the abstract Protocol class, the engine driving MCP communication. It manages the session lifecycle over a Transport, handles JSON-RPC request/response correlation via IDs, dispatches incoming messages to registered handlers, manages request timeouts and cancellation (AbortSignal), processes progress notifications, and defines RequestHandlerExtra. It’s the base for both Client and Server.\nDependencies: types.ts, shared/transport.ts, server/auth/types.ts.\n\n\n\nLevel 2: Base Client/Server Implementations\n\n\nsrc/client/index.ts:\n\nPurpose: Defines the primary public Client class. It extends Protocol, specializing it for client-side behavior. It implements the client part of the initialize handshake, stores server capabilities, checks server capabilities before sending requests (if strict), and provides high-level async methods (listTools, callTool, readResource, getPrompt, etc.) that wrap the core protocol.request logic. Defines ClientOptions.\nDependencies: shared/protocol.ts, types.ts, shared/transport.ts.\n\n\n\nsrc/server/index.ts:\n\nPurpose: Defines the low-level Server class. Extends Protocol, specializing for server-side behavior. Implements the server part of the initialize handshake (responding to the client), stores client capabilities, checks client capabilities before sending requests (if strict), and provides the fundamental setRequestHandler and setNotificationHandler methods for registering custom logic using Zod schemas for validation. Defines ServerOptions.\nDependencies: shared/protocol.ts, types.ts, shared/transport.ts.\n\n\n\nLevel 3: Concrete Transport Implementations\nThese classes implement the Transport interface for specific communication channels.\n\n\nsrc/inMemory.ts:\n\nPurpose: Implements Transport for testing. Uses internal queues to connect a client and server directly in memory. Provides createLinkedPair static method.\nDependencies: shared/transport.ts, types.ts, server/auth/types.ts.\n\n\n\nsrc/client/stdio.ts:\n\nPurpose: Client-side Transport for Stdio. Uses cross-spawn to launch the server process, manages its lifecycle, and communicates via its stdin/stdout streams using helpers from shared/stdio.ts. Defines StdioClientTransportOptions.\nDependencies: shared/transport.ts, shared/stdio.ts, types.ts, cross-spawn (external).\n\n\n\nsrc/server/stdio.ts:\n\nPurpose: Server-side Transport for Stdio. Assumes it’s the running process. Reads from process.stdin and writes to process.stdout using helpers from shared/stdio.ts.\nDependencies: shared/transport.ts, shared/stdio.ts, types.ts, Node process.\n\n\n\nsrc/client/websocket.ts:\n\nPurpose: Client-side Transport for WebSocket. Uses the ws library to connect and exchange messages according to the mcp subprotocol expectation.\nDependencies: shared/transport.ts, types.ts, ws (external).\n\n\n\nsrc/client/auth.ts:\n\nPurpose: Provides client-side helper functions (not a transport itself) for executing standard OAuth 2.1 flows against an MCP server’s auth endpoints (e.g., discovery, authorization request generation, code exchange, token refresh, dynamic client registration). Uses fetch.\nDependencies: shared/auth.ts, types.ts (for LATEST_PROTOCOL_VERSION), pkce-challenge (external/mocked for tests).\n\n\n\nsrc/client/sse.ts:\n\nPurpose: Implements Transport for the legacy HTTP+SSE client (dual endpoint). Handles the GET /sse stream (using eventsource) and sending POST /message?sessionId=.... Includes optional integration with client/auth.ts for adding Bearer tokens.\nDependencies: shared/transport.ts, types.ts, client/auth.ts, eventsource (external).\n\n\n\nsrc/server/sse.ts:\n\nPurpose: Implements Transport for the legacy HTTP+SSE server. Handles GET /sse (managing http.ServerResponse for SSE) and POST /message (parsing body, routing via sessionId query parameter).\nDependencies: shared/transport.ts, types.ts, server/auth/types.ts, Node http, crypto, url, content-type (external), raw-body (external).\n\n\n\nsrc/client/streamableHttp.ts:\n\nPurpose: Implements Transport for the modern Streamable HTTP client. Uses fetch for single-endpoint GET/POST/DELETE. Handles both SSE and direct JSON responses on POST. Manages Mcp-Session-Id header. Implements reconnection logic and Last-Event-ID for resumability. Includes optional integration with client/auth.ts.\nDependencies: shared/transport.ts, types.ts, client/auth.ts, eventsource-parser/stream (external).\n\n\n\nsrc/server/streamableHttp.ts:\n\nPurpose: Implements Transport for the modern Streamable HTTP server. Handles GET/POST/DELETE on a single endpoint. Manages sessions via Mcp-Session-Id header. Supports SSE/JSON response modes. Implements resumability by interacting with the EventStore interface (defined within).\nDependencies: shared/transport.ts, types.ts, server/auth/types.ts, Node http, crypto, content-type (external), raw-body (external). Defines StreamableHTTPServerTransportOptions, EventStore.\n\n\n\nLevel 4: High-Level Server Abstractions &amp; OAuth Implementation\nThese build significantly upon the lower-level components.\n\n\nsrc/server/completable.ts:\n\nPurpose: Defines the Completable Zod schema wrapper. This allows attaching a completion function to a schema definition, used by McpServer for argument autocompletion.\nDependencies: Zod (external).\n\n\n\nsrc/server/mcp.ts:\n\nPurpose: Defines the high-level McpServer class, the primary ergonomic API for building servers. Provides .tool(), .resource(), .prompt() methods for declarative registration. It wraps the low-level Server, automatically generating schemas (using zod-to-json-schema), registering handlers, and managing dynamic updates via returned handles (RegisteredTool, etc.). Defines ResourceTemplate.\nDependencies: server/index.ts (low-level Server), types.ts, Zod, zod-to-json-schema (external), server/completable.ts, shared/uriTemplate.ts.\n\n\n\nsrc/server/auth/clients.ts:\n\nPurpose: Defines the OAuthRegisteredClientsStore interface, the contract for how the OAuth server stores and retrieves information about registered client applications.\nDependencies: shared/auth.ts.\n\n\n\nsrc/server/auth/provider.ts:\n\nPurpose: Defines the OAuthServerProvider interface, the core contract for implementing the actual OAuth logic (user authorization, code/token exchange, token validation, revocation). This is what developers would implement or use (like ProxyOAuthServerProvider).\nDependencies: Express types (external, for Response), server/auth/clients.ts, shared/auth.ts, server/auth/types.ts.\n\n\n\nsrc/server/auth/middleware/allowedMethods.ts:\n\nPurpose: Utility Express middleware to restrict HTTP methods allowed for a route, returning 405 otherwise.\nDependencies: Express types (external), server/auth/errors.ts.\n\n\n\nsrc/server/auth/middleware/clientAuth.ts:\n\nPurpose: Express middleware for authenticating OAuth clients via client_id/client_secret in the request body (used by /token, /revoke). It uses the OAuthRegisteredClientsStore to validate credentials and attaches the client info to req.client.\nDependencies: Express types (external), Zod, server/auth/clients.ts, shared/auth.ts, server/auth/errors.ts.\n\n\n\nsrc/server/auth/middleware/bearerAuth.ts:\n\nPurpose: Critical Express middleware for protecting MCP endpoints. It extracts the Bearer token from the Authorization header, validates it using the OAuthServerProvider.verifyAccessToken, checks scopes/expiration, and attaches the resulting AuthInfo to req.auth.\nDependencies: Express types (external), server/auth/provider.ts, server/auth/errors.ts, server/auth/types.ts.\n\n\n\nsrc/server/auth/handlers/*.ts (authorize.ts, metadata.ts, register.ts, revoke.ts, token.ts):\n\nPurpose: These implement the specific logic for each standard OAuth endpoint. They parse requests using Zod/schemas, apply necessary middleware (authenticateClient), interact with the OAuthServerProvider to perform the core logic (e.g., provider.exchangeAuthorizationCode), and format appropriate OAuth success or error responses.\nDependencies: Express types (external), server/auth/provider.ts, relevant middleware (clientAuth), errors, shared types, Zod, pkce-challenge (token handler).\n\n\n\nsrc/server/auth/providers/proxyProvider.ts:\n\nPurpose: A concrete implementation of OAuthServerProvider that acts as a proxy, forwarding requests to an upstream OAuth server. Implements the required provider methods by making fetch calls to the configured upstream endpoints.\nDependencies: server/auth/provider.ts, server/auth/clients.ts (for its own client store interface), shared/auth.ts, server/auth/errors.ts.\n\n\n\nLevel 5: Top-Level Integration, Examples &amp; Tests\n\n\nsrc/server/auth/router.ts:\n\nPurpose: Provides the mcpAuthRouter factory function. This is a major convenience function that takes an OAuthServerProvider implementation and wires up an Express router with all the standard OAuth endpoint handlers and middleware configured correctly.\nDependencies: Express (external), all files in server/auth/handlers/, server/auth/middleware/, server/auth/provider.ts.\n\n\n\nsrc/cli.ts:\n\nPurpose: A basic command-line tool to run simple client/server examples provided in the SDK, primarily for testing Stdio but demonstrating other transports too.\nDependencies: client/index.ts, server/index.ts, various transport implementations (Stdio, SSE, WebSocket), types.ts, ws (external).\n\n\n\nsrc/examples/**/*.ts:\n\nPurpose: Provides practical, runnable examples demonstrating various ways to use the SDK to build clients and servers (different transports, stateful/stateless, resumability, parallel calls, etc.). These are key learning resources.\nDependencies: Core SDK classes (Client, McpServer), specific transports, types.ts, Node crypto, express (external).\n\n\n\nsrc/integration-tests/**/*.ts:\n\nPurpose: Contains tests that verify the interaction between different components, often client and server, sometimes involving real transports (like launching a Stdio process) or specific features like resumability with an InMemoryEventStore.\nDependencies: Core SDK classes, transports, types, testing framework (Jest), potentially example code (InMemoryEventStore).\n\n\n\nsrc/**/*.test.ts (Unit Tests):\n\nPurpose: Test individual classes, functions, or modules in isolation. Validate logic, error handling, and edge cases.\nDependencies: The specific file/unit under test, mocking libraries (Jest built-ins, potentially others), maybe inMemory.ts for simple transport mocking. Highest dependency level as they test everything else.\n\n\n\nThis detailed hierarchy flows from the most basic type definitions up through core logic, transports, abstractions, complex features like authentication, and finally the usage examples and tests that integrate everything."},"6-Remaining/109_recreated-break-down-of-CS-SDK-files":{"slug":"6-Remaining/109_recreated-break-down-of-CS-SDK-files","filePath":"6 Remaining/109_recreated break down of CS SDK files.md","title":"109_recreated break down of CS SDK files","links":[],"tags":[],"content":"Okay, let’s meticulously list the C# SDK files, attempting to order them from least internally dependent to most internally dependent, along with their purpose. This ordering is approximate, as dependencies can be complex, but it follows a general flow from foundational definitions to higher-level abstractions and integrations.\nLevel 0: Foundational Utilities &amp; Polyfills (Minimal internal SDK dependencies; rely on .NET BCL)\n\nCommon/Polyfills/**/*.cs:\n\nFiles: Numerous files under System/, System/Collections/, System/Diagnostics/, etc. (e.g., CollectionExtensions.cs, DynamicallyAccessedMembersAttribute.cs, StreamExtensions.cs, TaskExtensions.cs, IsExternalInit.cs, RequiredMemberAttribute.cs, etc.)\nPurpose: Provide implementations of newer .NET APIs and attributes for older target frameworks (like netstandard2.0 or net472) that the SDK supports. This allows the main SDK code to use modern C# features and APIs consistently across targets. They depend almost exclusively on the base .NET libraries for the specific framework they are polyfilling.\n\n\nCommon/Utils/Throw.cs:\n\nPurpose: Contains static helper methods (IfNull, IfNullOrWhiteSpace) for concisely throwing common argument exceptions. Reduces boilerplate code.\nDependencies: .NET BCL Exceptions (ArgumentNullException, ArgumentException).\n\n\nCommon/Utils/SemaphoreSlimExtensions.cs:\n\nPurpose: Provides the LockAsync extension method for SemaphoreSlim, offering a convenient using-based pattern for asynchronous locking.\nDependencies: .NET BCL (SemaphoreSlim, ValueTask, IDisposable).\n\n\n\nLevel 1: Core Protocol Constants, Enums, Basic Structures, and Exceptions\n\nModelContextProtocol/McpErrorCode.cs:\n\nPurpose: Defines the McpErrorCode enum containing standard JSON-RPC error codes used within MCP.\nDependencies: .NET BCL Enum.\n\n\nModelContextProtocol/McpException.cs:\n\nPurpose: Defines the primary custom exception class (McpException) used throughout the SDK to represent MCP-specific errors, often wrapping an McpErrorCode.\nDependencies: .NET BCL Exception, McpErrorCode.cs.\n\n\nModelContextProtocol/Protocol/Messages/RequestId.cs:\n\nPurpose: Defines the RequestId struct to represent the JSON-RPC id field, which can be a string or a number. Includes a custom JsonConverter to handle serialization/deserialization.\nDependencies: .NET BCL, System.Text.Json.\n\n\nModelContextProtocol/Protocol/Messages/ProgressToken.cs:\n\nPurpose: Defines the ProgressToken struct, similar to RequestId, representing the token used for progress notifications. Includes a custom JsonConverter.\nDependencies: .NET BCL, System.Text.Json.\n\n\nModelContextProtocol/Protocol/Messages/NotificationMethods.cs:\n\nPurpose: Defines string constants for standard MCP notification method names (e.g., &quot;notifications/progress&quot;).\nDependencies: None internal.\n\n\nModelContextProtocol/Protocol/Messages/RequestMethods.cs:\n\nPurpose: Defines string constants for standard MCP request method names (e.g., &quot;tools/list&quot;).\nDependencies: None internal.\n\n\nModelContextProtocol/Protocol/Types/Role.cs:\n\nPurpose: Defines the Role enum (User, Assistant). Uses CustomizableJsonStringEnumConverter.\nDependencies: Utils/Json/CustomizableJsonStringEnumConverter.cs.\n\n\nModelContextProtocol/Protocol/Types/LoggingLevel.cs:\n\nPurpose: Defines the LoggingLevel enum (Debug, Info, etc.). Uses CustomizableJsonStringEnumConverter.\nDependencies: Utils/Json/CustomizableJsonStringEnumConverter.cs.\n\n\nModelContextProtocol/Protocol/Types/ContextInclusion.cs:\n\nPurpose: Defines the ContextInclusion enum (None, ThisServer, AllServers). Uses CustomizableJsonStringEnumConverter.\nDependencies: Utils/Json/CustomizableJsonStringEnumConverter.cs.\n\n\nModelContextProtocol/Protocol/Types/Implementation.cs:\n\nPurpose: Defines the simple Implementation class used to identify clients and servers (Name, Version).\nDependencies: .NET BCL.\n\n\n\nLevel 2: JSON-RPC Message Structures &amp; Basic MCP Types\n\nModelContextProtocol/Protocol/Messages/JsonRpcMessage.cs:\n\nPurpose: Abstract base class for all JSON-RPC messages (jsonrpc property). Contains the crucial [JsonConverter] attribute pointing to JsonRpcMessageConverter.\nDependencies: Utils/Json/JsonRpcMessageConverter.cs.\n\n\nModelContextProtocol/Protocol/Messages/JsonRpcMessageWithId.cs:\n\nPurpose: Abstract base class for messages that have an ID (Requests, Responses, Errors). Inherits JsonRpcMessage.\nDependencies: JsonRpcMessage.cs, RequestId.cs.\n\n\nModelContextProtocol/Protocol/Messages/JsonRpcNotification.cs:\n\nPurpose: Represents a JSON-RPC Notification message (method, params). Inherits JsonRpcMessage.\nDependencies: JsonRpcMessage.cs, System.Text.Json.Nodes.\n\n\nModelContextProtocol/Protocol/Messages/JsonRpcRequest.cs:\n\nPurpose: Represents a JSON-RPC Request message (method, id, params). Inherits JsonRpcMessageWithId.\nDependencies: JsonRpcMessageWithId.cs, System.Text.Json.Nodes.\n\n\nModelContextProtocol/Protocol/Messages/JsonRpcErrorDetail.cs:\n\nPurpose: Record defining the structure of the error object within an error response (code, message, data).\nDependencies: .NET BCL.\n\n\nModelContextProtocol/Protocol/Messages/JsonRpcError.cs:\n\nPurpose: Represents a JSON-RPC Error Response message. Inherits JsonRpcMessageWithId.\nDependencies: JsonRpcMessageWithId.cs, JsonRpcErrorDetail.cs.\n\n\nModelContextProtocol/Protocol/Messages/JsonRpcResponse.cs:\n\nPurpose: Represents a successful JSON-RPC Response message (result). Inherits JsonRpcMessageWithId.\nDependencies: JsonRpcMessageWithId.cs, System.Text.Json.Nodes.\n\n\nModelContextProtocol/Protocol/Types/Annotations.cs:\n\nPurpose: Defines the Annotations record used within other primitives (audience, priority).\nDependencies: Role.cs.\n\n\nModelContextProtocol/Protocol/Types/RequestParamsMetadata.cs:\n\nPurpose: Defines the structure of the optional _meta field within request parameters (e.g., progressToken).\nDependencies: ProgressToken.cs.\n\n\nModelContextProtocol/Protocol/Types/RequestParams.cs:\n\nPurpose: Abstract base class intended for specific request parameter types (like InitializeRequestParams). Includes the optional Meta property.\nDependencies: RequestParamsMetadata.cs.\n\n\nModelContextProtocol/Protocol/Messages/PaginatedResult.cs:\n\nPurpose: Base class for response results that support pagination, defining the NextCursor property.\nDependencies: .NET BCL.\n\n\nModelContextProtocol/Protocol/Types/EmptyResult.cs:\n\nPurpose: Represents an empty result for successful operations that return no specific data.\nDependencies: .NET BCL.\n\n\n\nLevel 3: Complex MCP Payload Types (Primitives, Capabilities, Content)\n\nModelContextProtocol/Protocol/Types/Content.cs:\n\nPurpose: Defines the versatile Content class used in messages/results, representing text, image, audio, or embedded resources based on its Type property.\nDependencies: Annotations.cs, Role.cs (via Annotations), ResourceContents.cs.\n\n\nModelContextProtocol/Protocol/Types/ResourceContents.cs:\n\nPurpose: Abstract base class for resource content. Defines common fields (Uri, MimeType) and the custom JsonConverter for polymorphism.\nDependencies: Utils/Json/JsonRpcMessageConverter.cs (Conceptually similar converter needed, maybe defined internally or re-used).\n\n\nModelContextProtocol/Protocol/Types/TextResourceContents.cs:\n\nPurpose: Concrete class for text-based resource content (Text property). Inherits ResourceContents.\nDependencies: ResourceContents.cs.\n\n\nModelContextProtocol/Protocol/Types/BlobResourceContents.cs:\n\nPurpose: Concrete class for binary resource content (Blob property as base64 string). Inherits ResourceContents.\nDependencies: ResourceContents.cs.\n\n\nModelContextProtocol/Protocol/Types/PromptMessage.cs:\n\nPurpose: Defines the structure of messages within a prompt result (role, content).\nDependencies: Role.cs, Content.cs, EmbeddedResource.cs (defined within).\n\n\nModelContextProtocol/Protocol/Types/SamplingMessage.cs:\n\nPurpose: Defines the structure of messages used in sampling requests (role, content).\nDependencies: Role.cs, Content.cs (but restricted to Text/Image/Audio).\n\n\nModelContextProtocol/Protocol/Types/Resource.cs:\n\nPurpose: Defines the metadata structure for a Resource.\nDependencies: Annotations.cs.\n\n\nModelContextProtocol/Protocol/Types/ResourceTemplate.cs:\n\nPurpose: Defines the metadata structure for a Resource Template.\nDependencies: Annotations.cs.\n\n\nModelContextProtocol/Protocol/Types/ToolAnnotations.cs:\n\nPurpose: Defines optional behavioral hints for Tools.\nDependencies: .NET BCL.\n\n\nModelContextProtocol/Protocol/Types/Tool.cs:\n\nPurpose: Defines the metadata structure for a Tool, including its InputSchema as a JsonElement.\nDependencies: ToolAnnotations.cs, System.Text.Json.\n\n\nModelContextProtocol/Protocol/Types/PromptArgument.cs:\n\nPurpose: Defines the structure for describing arguments accepted by Prompts.\nDependencies: .NET BCL.\n\n\nModelContextProtocol/Protocol/Types/Prompt.cs:\n\nPurpose: Defines the metadata structure for a Prompt.\nDependencies: PromptArgument.cs.\n\n\nModelContextProtocol/Protocol/Types/Root.cs:\n\nPurpose: Defines the structure for representing a client Root.\nDependencies: .NET BCL.\n\n\nModelContextProtocol/Protocol/Types/ModelHint.cs, ModelPreferences.cs:\n\nPurpose: Define structures related to sampling model preferences.\nDependencies: ModelHint.cs depends on BCL, ModelPreferences.cs depends on ModelHint.cs.\n\n\nModelContextProtocol/Protocol/Types/Reference.cs, Argument.cs, Completion.cs:\n\nPurpose: Define structures specific to the argument completion feature (ref, argument, completion result structure).\nDependencies: .NET BCL.\n\n\nModelContextProtocol/Protocol/Types/*Capability.cs (ClientCapabilities.cs, ServerCapabilities.cs, LoggingCapability.cs, PromptsCapability.cs, ResourcesCapability.cs, ToolsCapability.cs, CompletionsCapability.cs, RootsCapability.cs, SamplingCapability.cs):\n\nPurpose: Define the structures used to declare supported features during initialization. They often contain boolean flags or [JsonIgnore]-ed Func&lt;&gt; delegates for handlers (set via configuration/DI).\nDependencies: Other specific MCP Types (e.g., McpServerTool, McpServerPrompt for collections, specific *RequestParams, *Result types for handler signatures). Server/RequestContext.cs.\n\n\n\nLevel 4: Foundational Interfaces &amp; Shared Logic\n\nModelContextProtocol/IMcpEndpoint.cs:\n\nPurpose: Core shared interface defining basic endpoint operations (SendMessageAsync, SendRequestAsync, RegisterNotificationHandler, DisposeAsync).\nDependencies: Protocol/Messages/* (basic JSON-RPC types), Func&lt;&gt; delegates.\n\n\nModelContextProtocol/Protocol/Transport/ITransport.cs:\n\nPurpose: Interface defining the contract for an active, established communication session (provides MessageReader, SendMessageAsync, DisposeAsync).\nDependencies: System.Threading.Channels, Protocol/Messages/JsonRpcMessage.cs.\n\n\nModelContextProtocol/Protocol/Transport/IClientTransport.cs:\n\nPurpose: Interface defining the contract for creating a client transport session (ConnectAsync returning ITransport).\nDependencies: ITransport.cs.\n\n\nModelContextProtocol/Shared/NotificationHandlers.cs, ModelContextProtocol/Shared/RequestHandlers.cs:\n\nPurpose: Internal helper classes for managing dictionaries of notification and request handlers, respectively, often keyed by method name string. Include logic for registration and invocation.\nDependencies: Protocol/Messages/*, Func&lt;&gt; delegates.\n\n\nModelContextProtocol/Shared/McpSession.cs:\n\nPurpose: The core internal engine. Manages a single MCP session over an ITransport. Handles the message processing loop (ProcessMessagesAsync), request/response correlation (_pendingRequests), dispatching messages to registered handlers (RequestHandlers, NotificationHandlers), cancellation tracking (_handlingRequests), and basic error handling.\nDependencies: ITransport.cs, NotificationHandlers.cs, RequestHandlers.cs, Protocol/Messages/*, McpException.cs, Diagnostics.cs, logging, System.Threading.Channels, System.Collections.Concurrent.\n\n\nModelContextProtocol/Shared/McpEndpoint.cs:\n\nPurpose: Abstract base class providing common implementation for IMcpEndpoint, likely containing the McpSession instance and delegating core operations to it. Manages disposal and session lifecycle.\nDependencies: IMcpEndpoint.cs, McpSession.cs, RequestHandlers.cs, NotificationHandlers.cs, logging.\n\n\nModelContextProtocol/Protocol/Transport/TransportBase.cs:\n\nPurpose: Abstract base class providing common boilerplate for ITransport implementations (channel management via _messageChannel, connection state IsConnected, logging helpers).\nDependencies: ITransport.cs, JsonRpcMessage.cs, logging, System.Threading.Channels.\n\n\nModelContextProtocol/Diagnostics.cs:\n\nPurpose: Internal static class providing helpers for creating and managing OpenTelemetry Activitys and Meters specific to MCP operations. Includes context propagation helpers.\nDependencies: System.Diagnostics, System.Diagnostics.Metrics, Protocol/Messages/*.\n\n\nModelContextProtocol/NopProgress.cs, ModelContextProtocol/ProgressNotificationValue.cs, ModelContextProtocol/TokenProgress.cs:\n\nPurpose: Support classes for the IProgress&lt;T&gt; pattern used for progress reporting. TokenProgress specifically links reports to an IMcpEndpoint and ProgressToken.\nDependencies: IMcpEndpoint.cs, Protocol/Messages/ProgressToken.cs, Protocol/Messages/ProgressNotification.cs.\n\n\n\nLevel 5: Concrete Transport Implementations\n(These depend on TransportBase or other transports, specific I/O APIs, and messages)\n\nModelContextProtocol/Protocol/Transport/StreamServerTransport.cs, ModelContextProtocol/Protocol/Transport/StreamClientSessionTransport.cs:\n\nPurpose: Core implementations for transports based on .NET Stream objects (e.g., TextReader/TextWriter). Handle line-delimited JSON framing. StreamClientSessionTransport is used internally by Stdio and Stream clients.\nDependencies: TransportBase.cs, ITransport.cs, .NET Streams, System.Text.Json.\n\n\nModelContextProtocol/Protocol/Transport/StdioServerTransport.cs, ModelContextProtocol/Protocol/Transport/StdioClientTransport.cs, ModelContextProtocol/Protocol/Transport/StdioClientSessionTransport.cs, ModelContextProtocol/Protocol/Transport/StdioClientTransportOptions.cs:\n\nPurpose: Implement Stdio transport. Client launches process (System.Diagnostics.Process, ProcessHelper); Server wraps Console streams. Use the stream transport bases.\nDependencies: Stream*Transport.cs, IClientTransport.cs, ProcessHelper.cs, .NET Process, Console.\n\n\nModelContextProtocol/Protocol/Transport/SseWriter.cs:\n\nPurpose: Helper class to format and write messages as Server-Sent Events to a stream. Manages event IDs for potential resumability.\nDependencies: System.Net.ServerSentEvents, JsonRpcMessage.cs, System.Text.Json, System.Threading.Channels.\n\n\nModelContextProtocol/Protocol/Transport/SseClientSessionTransport.cs, ModelContextProtocol/Protocol/Transport/SseClientTransport.cs, ModelContextProtocol/Protocol/Transport/SseClientTransportOptions.cs:\n\nPurpose: Implements client-side HTTP+SSE (legacy) or Streamable HTTP communication based on SseClientTransportOptions.UseStreamableHttp. Uses HttpClient and SseParser. SseClientTransport is the factory; SseClientSessionTransport is the active session transport.\nDependencies: TransportBase.cs, IClientTransport.cs, ITransport.cs, HttpClient, SseParser, StreamableHttpClientSessionTransport.cs (if UseStreamableHttp is true).\n\n\nModelContextProtocol/Protocol/Transport/StreamableHttpClientSessionTransport.cs:\n\nPurpose: Specific logic for Streamable HTTP client sessions (part of the SseClientTransport when UseStreamableHttp is true). Handles POSTing messages and processing SSE/JSON responses from POST, plus managing the optional GET stream.\nDependencies: TransportBase.cs, ITransport.cs, HttpClient, SseParser.\n\n\nModelContextProtocol/Protocol/Transport/StreamableHttpServerTransport.cs:\n\nPurpose: Server-side core logic for Streamable HTTP (used by ASP.NET Core integration). Implements ITransport. Manages session state (though no session ID itself), handles incoming messages via OnMessageReceivedAsync, sends responses/notifications via SseWriter, interacts with EventStore (interface defined but implementation external) for resumability.\nDependencies: ITransport.cs, SseWriter.cs, JsonRpcMessage.cs, System.IO.Pipelines, System.Threading.Channels. Defines EventStore.\n\n\nModelContextProtocol/Protocol/Transport/StreamableHttpPostTransport.cs:\n\nPurpose: Internal helper used by StreamableHttpServerTransport (likely via ASP.NET Core’s StreamableHttpHandler) to manage the request/response flow specifically for a single HTTP POST within the Streamable HTTP model, ensuring responses go back on the correct connection.\nDependencies: ITransport.cs, SseWriter.cs, System.IO.Pipelines.\n\n\nModelContextProtocol/Protocol/Transport/StreamClientTransport.cs:\n\nPurpose: Client transport factory that wraps pre-existing Stream objects. Useful for testing or custom scenarios.\nDependencies: IClientTransport.cs, StreamClientSessionTransport.cs.\n\n\n\nLevel 6: Core Client/Server Implementations &amp; Abstractions\n\nModelContextProtocol/Client/IMcpClient.cs:\n\nPurpose: Public interface for MCP clients. Inherits IMcpEndpoint. Adds server info/caps properties.\nDependencies: IMcpEndpoint.cs, Protocol/Types/*Capabilities.cs, Protocol/Types/Implementation.cs.\n\n\nModelContextProtocol/Server/IMcpServer.cs:\n\nPurpose: Public interface for MCP servers. Inherits IMcpEndpoint. Adds client info/caps properties, ServerOptions, Services, LoggingLevel, RunAsync.\nDependencies: IMcpEndpoint.cs, Protocol/Types/*Capabilities.cs, Protocol/Types/Implementation.cs, McpServerOptions.cs.\n\n\nModelContextProtocol/Client/McpClientOptions.cs:\n\nPurpose: Defines configuration options for creating an IMcpClient.\nDependencies: Protocol/Types/ClientCapabilities.cs, Protocol/Types/Implementation.cs.\n\n\nModelContextProtocol/Server/McpServerOptions.cs:\n\nPurpose: Defines configuration options for creating an IMcpServer. Holds ServerInfo, Capabilities, timeouts, etc.\nDependencies: Protocol/Types/ServerCapabilities.cs, Protocol/Types/Implementation.cs.\n\n\nModelContextProtocol/Client/McpClient.cs:\n\nPurpose: The concrete implementation of IMcpClient. Extends McpEndpoint. Contains the logic specific to client initialization and capability management.\nDependencies: IMcpClient.cs, Shared/McpEndpoint.cs, IClientTransport.cs, McpClientOptions.cs, Protocol/Types/*, Protocol/Messages/*.\n\n\nModelContextProtocol/Server/McpServer.cs:\n\nPurpose: The concrete implementation of IMcpServer. Extends McpEndpoint. Contains logic specific to server initialization response, managing client capabilities, and provides the infrastructure for registering handlers via McpServerOptions.\nDependencies: IMcpServer.cs, Shared/McpEndpoint.cs, ITransport.cs, McpServerOptions.cs, Protocol/Types/*, Protocol/Messages/*, IServiceProvider (optional).\n\n\nModelContextProtocol/Server/RequestContext.cs:\n\nPurpose: Container passed to server handler delegates, providing access to the IMcpServer, request Params, and potentially scoped Services.\nDependencies: IMcpServer.cs, IServiceProvider.\n\n\nModelContextProtocol/Server/IMcpServerPrimitive.cs, McpServerPrimitiveCollection.cs:\n\nPurpose: Defines a base interface for server-side Tools/Prompts and a thread-safe collection (ConcurrentDictionary-based) to store them, including a Changed event.\nDependencies: .NET BCL Collections.\n\n\n\nLevel 7: Factories, Extensions, Primitive Wrappers, Attributes\n\nModelContextProtocol/Client/McpClientFactory.cs:\n\nPurpose: Provides the static CreateAsync method, the primary way to instantiate and connect an IMcpClient. Orchestrates transport connection and initialization.\nDependencies: IMcpClient.cs, McpClient.cs, IClientTransport.cs, McpClientOptions.cs.\n\n\nModelContextProtocol/Server/McpServerFactory.cs:\n\nPurpose: Provides the static Create method for instantiating an IMcpServer. Primarily used internally by DI extensions but can be used manually.\nDependencies: IMcpServer.cs, McpServer.cs, ITransport.cs, McpServerOptions.cs.\n\n\nModelContextProtocol/AIContentExtensions.cs:\n\nPurpose: Crucial extension methods for converting between MCP Content/PromptMessage types and Microsoft.Extensions.AI types (AIContent, ChatMessage). Enables integration.\nDependencies: Microsoft.Extensions.AI (external), Protocol/Types/* (Content, PromptMessage, Role).\n\n\nModelContextProtocol/McpEndpointExtensions.cs:\n\nPurpose: Provides strongly-typed extension methods (SendRequestAsync&lt;TParams, TResult&gt;, SendNotificationAsync&lt;TParams&gt;) on IMcpEndpoint for easier message sending/receiving without manual JSON handling.\nDependencies: IMcpEndpoint.cs, Protocol/Messages/*, System.Text.Json.\n\n\nModelContextProtocol/Client/McpClientExtensions.cs:\n\nPurpose: Provides high-level, user-friendly extension methods on IMcpClient for common operations (PingAsync, ListToolsAsync, CallToolAsync, ReadResourceAsync, GetPromptAsync, SubscribeToResourceAsync, SetLoggingLevel, etc.). These wrap McpEndpointExtensions.SendRequestAsync.\nDependencies: IMcpClient.cs, McpEndpointExtensions.cs, Protocol/Types/*, Protocol/Messages/*, McpClientTool.cs, McpClientPrompt.cs.\n\n\nModelContextProtocol/Server/McpServerExtensions.cs:\n\nPurpose: Provides high-level extension methods on IMcpServer for server-initiated actions like (RequestSamplingAsync, AsSamplingChatClient, AsClientLoggerProvider, RequestRootsAsync).\nDependencies: IMcpServer.cs, McpEndpointExtensions.cs, Protocol/Types/*, Protocol/Messages/*, Microsoft.Extensions.AI, Microsoft.Extensions.Logging.\n\n\nModelContextProtocol/Client/McpClientTool.cs:\n\nPurpose: Client-side representation of a discovered server Tool. Inherits Microsoft.Extensions.AI.AIFunction, enabling direct use with AI clients. Wraps an IMcpClient and Tool metadata to implement InvokeCoreAsync by calling client.CallToolAsync. Includes WithName/WithDescription/WithProgress customization methods.\nDependencies: Microsoft.Extensions.AI, IMcpClient.cs, Protocol/Types/Tool.cs, Protocol/Types/CallToolResponse.cs, ProgressNotificationValue.cs.\n\n\nModelContextProtocol/Client/McpClientPrompt.cs:\n\nPurpose: Client-side representation of a discovered server Prompt. Wraps IMcpClient and Prompt metadata. Provides GetAsync method to call client.GetPromptAsync.\nDependencies: IMcpClient.cs, Protocol/Types/Prompt.cs, Protocol/Types/GetPromptResult.cs.\n\n\nModelContextProtocol/Server/McpServerTool.cs, ModelContextProtocol/Server/McpServerPrompt.cs:\n\nPurpose: Abstract base classes for server-side Tool/Prompt implementations. Define the ProtocolTool/ProtocolPrompt metadata property and the core InvokeAsync/GetAsync execution methods. Provide static Create factory methods that typically create AIFunctionMcpServerTool/Prompt instances.\nDependencies: IMcpServerPrimitive.cs, Protocol/Types/Tool.cs, Protocol/Types/Prompt.cs, RequestContext.cs, AIFunction (external), reflection APIs.\n\n\nModelContextProtocol/Server/AIFunctionMcpServerTool.cs, ModelContextProtocol/Server/AIFunctionMcpServerPrompt.cs:\n\nPurpose: Concrete implementations of McpServerTool/McpServerPrompt that wrap an AIFunction. Handle argument binding (including DI/context parameters via AIFunctionFactoryOptions), schema generation, method invocation, and result conversion.\nDependencies: McpServerTool/Prompt.cs, AIFunction (external), RequestContext.cs, Protocol/Types/*, AIContentExtensions.cs.\n\n\nModelContextProtocol/Server/DelegatingMcpServerTool.cs, ModelContextProtocol/Server/DelegatingMcpServerPrompt.cs:\n\nPurpose: Abstract base classes useful for creating decorators or wrappers around existing McpServerTool/McpServerPrompt instances.\nDependencies: McpServerTool/Prompt.cs.\n\n\nModelContextProtocol/Server/*Attribute.cs (McpServerToolAttribute.cs, McpServerToolTypeAttribute.cs, McpServerPromptAttribute.cs, McpServerPromptTypeAttribute.cs):\n\nPurpose: Attributes used by DI extensions (WithToolsFromAssembly, etc.) to discover methods and classes that should be registered as MCP Tools or Prompts. Contain metadata like Name, Description, ToolAnnotations.\nDependencies: .NET BCL Attributes.\n\n\nModelContextProtocol/Server/McpServerToolCreateOptions.cs, ModelContextProtocol/Server/McpServerPromptCreateOptions.cs:\n\nPurpose: Classes holding configuration options used by the McpServerTool/Prompt.Create factory methods, allowing programmatic customization equivalent to attribute properties.\nDependencies: IServiceProvider, JsonSerializerOptions.\n\n\n\nLevel 8: Dependency Injection &amp; Hosting Configuration\n\nModelContextProtocol/Configuration/IMcpServerBuilder.cs:\n\nPurpose: Defines the fluent builder interface returned by AddMcpServer, exposing the Services collection.\nDependencies: Microsoft.Extensions.DependencyInjection.\n\n\nModelContextProtocol/Configuration/DefaultMcpServerBuilder.cs:\n\nPurpose: The default, internal implementation of IMcpServerBuilder.\nDependencies: IMcpServerBuilder.cs, Microsoft.Extensions.DependencyInjection.\n\n\nModelContextProtocol/Server/McpServerHandlers.cs:\n\nPurpose: A container class, typically configured via DI Options, holding the Func&lt;&gt; delegates for low-level request handlers (ListTools, CallTool, ReadResource, etc.).\nDependencies: RequestContext.cs, specific *RequestParams and *Result types from Protocol/Types/.\n\n\nModelContextProtocol/Configuration/McpServerOptionsSetup.cs:\n\nPurpose: An IConfigureOptions&lt;McpServerOptions&gt; implementation. Runs during DI container build. It retrieves registered McpServerTools, McpServerPrompts, and IOptions&lt;McpServerHandlers&gt; from DI and populates the corresponding collections and handler delegates within the final McpServerOptions. This wires up the DI registrations to the server configuration.\nDependencies: Microsoft.Extensions.Options, Microsoft.Extensions.DependencyInjection, McpServerOptions.cs, McpServerHandlers.cs, McpServerTool.cs, McpServerPrompt.cs.\n\n\nModelContextProtocol/Configuration/McpServerBuilderExtensions.cs:\n\nPurpose: The primary user-facing API for DI configuration. Defines extension methods like AddMcpServer, WithTools&lt;T&gt;, WithPromptsFromAssembly, WithListResourcesHandler, WithStdioServerTransport, WithHttpTransport. These methods register services, configure options, and add primitives to the DI container.\nDependencies: IMcpServerBuilder.cs, Microsoft.Extensions.DependencyInjection, McpServerHandlers.cs, McpServerOptions.cs, ITransport.cs, McpServerTool/Prompt.cs.\n\n\nModelContextProtocol/Hosting/SingleSessionMcpServerHostedService.cs:\n\nPurpose: An IHostedService implementation used by WithStdioServerTransport and WithStreamServerTransport. It retrieves the IMcpServer from DI and calls server.RunAsync() when the .NET host starts, managing the lifecycle for single-session transports.\nDependencies: Microsoft.Extensions.Hosting, IMcpServer.cs.\n\n\n\nLevel 9: ASP.NET Core Integration\n\nModelContextProtocol.AspNetCore/*: These files depend heavily on ASP.NET Core abstractions (HttpContext, IEndpointRouteBuilder, RequestDelegate, IDuplexPipe, etc.) as well as the core MCP Server components (McpServerFactory, IMcpServer, McpServerOptions) and transports (StreamableHttpServerTransport, SseResponseStreamTransport).\n\nHttpServerTransportOptions.cs: Defines options specific to ASP.NET Core hosting (IdleTimeout, ConfigureSessionOptions, RunSessionHandler).\nHttpMcpSession.cs: Internal class managing state for a single HTTP-based session.\nIdleTrackingBackgroundService.cs: Uses hosting and options to clean up idle sessions.\nStreamableHttpHandler.cs / SseHandler.cs: The core request delegates implementing the transport logic using ASP.NET Core APIs.\nHttpMcpServerBuilderExtensions.cs: Defines .WithHttpTransport() for DI setup.\nMcpEndpointRouteBuilderExtensions.cs: Defines .MapMcp() for routing setup.\n\n\n\nLevel 10: Samples &amp; Tests\n\nsamples/**/*.cs: Demonstrate usage of the SDK features. Depend on the core SDK libraries (ModelContextProtocol), potentially ASP.NET Core integration (ModelContextProtocol.AspNetCore), and external libraries (Microsoft.Extensions.Hosting, Anthropic.SDK).\ntests/**/*.cs: Verify the correctness and behavior of SDK components. Depend on the specific parts of the SDK being tested, testing frameworks (xUnit), mocking libraries (Moq), and utility helpers (tests/Common, tests/ModelContextProtocol.AspNetCore.Tests/Utils).\n\nThis detailed ordering highlights the layered nature of the SDK, moving from fundamental definitions up through core logic, specific implementations, abstractions, and finally application-level integrations and testing."},"6-Remaining/Blogs/blog-11":{"slug":"6-Remaining/Blogs/blog-11","filePath":"6 Remaining/Blogs/blog-11.md","title":"Blog 11: FastMCP Showdown - Comparing Advanced TypeScript vs. Python Implementations","links":[],"tags":[],"content":"Blog 11: FastMCP Showdown - Comparing Advanced TypeScript vs. Python Implementations\nSeries: Deep Dive into the Model Context Protocol SDKs (Advanced Topics)\r\nPost: 11 of 12\nWe’ve journeyed deep into the Model Context Protocol (MCP) ecosystem, exploring the official SDKs and, more recently, diving into specific higher-level frameworks aimed at enhancing developer experience. Two prominent examples share the “FastMCP” name, drawing inspiration from the original concept of providing ergonomic, Pythonic-feeling interfaces for building MCP servers:\n\njlowin-fastmcp (Python V2): An advanced extension built on the official mcp Python package.\npunkpeye-fastmcp (TypeScript): A framework built on the official @modelcontextprotocol/sdk TypeScript package.\n\nWhile sharing a name and a goal of improved DX, these two community projects, targeting different language ecosystems, represent distinct architectural choices and feature sets. This post provides a comparative deep dive for advanced users, analyzing their internal workings, design philosophies, and suitability for complex MCP tasks. We’ll compare:\n\nCore Server API Ergonomics (Decorators vs. Methods)\nSchema Handling and Validation Philosophies\nContext Provision Mechanisms\nAdvanced Server Patterns (Proxy, Mount, Generation)\nClient Implementations\nTransport Handling Abstractions\nCLI Tooling Capabilities\nOverall Ecosystem Fit and Dependencies\n\n1. Core Server API Ergonomics: Defining Primitives\nBoth frameworks aim to simplify defining Tools, Resources, and Prompts compared to their underlying official SDKs.\n\n\njlowin-fastmcp (Python V2): Decorator-Centric\n\nUses @mcp.tool(), @mcp.resource(), @mcp.prompt() directly on functions.\nMetadata (name, description) is often inferred from the function itself (name, docstring) but can be overridden in the decorator.\nFeels highly idiomatic and concise for Python developers. Minimal boilerplate.\n\n@mcp.tool(name=&quot;calculate&quot;, description=&quot;Performs calculation.&quot;)\ndef calc(op: str, val: int): # Schema inferred\n    &quot;&quot;&quot;Docstring possibly ignored if description provided.&quot;&quot;&quot;\n    # ... logic ...\n\n\npunkpeye-fastmcp (TypeScript): Method-Centric\n\nUses explicit methods on the FastMCP instance: server.addTool({...}), server.addResource({...}), server.addPrompt({...}).\nRequires passing a configuration object containing name, description, parameters/uri/arguments, and the handler execute/load.\nSlightly more verbose than decorators but very explicit.\n\nserver.addTool({\n  name: &quot;calculate&quot;,\n  description: &quot;Performs calculation.&quot;,\n  parameters: z.object({ op: z.string(), val: z.number() }), // Schema object required\n  execute: async (args, context) =&gt; { /* logic */ }\n});\n\n\nComparison: Python’s decorators offer maximum conciseness and leverage language introspection heavily. TypeScript’s method-based approach is more explicit, requiring a configuration object but keeping the function definition separate from its MCP registration metadata.\n2. Schema Handling &amp; Input Validation\nThis is a major point of divergence reflecting language philosophies.\n\n\nPython V2: Type Hint Inference + Pydantic\n\nMechanism: Uses utilities/func_metadata.py to inspect function type hints at runtime. Dynamically generates a Pydantic BaseModel for arguments. Uses model.model_validate(args) to validate/coerce incoming arguments before calling the handler. Also includes logic to pre-parse JSON strings within arguments.\nDX: Define types once in the signature. Validation is automatic. Leverages Pydantic’s rich ecosystem.\nCaveat: Relies entirely on the accuracy of type hints. Can feel “magical”. Complex/custom types might challenge inference.\n\n\n\nTypeScript (punkpeye): Standard Schema + Explicit Validation\n\nMechanism: Accepts a schema object (parameters for tools) adhering to the “Standard Schema” interface. Supports Zod, ArkType, Valibot out-of-the-box. Internally uses libraries like xsschema or zod-to-json-schema to potentially convert this to JSON Schema (for listTools) and likely uses the provided schema object’s .parse() / .validate() method for runtime validation within its central tools/call handler wrapper.\nDX: Choose your preferred validation library. Schema definition is separate but explicit. Validation is automatic if using a supported library object.\nCaveat: Adds dependencies for schema conversion. Less direct link between function signature and validated schema compared to Python’s inference.\n\n\n\nComparison: Python offers a more integrated, DRY approach leveraging type hints directly. TypeScript provides flexibility in choosing a validation library but requires passing the schema object explicitly during registration. Both perform validation before the user’s handler code runs.\n3. Context Provision\nBoth provide a simplified Context object to handlers.\n\nPython V2: Injected via type hint (ctx: Context). Provides high-level methods (.info, .report_progress, .sample, .read_resource) and access to underlying session/request info.\nTypeScript (punkpeye): Passed as the second argument to execute/load handlers. Provides log object (with .info, etc.) and reportProgress method, plus the session data from the authenticate hook.\n\nComparison: Both offer similar convenience methods. Python’s uses dependency injection style hinting, while TypeScript uses explicit parameter passing. Python’s Context currently seems slightly richer, offering direct resource reading and sampling methods, whereas the TS Context focuses on logging, progress, and auth session data.\n4. Advanced Server Patterns: Python Leads\nThis is where jlowin-fastmcp significantly pulls ahead:\n\nProxying (from_client): Python V2 has built-in support for creating a proxy server that forwards requests to any MCP endpoint defined by a Client. punkpeye-fastmcp lacks this feature.\nMounting (mount): Python V2 allows composing multiple FastMCP instances under prefixes. punkpeye-fastmcp lacks this feature.\nGeneration (from_openapi/from_fastapi): Python V2 can automatically generate MCP servers from web API definitions. punkpeye-fastmcp lacks this feature.\n\nComparison: jlowin-fastmcp provides powerful architectural tools for integration and modularity that are entirely absent in punkpeye-fastmcp.\n5. Client Implementation\n\nPython V2 (fastmcp.Client): Provides a dedicated, enhanced client with transport inference, simplified methods, raw result access, and built-in support for configuring sampling/roots handlers.\nTypeScript (punkpeye): Does not include its own high-level client. Developers using punkpeye-fastmcp on the server would typically use the official @modelcontextprotocol/sdk’s Client for client-side interactions.\n\nComparison: Python V2 offers a bespoke, high-level client experience as part of its package. The TypeScript framework focuses solely on the server-side abstraction.\n6. Transport Handling\n\nStdio: Both SDKs provide wrappers around the official SDK’s Stdio transport logic. Implementations differ based on platform process APIs (cross-spawn vs. anyio/subprocess).\nWeb (HTTP):\n\nPython V2: Uses the official mcp package’s HTTP+SSE (legacy spec) transport via ASGI (sse_app).\nTypeScript (punkpeye): Uses the mcp-proxy helper library, which likely wraps the official mcp package’s HTTP+SSE (legacy spec) transport (SSEServerTransport).\nKey Limitation: Neither jlowin-fastmcp nor punkpeye-fastmcp’s high-level server APIs currently offer built-in support for the modern Streamable HTTP transport. Users needing resumability or single-endpoint efficiency would need to bypass these frameworks and use the official TS/C# SDKs directly or implement custom Streamable HTTP handling.\n\n\nWebSockets: Python V2 provides client and server transports. punkpeye-fastmcp does not explicitly support a WebSocket server transport in its start method (though the underlying official TS SDK has a client).\n\nComparison: Both frameworks currently rely on the older HTTP+SSE model for their primary simplified web hosting. Python V2 offers WebSocket support. Neither offers built-in Streamable HTTP server hosting via their high-level APIs.\n7. CLI Tooling\n\nPython V2 (fastmcp CLI): Integrated, powerful tool using typer and uv.\n\ndev: Manages virtual envs (uv run), installs dependencies (--with), runs server, and launches MCP Inspector.\ninstall: Manages virtual envs (uv run), installs dependencies, finds Claude Desktop config, updates config with correct command and environment variables.\nrun: Executes server, supports transport/host/port flags.\n\n\nTypeScript (punkpeye) (fastmcp CLI): Simple wrapper using yargs and execa.\n\ndev: Launches external @wong2/mcp-cli tool via npx, passing the server file.\ninspect: Launches official @modelcontextprotocol/inspector via npx, passing the server file.\nNo dependency management, environment creation, or direct Claude Desktop integration.\n\n\n\nComparison: The Python V2 CLI is vastly more capable, offering a complete development and local deployment workflow solution integrated with uv. The TypeScript CLI is merely a convenience launcher for other external tools.\n8. Ecosystem &amp; Dependencies\n\nPython V2: Relies on official mcp, pydantic (core), anyio (async), typer (CLI), httpx/httpx-sse/websockets (transports), uv (tooling). Tightly integrated with the modern Python tooling landscape.\nTypeScript (punkpeye): Relies on official @modelcontextprotocol/sdk, zod (or other Standard Schema libs), xsschema/zod-to-json-schema (internal), mcp-proxy (SSE helper), yargs/execa (CLI). Depends heavily on the official SDK and specific helper libraries.\n\nSynthesis: Philosophy and Suitability\nBoth jlowin-fastmcp and punkpeye-fastmcp successfully apply the “FastMCP” philosophy of providing ergonomic, higher-level abstractions over the official MCP SDKs in their respective languages. However, they embody different design choices and target slightly different needs beyond basic primitive definition:\n\njlowin-fastmcp (Python V2): Focuses on maximum DX and integration power within the Python ecosystem. Its strengths are the incredibly concise decorator API, powerful server patterns (proxy/mount/gen), a feature-rich client, and unmatched CLI tooling for local dev/deployment. It’s the “batteries-included” framework for Python MCP development. Its main limitation (shared with the official Python SDK) is the lack of built-in Streamable HTTP server support.\npunkpeye-fastmcp (TypeScript): Focuses primarily on simplifying server primitive definition with schema flexibility. Its add* methods and Context object provide a cleaner interface than the raw official SDK handlers. However, it lacks the advanced server patterns and powerful CLI of its Python counterpart and critically relies on the legacy SSE transport for web hosting via an external helper (mcp-proxy), foregoing the Streamable HTTP capabilities present in the very SDK it wraps.\n\nChoosing Between Them (If Language is Flexible):\n\nFor the most advanced server patterns (proxying, mounting, API generation) and the best local dev/deployment tooling (especially for Claude Desktop): Python V2 (jlowin-fastmcp) is currently superior.\nFor building web servers needing high reliability and resumability: Neither framework’s high-level API is ideal. Use the official TypeScript or C# SDKs directly to leverage Streamable HTTP.\nFor simpler Stdio servers where DX in defining primitives is the main goal: Both frameworks offer significant improvements over their respective official SDKs, with the choice depending on language preference (Python decorators vs. TS methods/objects).\nFor building MCP clients: Python V2 provides its own enhanced client; for TypeScript, you’d use the official SDK’s client.\n\nThese frameworks showcase the potential for building higher-level tools upon the MCP foundation, tailoring the experience to specific language idioms and developer needs, albeit sometimes with trade-offs in feature completeness or adherence to the latest specification details compared to the official core SDKs.\n"},"6-Remaining/Blogs/blog-13":{"slug":"6-Remaining/Blogs/blog-13","filePath":"6 Remaining/Blogs/blog-13.md","title":"Blog 13: Handling Failures & State - Advanced Error Handling and Session Management in FastMCP (TS vs. Py)","links":["6-Remaining/Blogs/blog-2"],"tags":[],"content":"Blog 13: Handling Failures &amp; State - Advanced Error Handling and Session Management in FastMCP (TS vs. Py)\nSeries: Deep Dive into the Model Context Protocol SDKs (Advanced Topics)\r\nPost: 13 of 10\nOur advanced journey through the Model Context Protocol (MCP) SDK ecosystem now brings us to the critical aspects of building production-ready applications: robust error handling and effective session state management. While the FastMCP frameworks (punkpeye-fastmcp for TypeScript and jlowin-fastmcp for Python V2) excel at simplifying the happy path (Blog 2), real-world scenarios involve validation failures, unexpected exceptions, network interruptions, and the need to maintain context across multiple interactions within a single client session.\nThis post targets advanced developers and compares how these two specific FastMCP frameworks handle the inevitable bumps in the road:\n\nError Handling Philosophies: How exceptions within Tool/Resource/Prompt handlers are caught and reported back to clients.\nValidation Error Reporting: Translating schema validation failures (Pydantic, Zod, etc.) into meaningful MCP errors.\nSurfacing Transport/Protocol Errors: How underlying connection or protocol issues are managed.\nSession State Strategies: Mechanisms for storing and retrieving data associated with a specific client connection.\nResilience Revisited: The impact of state management choices on handling disconnections, especially given the prevalent transport models.\n\n1. Error Handling: From Handler Exceptions to MCP Responses\nWhen code within your execute (Tool), load (Resource/Prompt), or handler functions fails, how do the frameworks respond?\n\n\njlowin-fastmcp (Python V2): Automatic Conversion (Mostly for Tools)\n\nMechanism: The core execution logic, particularly within ToolManager.call_tool which uses Tool.run which in turn calls func_metadata.call_fn_with_arg_validation, wraps the execution of the user’s decorated function in a try...except Exception.\nTool Exceptions: If an exception is caught during tool execution, Tool.run catches it and raises a ToolError. This ToolError is then caught higher up (likely in FastMCP._mcp_call_tool or its internal routing logic), which then constructs and returns a CallToolResult with isError=True and the error message (often f&quot;Error executing tool {tool.name}: {e}&quot;) as TextContent. The original exception doesn’t typically crash the server session.\nResource/Prompt Exceptions: Exceptions raised during @mcp.resource or @mcp.prompt execution might be less gracefully handled by default in the high-level FastMCP wrapper. While the underlying mcp low-level server might catch them and return a generic InternalError JSON-RPC response, FastMCP itself doesn’t seem to have explicit isError: true conversion logic built into its resource/prompt handling wrappers comparable to its tool handling. Uncaught exceptions here could potentially lead to standard JSON-RPC Internal Errors being sent back.\n\n\n\npunkpeye-fastmcp (TypeScript): Explicit UserError &amp; Catch-All\n\nMechanism: The conceptual wrapper function created internally by addTool (and likely addResource/addPrompt) wraps the call to the user’s execute/load function in a try...catch.\nTool Exceptions:\n\nIf the handler throws a UserError (exported by the framework), the catch block specifically formats this into a CallToolResult { isError: true, content: [{ type: &#039;text&#039;, text: error.message }] }. This allows developers to signal user-facing errors explicitly.\nIf the handler throws any other Error, the catch block likely logs the error server-side and returns a generic CallToolResult { isError: true, content: [{ type: &#039;text&#039;, text: &#039;Internal Server Error&#039; /* or similar */ }] }, avoiding leaking internal details.\n\n\nResource/Prompt Exceptions: Exceptions during load are likely caught by the central resources/read or prompts/get handlers. These would typically be converted into standard JSON-RPC Error responses (e.g., InternalError code -32603) sent back by the underlying official SDK’s Server instance, rather than a result object with an isError flag.\n\n\n\nComparison: Both frameworks automatically handle exceptions within Tools to return isError: true results, which is helpful for LLMs attempting self-correction. Python’s conversion is generic, while TypeScript offers the UserError type for explicitly controlling user-facing error messages. For Resources/Prompts, exceptions are more likely to result in standard JSON-RPC InternalError responses in both systems.\n2. Validation Error Reporting\nWhen incoming arguments fail schema validation:\n\nPython V2 (jlowin): Pydantic ValidationError\n\nMechanism: call_fn_with_arg_validation calls ArgModelBase.model_validate(args). If this raises Pydantic’s ValidationError, it’s caught.\nReporting: This ValidationError is typically wrapped (perhaps as a ToolError or similar) and results in a CallToolResult { isError: true } containing a formatted message detailing the validation failures (leveraging Pydantic’s detailed error reporting). Clients get structured (though potentially verbose) feedback on why the arguments were invalid.\n\n\nTypeScript (punkpeye): Zod/Standard Schema .safeParse/.validate\n\nMechanism: The internal wrapper function calls the provided schema object’s validation method (e.g., zodSchema.safeParse(args)).\nReporting: If validation fails (!parsed.success), the framework catches the issues/errors. It then throws an McpError with code ErrorCode.InvalidParams (-32602) and a message containing the formatted validation issues (e.g., from Zod’s error.format()). This results in a standard JSON-RPC Error response, not a CallToolResult.\n\n\n\nComparison: Python V2 reports argument validation errors via the CallToolResult.isError mechanism, potentially providing more structured error details within the content. TypeScript (punkpeye) uses the standard JSON-RPC error mechanism (ErrorCode.InvalidParams) for validation failures, which might be considered more protocol-correct but potentially less informative within the content block itself.\n3. Surfacing Transport &amp; Protocol Errors\nErrors occurring below the handler level (e.g., transport disconnected, malformed JSON received):\n\nGenerally Handled by Underlying SDK: Both jlowin-fastmcp and punkpeye-fastmcp rely on the core mcp package / @modelcontextprotocol/sdk respectively to handle these.\nmcp/@modelcontextprotocol/sdk Behavior:\n\nMalformed JSON: Results in ParseError (-32700).\nInvalid Request Structure: Results in InvalidRequest (-32600).\nTransport Disconnect: Causes the session’s message processing loop (ProcessMessagesAsync / internal async tasks) to terminate, potentially rejecting pending client request promises/futures with connection errors. Server-side disconnect events fire.\n\n\nFastMCP Framework Role: These errors usually occur before the FastMCP framework’s handler wrappers are invoked. The frameworks themselves don’t typically add much specific handling here, beyond potentially logging or providing lifecycle events (disconnect). Error responses are generated by the underlying SDK core.\n\n4. Session State Management\nHow can handlers store and retrieve data associated with a specific client session?\n\n\nPython V2 (jlowin): External State Preferred\n\nMechanism: The Context object provides ctx.session (the underlying mcp.server.session.ServerSession) which has a stable session_id throughout the connection. This session_id is the primary key for associating state.\nPattern: Store session data (user preferences, conversation history, multi-step tool state) in an external store (Redis, database, in-memory dict keyed by session_id) accessed within handlers using the ctx.session.session_id. Lifespan context (ctx.request_context.lifespan_context) can provide shared connections/resources for accessing these stores.\nWhy External? Especially important for SSE transport where the server might be stateless and scaled horizontally. Storing state externally makes it accessible regardless of which server instance handles a subsequent POST request (identified by sessionId query param).\n\n\n\nTypeScript (punkpeye): In-Memory Session Object\n\nMechanism: The framework creates a FastMCPSession object per connection. This object lives in memory within the Node.js process for the duration of the connection. The authenticate hook allows attaching custom data (T) directly to this session object, accessible via context.session. Developers could potentially add other properties to a custom subclass of FastMCPSession if needed (though not a documented pattern).\nPattern: Store short-lived, non-critical session data directly on the FastMCPSession object via the authenticate return value or by modifying the session object obtained via server events (less common). For durable or scalable state, an external store keyed by a session identifier (perhaps derived from the connection or auth) would still be needed.\nLimitation: This in-memory state is lost if the server process restarts or if deployed across multiple instances without sticky sessions.\n\n\n\nComparison: Python V2’s design implicitly encourages using external state stores keyed by session ID, suitable for scalable web deployments using SSE. TypeScript (punkpeye) provides a convenient in-memory session object (context.session) via the auth hook, which is simpler for basic state but less scalable/durable for web transports without additional work to persist or externalize that state.\n5. Resilience and State Recovery\nHow does state management interact with connection drops?\n\nStdio: Less of an issue. If the connection (pipe) breaks, the server process typically terminates, losing all in-memory state. State persistence isn’t usually expected between Stdio sessions.\nHTTP+SSE (Python V2, punkpeye-fastmcp):\n\nNo Built-in Resumability: If the client’s GET /sse connection drops, they lose any server-sent messages (notifications, progress, responses) sent during the disconnect.\nState Recovery: If state is stored externally keyed by session ID, when the client reconnects (establishing a new SSE connection and getting a new session ID, or potentially reusing an old one if the server supports it - complex), the application logic could potentially retrieve the previous state. However, intermediate notifications are lost. Long-running tools ideally need to store their final result externally so the client can query for it later, perhaps using the original request ID.\n\n\nStreamable HTTP (Not supported by these frameworks’ high-level APIs):\n\nBuilt-in Resumability: The EventStore mechanism (if implemented on the server, possible with official TS/C# SDKs) allows the client to automatically receive missed messages upon reconnection using Last-Event-ID, transparently recovering state related to notifications and intermediate responses.\n\n\n\nComparison: For web transports, the lack of Streamable HTTP support in both jlowin-fastmcp and punkpeye-fastmcp’s high-level APIs means developers must rely on application-level patterns (primarily external state stores) to handle state persistence and recovery across disconnections, which is less seamless than the built-in resumability possible with the official TS/C# SDKs using the modern transport.\nConclusion: Framework Convenience vs. Foundational Robustness\nBoth FastMCP frameworks simplify common error handling, particularly for tools, by automatically converting exceptions and validation failures into user-friendly MCP responses (isError: true or InvalidParams). However, nuances exist: Python reports validation errors via CallToolResult, while TypeScript (punkpeye) uses standard JSON-RPC errors. Java/C# core SDKs often require more manual construction of error results within handlers.\nFor session state, Python V2’s architecture nudges developers towards external stores suitable for scaling with SSE. punkpeye-fastmcp offers convenient in-memory state via its FastMCPSession object and auth hook, but this approach faces durability and scalability challenges for web deployments, especially given the lack of transport-level resumability inherited from its use of legacy SSE.\nAdvanced developers using these frameworks must implement robust internal validation, manage external state carefully when necessary, and be aware of the limitations imposed by the chosen HTTP transport (primarily legacy SSE) regarding resilience to network interruptions. While the frameworks provide significant DX gains, ensuring production-grade reliability often requires looking beyond their core abstractions and implementing appropriate state management and error recovery patterns at the application level.\n"},"6-Remaining/Blogs/blog-14":{"slug":"6-Remaining/Blogs/blog-14","filePath":"6 Remaining/Blogs/blog-14.md","title":"Blog 14: FastMCP Obscure Gems & Deep Cuts - A Comparative Look for the Curious Coder (TS vs. Py V2)","links":["6-Remaining/Blogs/blog-1"],"tags":[],"content":"Blog 14: FastMCP Obscure Gems &amp; Deep Cuts - A Comparative Look for the Curious Coder (TS vs. Py V2)\nSeries: Deep Dive into the Model Context Protocol SDKs (Advanced Topics)\r\nPost: 14 of 10\nWe’ve navigated the high-level APIs, core concepts, and architectural patterns of the FastMCP frameworks for TypeScript (punkpeye-fastmcp) and Python V2 (jlowin-fastmcp). These frameworks excel at providing ergonomic interfaces over their respective official Model Context Protocol (MCP) SDKs. But for those of us who like to peek behind the curtain, the implementation details often reveal fascinating design choices, clever workarounds, and subtle trade-offs.\nThis post is for the developer who delights in technical trivia and obscure details. We’ll unearth some non-obvious implementation gems and compare how punkpeye-fastmcp and jlowin-fastmcp tackle specific challenges under the hood.\n1. The Schema Shuffle: Inference vs. Standard Schema vs. JSON Schema\n\nPython V2 (jlowin): Dynamic Pydantic Magic\n\nObscure Detail: The core of its schema handling (utilities/func_metadata.py) doesn’t just use Pydantic; it dynamically generates Pydantic BaseModel subclasses at runtime based on function signature inspection (func_metadata creating ArgModelBase). This generated model is then used for both validation (model_validate) and generating the final JSON Schema (model_json_schema) needed for MCP’s tools/list.\nDeep Cut: The FuncMetadata.pre_parse_json method exists specifically to handle clients (like Claude Desktop) that might send JSON objects/arrays as strings within the arguments map. It attempts json.loads on string inputs before Pydantic validation, but only if the result isn’t a simple type (like str/int/float) to avoid incorrectly parsing &quot;hello&quot; into hello. This is a pragmatic workaround for real-world client behavior.\n\n\nTypeScript (punkpeye): Standard Schema Abstraction &amp; Conversion\n\nObscure Detail: While it accepts Zod, ArkType, or Valibot schemas (via the “Standard Schema” concept likely using xsschema), it still needs a standard JSON Schema for the MCP tools/list response. Internally, it must convert the provided schema object into JSON Schema format, likely using zod-to-json-schema or xsschema’s conversion capabilities. This conversion happens during tool registration (addTool).\nDeep Cut: For runtime validation within its internal tools/call handler, it likely calls the .parse() or .validate() method of the original schema object (Zod/ArkType/Valibot) that the user provided during registration, rather than validating against the generated JSON Schema. This leverages the chosen library’s specific validation logic and error reporting.\n\n\n\nComparison: Python dynamically creates Pydantic models from signatures for both validation and schema output, including specific pre-parsing logic. TypeScript abstracts the input schema type but performs an internal conversion step to JSON Schema for metadata while using the original schema object for runtime validation.\n2. Context Objects: Facades and Injection Points\n\nPython V2 (jlowin): Injected Convenience\n\nObscure Detail: The Context object (server/context.py) isn’t just a data bag; its methods (.info, .report_progress, .read_resource, .sample) are convenient facades that delegate calls to the underlying mcp.server.session.ServerSession instance (accessed via ctx.request_context.session).\nDeep Cut: The injection mechanism relies on Tool.from_function (and equivalents for resources/prompts) inspecting the signature to find a parameter annotated as Context and storing its name (context_kwarg). The ToolManager.call_tool then uses this stored name to pass the instantiated Context object into the handler call.\n\n\nTypeScript (punkpeye): Explicit Parameter + Session Binding\n\nObscure Detail: The Context type alias passed as the second argument to execute/load handlers is constructed per-request by the framework’s internal wrapper function.\nDeep Cut: Its log methods internally check the session.loggingLevel (set via logging/setLevel) before bothering to construct and send the log notification via the underlying official SDK’s server.sendLoggingMessage. The context.session property directly exposes the return value of the user-provided authenticate function, offering a simple (but less structured than full DI) way to pass session state.\n\n\n\nComparison: Both provide simplified interfaces, but Python’s uses type-hint-driven injection, while TypeScript uses explicit parameter passing. Python’s Context offers more direct methods for MCP interactions like resource reading and sampling.\n3. Mounting (jlowin-fastmcp): The as_proxy Subtlety\n\nObscure Detail: The FastMCP.mount(prefix, server, as_proxy=None) method has non-trivial default behavior for the as_proxy flag.\n\nIf as_proxy is explicitly True or False, it respects that.\nIf as_proxy is None (the default), it automatically uses proxy mode (as_proxy=True) if and only if the server being mounted has a custom lifespan function defined. Otherwise, it uses direct mode.\nWhy? Direct mode bypasses the mounted server’s client lifecycle, including its lifespan. Proxy mode simulates a full client connection (using FastMCPProxy internally), ensuring the lifespan runs correctly. This default aims for performance (direct) when possible but ensures correctness (proxy) when lifespans are involved.\n\n\n\n4. Server Generation (jlowin-fastmcp): HTTP Client is Key\n\nObscure Detail: When using FastMCP.from_openapi(spec, client) or FastMCP.from_fastapi(app), the generated OpenAPITool/Resource handlers don’t contain the API logic themselves. They contain logic to reconstruct the original HTTP request (URL with path params, query params, headers, JSON body) based on the OpenAPI definition and the arguments provided to the MCP tool/resource call.\nDeep Cut: They then use the httpx.AsyncClient instance passed during server creation (client) to make a live HTTP call to the actual backend API. The performance and authentication of the generated MCP server are therefore entirely dependent on the performance and configuration (e.g., base URL, auth headers) of this underlying httpx client. It’s essentially an MCP-to-HTTP adapter generator.\n\n5. SSE Handling (punkpeye-fastmcp): The mcp-proxy Indirection\n\nObscure Detail: The server.start({ transportType: &#039;sse&#039;, ... }) method doesn’t directly use the official @modelcontextprotocol/sdk’s SSEServerTransport. Instead, it delegates to startSSEServer from the external mcp-proxy library.\nDeep Cut: This mcp-proxy helper likely does use the official SSEServerTransport internally, but it handles the setup of the Node.js http.Server, routing for /sse and /message, session ID generation/tracking, and mapping incoming connections to new instances of the official SDK’s Server (configured via the createServer callback). This means punkpeye-fastmcp relies on this specific library’s implementation for its SSE functionality and inherits its use of the legacy HTTP+SSE dual-endpoint model. It also implies potential overhead from creating multiple underlying Server instances per client.\n\n6. CLI Tooling: uv run vs. npx\n\nPython V2 (jlowin):\n\nObscure Detail: The dev and install commands construct complex uv run --with ... --with-editable ... fastmcp run ... commands.\nDeep Cut: uv run creates a temporary, ephemeral virtual environment on the fly, installs only the specified dependencies (fastmcp, server deps, editable path), executes the fastmcp run command within it, and then discards the environment. This provides strong isolation and ensures the server runs with exactly the intended dependencies without affecting other projects. The install command persists this exact command string into Claude’s config.\n\n\nTypeScript (punkpeye):\n\nObscure Detail: The dev and inspect commands simply use execa to shell out to npx.\nDeep Cut: npx handles fetching and running the specified package (@wong2/mcp-cli or @modelcontextprotocol/inspector). However, the server script (argv.file, run via tsx) and the external tools execute within the user’s current Node.js environment. Dependency conflicts or missing packages can occur if the environment isn’t correctly set up, unlike uv run’s guaranteed isolation.\n\n\n\n7. Testing Transport (jlowin-fastmcp): FastMCPTransport’s Clever Reuse\n\nObscure Detail: The FastMCPTransport used for efficient in-memory testing connects a Client directly to a FastMCP server instance.\nDeep Cut: The contrib/bulk_tool_caller module cleverly reuses this testing transport. It creates an internal Client using FastMCPTransport pointing back to the very server the BulkToolCaller is attached to. This allows the call_tools_bulk tool handler to efficiently make multiple internal client.call_tool_mcp requests without any actual transport overhead.\n\nConclusion: Layers of Abstraction and Ecosystem Choices\nPeeking under the hood of jlowin-fastmcp and punkpeye-fastmcp reveals more than just ergonomic APIs. We see sophisticated techniques like dynamic code generation and introspection (Python), careful abstraction using interfaces and helper libraries (TypeScript, mcp-proxy), and deep integration with platform-specific tooling (uv, DI, AIFunction).\nUnderstanding these obscure gems and deep cuts is valuable for advanced users:\n\nIt clarifies the source of “magic” (e.g., Python’s schema inference).\nIt highlights potential performance trade-offs (e.g., dynamic model gen vs. static schemas, legacy SSE vs. Streamable HTTP).\nIt reveals limitations or dependencies (e.g., reliance on mcp-proxy, lack of Streamable HTTP in punkpeye, manual validation in core Java handlers).\nIt exposes the best ways to debug and extend the frameworks effectively.\n\nWhile both frameworks successfully simplify MCP server development, their internal strategies differ markedly, reflecting the philosophies and capabilities of the Python and TypeScript ecosystems.\n"},"6-Remaining/Blogs/blog-15":{"slug":"6-Remaining/Blogs/blog-15","filePath":"6 Remaining/Blogs/blog-15.md","title":"Blog 15: Under the Microscope - Obscure Internals of MCP SDKs (TS, Py, C#, Java)","links":[],"tags":[],"content":"Blog 15: Under the Microscope - Obscure Internals of MCP SDKs (TS, Py, C#, Java)\nSeries: Deep Dive into the Model Context Protocol SDKs (Advanced Topics)\r\nPost: 15 of 10\nWe’ve covered the high-level APIs, patterns, and features of the official and prominent community Model Context Protocol (MCP) SDKs. For the truly curious developer, however, the real intrigue often lies in the non-obvious implementation details – the clever hacks, the subtle trade-offs, the platform-specific workarounds. How exactly do these SDKs translate the MCP specification into working code across such different ecosystems?\nThis post digs into the weeds, unearthing some “obscure gems” and comparing the internal approaches of the official SDKs (TypeScript, C#, Java) and the enhanced Python V2 framework (jlowin-fastmcp) in four key areas:\n\nSchema Nuances: Beyond basic definition – generation, validation sources, flexibility.\nSession ID Handling: Headers vs. Query Parameters across transports.\nRequest Correlation: The machinery behind matching responses to requests.\nCancellation Internals: How the notifications/cancelled flow interacts with running handlers.\n\n(Disclaimer: This involves peering into internal implementation details which may change between versions. It’s for understanding, not necessarily for relying on undocumented behavior.)\n1. The Schema Shuffle: Generation, Validation, and Flexibility\nWhile all SDKs represent MCP types, how they handle the associated JSON Schema and validation varies considerably.\n\n\nSchema Source &amp; Generation:\n\nTS Official (types.ts): Uses Zod schemas as the primary definition. JSON Schema for tools/list needs to be generated (e.g., using zod-to-json-schema by the developer or a higher-level framework).\nPython Official (mcp/v1) / jlowin-fastmcp (func_metadata.py): Dynamically generates Pydantic models from function type hints. Uses model.model_json_schema() on these generated models to produce the required inputSchema for tools/list.\nC# Official (AIFunctionMcpServerTool): Generates JSON Schema internally using AIFunctionFactory, which reflects on the method signature (excluding DI/context params).\nJava Official (ToolSpecification): Requires the developer to manually provide the inputSchema as a String or Map when creating the Tool metadata object. No built-in generation from method signatures.\nTS punkpeye: Accepts user-provided Zod/ArkType/Valibot schema. Internally converts this to JSON Schema using xsschema/zod-to-json-schema for tools/list.\nObscurity: The Python and C# approaches automate schema generation, reducing duplication but tying the schema tightly to the reflection/introspection capabilities of Pydantic/AIFunctionFactory. Java requires the most manual effort. TS punkpeye adds a conversion step.\n\n\n\nRuntime Validation Source:\n\nTS Official (Server.setRequestHandler): Takes an explicit Zod schema for validation separate from the handler function signature.\nPython V1/V2 (FastMCP): Validates against the dynamically generated Pydantic model derived from the handler’s signature.\nC# (AIFunctionMcpServerTool): Validation occurs internally via the AIFunction invocation logic, likely using the generated JSON schema or reflection-based checks.\nJava Official: No automatic validation in the core session logic before calling the handler BiFunction. Validation is the handler’s responsibility, potentially using the manually provided inputSchema.\nTS punkpeye: Uses the original user-provided schema object (Zod/ArkType/Valibot) via its .parse()/.validate() method.\nObscurity: There’s a potential disconnect in TS punkpeye if the generated JSON Schema (for tools/list) doesn’t perfectly match the runtime validation behavior of the original Zod/ArkType/Valibot schema. Python and C# keep generation and validation closely linked (though potentially less flexible). Java puts the onus entirely on the handler developer.\n\n\n\n2. Session ID Handling: Header vs. Query Parameter\nHow do stateful HTTP transports associate incoming client messages with the correct server-side session?\n\n\nLegacy HTTP+SSE (2024-11-05 Spec):\n\nMechanism: Session ID is generated by the server, included in the data: field of the initial event: endpoint SSE message (as part of the message POST URL). The client extracts this ID and includes it as a ?sessionId=... query parameter on all subsequent POST /message requests.\nSDKs Using: Java (All SSE Providers), Python (SseServerTransport), C# (Legacy SseHandler), TS (SSEServerTransport).\nObscurity: This relies entirely on the client correctly parsing the endpoint event and appending the query parameter. It’s slightly less conventional than using headers and potentially exposes the session ID in URL logs. Server-side routing needs to parse the query string. mcp-proxy likely handles this mapping for punkpeye-fastmcp.\n\n\n\nStreamable HTTP (2025-03-26 Spec):\n\nMechanism: Session ID is generated by the server, sent back in the Mcp-Session-Id HTTP response header of the initial successful POST (often the initialize request). The client reads this header, stores the ID, and includes it as an Mcp-Session-Id HTTP request header on all subsequent POST, GET, and DELETE requests to the server’s single endpoint.\nSDKs Using: TS Official (StreamableHttp*Transport), C# Official (SseClientTransport with UseStreamableHttp=true, StreamableHttpHandler in AspNetCore).\nObscurity: Aligns better with standard HTTP session practices (like cookies, but stateless). Requires header parsing on both client and server. Enables stateless server deployments more easily if session state is external, as the header identifies the context without relying on a specific SSE connection being mapped. C#‘s HttpMcpSession likely tracks sessions based on this header value.\n\n\n\nKey Takeaway: Knowing which session ID mechanism is used by your chosen SDK and transport is vital for debugging connectivity, implementing custom clients/servers, or configuring proxies/load balancers correctly.\n3. Request/Response Correlation: The Pending Request Map\nHow does an SDK ensure the result or error from the server gets delivered to the correct await client.callTool(...) call that initiated it, especially with concurrent requests?\n\nMechanism: All SDKs use a variation of a dictionary/map keyed by the RequestId.\n\nSending: When client.sendRequestAsync (or equivalent low-level method) is called:\n\nA unique RequestId is generated (if not provided).\nA completion mechanism is created (e.g., TaskCompletionSource&lt;JsonRpcResponse&gt; in C#, Promise resolve/reject callbacks in TS, Future/CompletableFuture in Java, potentially an anyio.Event or queue in Python).\nThis completion mechanism is stored in the internal “pending requests” map, keyed by the RequestId.\nThe JsonRpcRequest (with the ID) is sent over the transport.\nThe sendRequestAsync method returns a Task/Promise/Future/Mono linked to the completion mechanism.\n\n\nReceiving: When the core session logic (McpSession/BaseSession) receives an incoming JsonRpcResponse or JsonRpcError:\n\nIt extracts the id from the message.\nIt looks up the id in the “pending requests” map.\nIf found, it retrieves the corresponding completion mechanism.\nIt removes the entry from the map.\nIt completes the Task/Promise/Future/Mono with the received message (either successfully with the result or exceptionally with the error).\nIf not found, it logs an error (received response for unknown request ID).\n\n\n\n\nObscurity:\n\nSynchronization: Access to this map must be thread-safe/concurrency-safe. C# uses ConcurrentDictionary. Others might use locks (threading.Lock in Python BaseSession) or rely on single-threaded event loop guarantees (TS).\nTimeout Handling: Timeouts typically work by setting a timer when the request is sent. If the timer expires before the response arrives, the timer callback attempts to cancel or fail the completion mechanism in the map (e.g., TaskCompletionSource.TrySetException(new TimeoutException())) and removes the entry.\nResource Leaks: If responses are lost and timeouts don’t fire correctly, entries could potentially leak in the map (though good implementations guard against this).\n\n\n\n4. Cancellation Internals: Tying Notifications to Handlers\nHow does receiving notifications/cancelled stop work already in progress on the other end?\n\nMechanism: Requires tracking incoming requests currently being processed.\n\nServer-Side (Handling Client Cancellation):\n\nWhen the server’s core session logic receives a JsonRpcRequest, before invoking the user’s handler:\n\nIt creates a cancellation primitive (e.g., CancellationTokenSource in C#, AbortController in TS).\nIt stores this primitive in a second internal map (“handling requests” or “in-flight”), keyed by the incoming RequestId.\nIt passes the corresponding token/signal (CancellationToken, AbortSignal) to the handler function (e.g., via RequestContext, RequestHandlerExtra, or injected parameter).\n\n\nWhen notifications/cancelled arrives:\n\nThe notification handler looks up the requestId in the “handling requests” map.\nIf found, it triggers cancellation on the stored primitive (e.g., cts.Cancel()).\nThe handler logic (if properly written) detects this cancellation via the token/signal it received and aborts.\n\n\nWhen the handler completes (either successfully or via cancellation/exception):\n\nThe entry for that RequestId is removed from the “handling requests” map.\n\n\n\n\nClient-Side (Handling Server Cancellation): Similar logic applies if the client implements handlers for server-initiated requests (like sampling/createMessage).\n\n\nObscurity:\n\nResource Management: Requires careful management of the cancellation primitives (e.g., ensuring CancellationTokenSource.Dispose() is called in C#) and reliable cleanup of the “handling requests” map entries.\nRace Conditions: As noted before, the cancellation notification might arrive after the handler has already completed, in which case triggering cancellation has no effect.\n\n\n\nConclusion: The Devil is in the (Internal) Details\nWhile high-level frameworks like FastMCP abstract away much of the protocol’s complexity, a deep appreciation for the underlying mechanics is invaluable for advanced debugging, performance tuning, and extension. Understanding the subtle differences in how each SDK:\n\nGenerates or requires JSON Schemas, and where runtime validation occurs.\nIdentifies sessions over HTTP (headers vs. query parameters).\nCorrelates asynchronous requests and responses using internal maps and completion primitives.\nPropagates cancellation signals from notifications to active handlers via dedicated tracking.\n\n…allows developers to make more informed decisions, anticipate potential issues (like transport limitations or validation mismatches), and ultimately build more robust and reliable MCP applications, regardless of their chosen language ecosystem.\n"},"6-Remaining/README":{"slug":"6-Remaining/README","filePath":"6 Remaining/README.md","title":"README","links":[],"tags":[],"content":"\nRemaining\n"},"6-Remaining/index":{"slug":"6-Remaining/index","filePath":"6 Remaining/index.md","title":"6 Remaining","links":[],"tags":[],"content":""},"index":{"slug":"index","filePath":"index.md","title":"index","links":[],"tags":[],"content":"Tutorials targeting Python, Typescript, java and C# sdks for MCP as of 5th May 2025.\nIt also has series o MCP spec and codebases analysis."}}